{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# run ipython with this command: jupyter notebook --NotebookApp.iopub_data_rate_limit=10000000000\n",
    "import matplotlib\n",
    "import brewer2mpl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import layers\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "from keras.models import model_from_json\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Dense, MaxPool2D, Dropout,Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.activations import relu, tanh, elu\n",
    "from keras.backend import clear_session\n",
    "from keras.models import load_model\n",
    "\n",
    "set3 = brewer2mpl.get_map('Set3', 'qualitative', 7).mpl_colors\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_x = pd.read_pickle('normalized_fer2013.pkl')\n",
    "train_data_y = pd.read_pickle('normalized_fer2013_labels.pkl').astype(int)\n",
    "test_data_x = pd.read_pickle('normalized_test_fer2013.pkl')\n",
    "test_data_y = pd.read_pickle('normalized_test_fer2013_labels.pkl').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_x = train_data_x.as_matrix().reshape((-1,48,48,1))\n",
    "test_data_x = test_data_x.as_matrix().reshape((-1,48,48,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_y = train_data_y.as_matrix()\n",
    "test_data_y = test_data_y.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_y = keras.utils.to_categorical(train_data_y, num_classes=7)\n",
    "test_data_y = keras.utils.to_categorical(test_data_y, num_classes=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 20pt>__Training Process__</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5741, 5741, 5741, 5741, 5745]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "partition = 5\n",
    "train_sets = [[] for i in range(partition)]\n",
    "pop = range(len(train_data_y))\n",
    "for i in range(partition - 1):\n",
    "    train_sets[i] = random.sample(pop, len(train_data_y) // partition)\n",
    "    pop = [j for j in pop if j not in train_sets[i]]\n",
    "train_sets[partition - 1] = pop\n",
    "\n",
    "print([len(train_sets[i]) for i in range(partition)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clear_session()\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(Conv2D(8, (2,2), strides=(1,1),activation='elu',padding='same',input_shape=(48,48,1)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(8, (2,2), strides=(1,1),activation='elu',padding='same'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(8, (2,2), strides=(1,1),activation='elu',padding='same'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(8, (2,2), strides=(1,1),activation='elu',padding='same'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(8, (2,2), strides=(2,2),activation='elu',padding='valid'))\n",
    "\n",
    "model.add(Conv2D(16, (2,2), strides=(1,1),activation='elu',padding='same'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(16, (2,2), strides=(1,1),activation='elu',padding='same'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(8, (2,2), strides=(1,1),activation='elu',padding='same'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(8, (2,2), strides=(1,1),activation='elu',padding='same'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(16, (2,2), strides=(2,2),activation='elu',padding='valid'))\n",
    "\n",
    "model.add(Conv2D(8, (2,2), strides=(1,1),activation='elu',padding='same'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(8, (2,2), strides=(1,1),activation='elu',padding='same'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(8, (2,2), strides=(1,1),activation='elu',padding='same'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(8, (2,2), strides=(1,1),activation='elu',padding='same'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(8, (2,2), strides=(1,1),activation='elu',padding='same'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32,activation='elu'))\n",
    "model.add(Dense(7,activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# returns a compiled model\n",
    "# identical to the previous one\n",
    "# model = load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1\n",
      "Train on 22968 samples, validate on 5741 samples\n",
      "Epoch 1/10\n",
      "22968/22968 [==============================] - 201s - loss: 1.7676 - acc: 0.2769 - val_loss: 1.6819 - val_acc: 0.3262\n",
      "Epoch 2/10\n",
      "22968/22968 [==============================] - 258s - loss: 1.7016 - acc: 0.3203 - val_loss: 1.6580 - val_acc: 0.3449\n",
      "Epoch 3/10\n",
      "22968/22968 [==============================] - 208s - loss: 1.6649 - acc: 0.3391 - val_loss: 1.6045 - val_acc: 0.3679\n",
      "Epoch 4/10\n",
      "22968/22968 [==============================] - 182s - loss: 1.6155 - acc: 0.3662 - val_loss: 1.5700 - val_acc: 0.3998\n",
      "Epoch 5/10\n",
      "22968/22968 [==============================] - 167s - loss: 1.5693 - acc: 0.3894 - val_loss: 1.5012 - val_acc: 0.4275\n",
      "Epoch 6/10\n",
      "22968/22968 [==============================] - 229s - loss: 1.5384 - acc: 0.3966 - val_loss: 1.4836 - val_acc: 0.4196\n",
      "Epoch 7/10\n",
      "22968/22968 [==============================] - 307s - loss: 1.5115 - acc: 0.4125 - val_loss: 1.4629 - val_acc: 0.4313\n",
      "Epoch 8/10\n",
      "22968/22968 [==============================] - 300s - loss: 1.4932 - acc: 0.4221 - val_loss: 1.4704 - val_acc: 0.4299\n",
      "Epoch 9/10\n",
      "22968/22968 [==============================] - 308s - loss: 1.4749 - acc: 0.4269 - val_loss: 1.4452 - val_acc: 0.4407\n",
      "Epoch 10/10\n",
      "22968/22968 [==============================] - 259s - loss: 1.4596 - acc: 0.4305 - val_loss: 1.4270 - val_acc: 0.4475\n",
      "EPOCH 11\n",
      "Train on 22968 samples, validate on 5741 samples\n",
      "Epoch 1/10\n",
      "22968/22968 [==============================] - 263s - loss: 1.4509 - acc: 0.4360 - val_loss: 1.3857 - val_acc: 0.4534\n",
      "Epoch 2/10\n",
      "22968/22968 [==============================] - 254s - loss: 1.4402 - acc: 0.4372 - val_loss: 1.3791 - val_acc: 0.4599\n",
      "Epoch 3/10\n",
      "22968/22968 [==============================] - 258s - loss: 1.4216 - acc: 0.4457 - val_loss: 1.3619 - val_acc: 0.4700\n",
      "Epoch 4/10\n",
      "22968/22968 [==============================] - 213s - loss: 1.4132 - acc: 0.4511 - val_loss: 1.3547 - val_acc: 0.4700\n",
      "Epoch 5/10\n",
      "22968/22968 [==============================] - 166s - loss: 1.4038 - acc: 0.4535 - val_loss: 1.3415 - val_acc: 0.4736\n",
      "Epoch 6/10\n",
      "22968/22968 [==============================] - 166s - loss: 1.3950 - acc: 0.4560 - val_loss: 1.3463 - val_acc: 0.4745\n",
      "Epoch 7/10\n",
      "22968/22968 [==============================] - 166s - loss: 1.3830 - acc: 0.4638 - val_loss: 1.3405 - val_acc: 0.4750\n",
      "Epoch 8/10\n",
      "22968/22968 [==============================] - 195s - loss: 1.3738 - acc: 0.4652 - val_loss: 1.3541 - val_acc: 0.4670\n",
      "Epoch 9/10\n",
      "22968/22968 [==============================] - 143s - loss: 1.3703 - acc: 0.4701 - val_loss: 1.3348 - val_acc: 0.4780\n",
      "Epoch 10/10\n",
      "22968/22968 [==============================] - 143s - loss: 1.3627 - acc: 0.4690 - val_loss: 1.3483 - val_acc: 0.4766\n",
      "EPOCH 21\n",
      "Train on 22968 samples, validate on 5741 samples\n",
      "Epoch 1/10\n",
      "22968/22968 [==============================] - 143s - loss: 1.3796 - acc: 0.4636 - val_loss: 1.2748 - val_acc: 0.5024\n",
      "Epoch 2/10\n",
      "22968/22968 [==============================] - 143s - loss: 1.3664 - acc: 0.4707 - val_loss: 1.2755 - val_acc: 0.5020\n",
      "Epoch 3/10\n",
      "22968/22968 [==============================] - 143s - loss: 1.3588 - acc: 0.4705 - val_loss: 1.2613 - val_acc: 0.5140\n",
      "Epoch 4/10\n",
      "22968/22968 [==============================] - 143s - loss: 1.3490 - acc: 0.4774 - val_loss: 1.3007 - val_acc: 0.4905\n",
      "Epoch 5/10\n",
      "22968/22968 [==============================] - 143s - loss: 1.3495 - acc: 0.4770 - val_loss: 1.2752 - val_acc: 0.5010\n",
      "Epoch 6/10\n",
      "22968/22968 [==============================] - 143s - loss: 1.3455 - acc: 0.4757 - val_loss: 1.2679 - val_acc: 0.5053\n",
      "Epoch 7/10\n",
      "22968/22968 [==============================] - 143s - loss: 1.3381 - acc: 0.4812 - val_loss: 1.2808 - val_acc: 0.5015\n",
      "Epoch 8/10\n",
      "22968/22968 [==============================] - 143s - loss: 1.3415 - acc: 0.4788 - val_loss: 1.2825 - val_acc: 0.4961\n",
      "Epoch 9/10\n",
      "22968/22968 [==============================] - 167s - loss: 1.3311 - acc: 0.4850 - val_loss: 1.2941 - val_acc: 0.5015 - ETA: 1s - loss: 1.3315 - acc: \n",
      "Epoch 10/10\n",
      "22968/22968 [==============================] - 168s - loss: 1.3291 - acc: 0.4847 - val_loss: 1.2790 - val_acc: 0.5006\n",
      "EPOCH 31\n",
      "Train on 22968 samples, validate on 5741 samples\n",
      "Epoch 1/10\n",
      "22968/22968 [==============================] - 166s - loss: 1.3356 - acc: 0.4807 - val_loss: 1.2626 - val_acc: 0.5128\n",
      "Epoch 2/10\n",
      "22968/22968 [==============================] - 157s - loss: 1.3290 - acc: 0.4854 - val_loss: 1.2254 - val_acc: 0.5276\n",
      "Epoch 3/10\n",
      "22968/22968 [==============================] - 141s - loss: 1.3214 - acc: 0.4847 - val_loss: 1.2554 - val_acc: 0.5091\n",
      "Epoch 4/10\n",
      "22968/22968 [==============================] - 141s - loss: 1.3270 - acc: 0.4882 - val_loss: 1.2594 - val_acc: 0.5130\n",
      "Epoch 5/10\n",
      "22968/22968 [==============================] - 145s - loss: 1.3132 - acc: 0.4943 - val_loss: 1.2514 - val_acc: 0.5206\n",
      "Epoch 6/10\n",
      "22968/22968 [==============================] - 189s - loss: 1.3208 - acc: 0.4898 - val_loss: 1.2459 - val_acc: 0.5170\n",
      "Epoch 7/10\n",
      "22968/22968 [==============================] - 198s - loss: 1.3142 - acc: 0.4915 - val_loss: 1.2524 - val_acc: 0.5186\n",
      "Epoch 8/10\n",
      "22968/22968 [==============================] - 181s - loss: 1.3074 - acc: 0.4923 - val_loss: 1.2597 - val_acc: 0.5163\n",
      "Epoch 9/10\n",
      "22968/22968 [==============================] - 161s - loss: 1.3025 - acc: 0.4930 - val_loss: 1.2584 - val_acc: 0.5156\n",
      "Epoch 10/10\n",
      "22968/22968 [==============================] - 161s - loss: 1.3014 - acc: 0.4991 - val_loss: 1.2764 - val_acc: 0.5107\n",
      "EPOCH 41\n",
      "Train on 22964 samples, validate on 5745 samples\n",
      "Epoch 1/10\n",
      "22964/22964 [==============================] - 159s - loss: 1.3162 - acc: 0.4894 - val_loss: 1.1935 - val_acc: 0.5413\n",
      "Epoch 2/10\n",
      "22964/22964 [==============================] - 159s - loss: 1.3089 - acc: 0.4940 - val_loss: 1.2007 - val_acc: 0.5344\n",
      "Epoch 3/10\n",
      "22964/22964 [==============================] - 160s - loss: 1.3037 - acc: 0.4966 - val_loss: 1.2064 - val_acc: 0.5358\n",
      "Epoch 4/10\n",
      "22964/22964 [==============================] - 159s - loss: 1.3011 - acc: 0.4964 - val_loss: 1.2210 - val_acc: 0.5305\n",
      "Epoch 5/10\n",
      "22964/22964 [==============================] - 159s - loss: 1.3002 - acc: 0.4949 - val_loss: 1.2173 - val_acc: 0.5312\n",
      "Epoch 6/10\n",
      "22964/22964 [==============================] - 160s - loss: 1.2995 - acc: 0.4980 - val_loss: 1.2310 - val_acc: 0.5271\n",
      "Epoch 7/10\n",
      "22964/22964 [==============================] - 159s - loss: 1.2905 - acc: 0.5051 - val_loss: 1.2415 - val_acc: 0.5151\n",
      "Epoch 8/10\n",
      "22964/22964 [==============================] - 159s - loss: 1.2899 - acc: 0.5000 - val_loss: 1.2452 - val_acc: 0.5161\n",
      "Epoch 9/10\n",
      "22964/22964 [==============================] - 160s - loss: 1.2841 - acc: 0.5009 - val_loss: 1.2413 - val_acc: 0.5170\n",
      "Epoch 10/10\n",
      "22964/22964 [==============================] - 157s - loss: 1.2807 - acc: 0.5077 - val_loss: 1.2386 - val_acc: 0.5206\n",
      "EPOCH 51\n",
      "Train on 22968 samples, validate on 5741 samples\n",
      "Epoch 1/10\n",
      "22968/22968 [==============================] - 160s - loss: 1.2996 - acc: 0.5012 - val_loss: 1.1800 - val_acc: 0.5445\n",
      "Epoch 2/10\n",
      "22968/22968 [==============================] - 192s - loss: 1.2859 - acc: 0.5017 - val_loss: 1.1919 - val_acc: 0.5426\n",
      "Epoch 3/10\n",
      "22968/22968 [==============================] - 208s - loss: 1.2922 - acc: 0.5025 - val_loss: 1.1846 - val_acc: 0.5469\n",
      "Epoch 4/10\n",
      "22968/22968 [==============================] - 212s - loss: 1.2873 - acc: 0.5039 - val_loss: 1.1950 - val_acc: 0.5386\n",
      "Epoch 5/10\n",
      "22968/22968 [==============================] - 234s - loss: 1.2799 - acc: 0.5041 - val_loss: 1.2048 - val_acc: 0.5370\n",
      "Epoch 6/10\n",
      "22968/22968 [==============================] - 240s - loss: 1.2827 - acc: 0.5022 - val_loss: 1.1929 - val_acc: 0.5422\n",
      "Epoch 7/10\n",
      "22968/22968 [==============================] - 190s - loss: 1.2824 - acc: 0.5035 - val_loss: 1.2138 - val_acc: 0.5363\n",
      "Epoch 8/10\n",
      "22968/22968 [==============================] - 193s - loss: 1.2770 - acc: 0.5053 - val_loss: 1.1937 - val_acc: 0.5438\n",
      "Epoch 9/10\n",
      "22968/22968 [==============================] - 188s - loss: 1.2802 - acc: 0.5044 - val_loss: 1.2063 - val_acc: 0.5346\n",
      "Epoch 10/10\n",
      "22968/22968 [==============================] - 202s - loss: 1.2789 - acc: 0.5067 - val_loss: 1.2123 - val_acc: 0.5361\n",
      "EPOCH 61\n",
      "Train on 22968 samples, validate on 5741 samples\n",
      "Epoch 1/10\n",
      "22968/22968 [==============================] - 176s - loss: 1.2823 - acc: 0.5043 - val_loss: 1.1686 - val_acc: 0.5546\n",
      "Epoch 2/10\n",
      "22968/22968 [==============================] - 175s - loss: 1.2848 - acc: 0.5030 - val_loss: 1.1636 - val_acc: 0.5525\n",
      "Epoch 3/10\n",
      "22968/22968 [==============================] - 175s - loss: 1.2788 - acc: 0.5084 - val_loss: 1.1863 - val_acc: 0.5407\n",
      "Epoch 4/10\n",
      "22968/22968 [==============================] - 174s - loss: 1.2674 - acc: 0.5083 - val_loss: 1.1915 - val_acc: 0.5426\n",
      "Epoch 5/10\n",
      "22968/22968 [==============================] - 172s - loss: 1.2742 - acc: 0.5119 - val_loss: 1.2032 - val_acc: 0.5457\n",
      "Epoch 6/10\n",
      "22968/22968 [==============================] - 175s - loss: 1.2755 - acc: 0.5054 - val_loss: 1.1970 - val_acc: 0.5353\n",
      "Epoch 7/10\n",
      "22968/22968 [==============================] - 175s - loss: 1.2660 - acc: 0.5099 - val_loss: 1.2088 - val_acc: 0.5339\n",
      "Epoch 8/10\n",
      "22968/22968 [==============================] - 174s - loss: 1.2694 - acc: 0.5130 - val_loss: 1.1997 - val_acc: 0.5395\n",
      "Epoch 9/10\n",
      "22968/22968 [==============================] - 175s - loss: 1.2684 - acc: 0.5097 - val_loss: 1.2096 - val_acc: 0.5382\n",
      "Epoch 10/10\n",
      "22968/22968 [==============================] - 174s - loss: 1.2617 - acc: 0.5109 - val_loss: 1.2166 - val_acc: 0.5348\n",
      "EPOCH 71\n",
      "Train on 22968 samples, validate on 5741 samples\n",
      "Epoch 1/10\n",
      "22968/22968 [==============================] - 174s - loss: 1.2767 - acc: 0.5111 - val_loss: 1.1236 - val_acc: 0.5611\n",
      "Epoch 2/10\n",
      "22968/22968 [==============================] - 174s - loss: 1.2773 - acc: 0.5042 - val_loss: 1.1474 - val_acc: 0.5557\n",
      "Epoch 3/10\n",
      "22968/22968 [==============================] - 174s - loss: 1.2701 - acc: 0.5125 - val_loss: 1.1576 - val_acc: 0.5523\n",
      "Epoch 4/10\n",
      "22968/22968 [==============================] - 174s - loss: 1.2662 - acc: 0.5088 - val_loss: 1.1529 - val_acc: 0.5548\n",
      "Epoch 5/10\n",
      "22968/22968 [==============================] - 182s - loss: 1.2700 - acc: 0.5049 - val_loss: 1.1709 - val_acc: 0.5436\n",
      "Epoch 6/10\n",
      "22968/22968 [==============================] - 182s - loss: 1.2671 - acc: 0.5142 - val_loss: 1.1684 - val_acc: 0.5480\n",
      "Epoch 7/10\n",
      "22968/22968 [==============================] - 175s - loss: 1.2642 - acc: 0.5114 - val_loss: 1.1919 - val_acc: 0.5410\n",
      "Epoch 8/10\n",
      "22968/22968 [==============================] - 176s - loss: 1.2562 - acc: 0.5175 - val_loss: 1.1728 - val_acc: 0.5442\n",
      "Epoch 9/10\n",
      "22968/22968 [==============================] - 173s - loss: 1.2617 - acc: 0.5147 - val_loss: 1.2000 - val_acc: 0.5337\n",
      "Epoch 10/10\n",
      "22968/22968 [==============================] - 171s - loss: 1.2623 - acc: 0.5154 - val_loss: 1.1888 - val_acc: 0.5410\n",
      "EPOCH 81\n",
      "Train on 22968 samples, validate on 5741 samples\n",
      "Epoch 1/10\n",
      "22968/22968 [==============================] - 175s - loss: 1.2677 - acc: 0.5108 - val_loss: 1.1264 - val_acc: 0.5710\n",
      "Epoch 2/10\n",
      "22968/22968 [==============================] - 158s - loss: 1.2664 - acc: 0.5119 - val_loss: 1.1343 - val_acc: 0.5624\n",
      "Epoch 3/10\n",
      "22968/22968 [==============================] - 153s - loss: 1.2581 - acc: 0.5177 - val_loss: 1.2102 - val_acc: 0.5400\n",
      "Epoch 4/10\n",
      "22968/22968 [==============================] - 153s - loss: 1.2644 - acc: 0.5134 - val_loss: 1.1688 - val_acc: 0.5478513\n",
      "Epoch 5/10\n",
      "22968/22968 [==============================] - 153s - loss: 1.2575 - acc: 0.5163 - val_loss: 1.1759 - val_acc: 0.5435\n",
      "Epoch 6/10\n",
      "22968/22968 [==============================] - 153s - loss: 1.2576 - acc: 0.5115 - val_loss: 1.1608 - val_acc: 0.5501\n",
      "Epoch 7/10\n",
      "22968/22968 [==============================] - 153s - loss: 1.2522 - acc: 0.5201 - val_loss: 1.1934 - val_acc: 0.5415\n",
      "Epoch 8/10\n",
      "22968/22968 [==============================] - 153s - loss: 1.2473 - acc: 0.5199 - val_loss: 1.1794 - val_acc: 0.5462\n",
      "Epoch 9/10\n",
      "22968/22968 [==============================] - 153s - loss: 1.2529 - acc: 0.5174 - val_loss: 1.1822 - val_acc: 0.5428\n",
      "Epoch 10/10\n",
      "22968/22968 [==============================] - 153s - loss: 1.2499 - acc: 0.5173 - val_loss: 1.1877 - val_acc: 0.5414\n",
      "EPOCH 91\n",
      "Train on 22964 samples, validate on 5745 samples\n",
      "Epoch 1/10\n",
      "22964/22964 [==============================] - 153s - loss: 1.2609 - acc: 0.5134 - val_loss: 1.1191 - val_acc: 0.5692\n",
      "Epoch 2/10\n",
      "22964/22964 [==============================] - 153s - loss: 1.2561 - acc: 0.5178 - val_loss: 1.1398 - val_acc: 0.5619\n",
      "Epoch 3/10\n",
      "22964/22964 [==============================] - 152s - loss: 1.2539 - acc: 0.5177 - val_loss: 1.1720 - val_acc: 0.5450\n",
      "Epoch 4/10\n",
      "22964/22964 [==============================] - 153s - loss: 1.2538 - acc: 0.5192 - val_loss: 1.1555 - val_acc: 0.5525\n",
      "Epoch 5/10\n",
      "22964/22964 [==============================] - 153s - loss: 1.2545 - acc: 0.5192 - val_loss: 1.1649 - val_acc: 0.5499\n",
      "Epoch 6/10\n",
      "22964/22964 [==============================] - 153s - loss: 1.2501 - acc: 0.5154 - val_loss: 1.1797 - val_acc: 0.5497\n",
      "Epoch 7/10\n",
      "22964/22964 [==============================] - 153s - loss: 1.2444 - acc: 0.5197 - val_loss: 1.1816 - val_acc: 0.5433\n",
      "Epoch 8/10\n",
      "22964/22964 [==============================] - 153s - loss: 1.2444 - acc: 0.5196 - val_loss: 1.1627 - val_acc: 0.5502\n",
      "Epoch 9/10\n",
      "22964/22964 [==============================] - 154s - loss: 1.2458 - acc: 0.5197 - val_loss: 1.1580 - val_acc: 0.5570\n",
      "Epoch 10/10\n",
      "22964/22964 [==============================] - 153s - loss: 1.2466 - acc: 0.5187 - val_loss: 1.1714 - val_acc: 0.5448\n",
      "EPOCH 101\n",
      "Train on 22968 samples, validate on 5741 samples\n",
      "Epoch 1/10\n",
      "22968/22968 [==============================] - 153s - loss: 1.2499 - acc: 0.5195 - val_loss: 1.1272 - val_acc: 0.5661\n",
      "Epoch 2/10\n",
      "22968/22968 [==============================] - 153s - loss: 1.2538 - acc: 0.5175 - val_loss: 1.1362 - val_acc: 0.5708\n",
      "Epoch 3/10\n",
      "22968/22968 [==============================] - 154s - loss: 1.2507 - acc: 0.5193 - val_loss: 1.1082 - val_acc: 0.5795\n",
      "Epoch 4/10\n",
      "22968/22968 [==============================] - 153s - loss: 1.2471 - acc: 0.5195 - val_loss: 1.1287 - val_acc: 0.5710\n",
      "Epoch 5/10\n",
      "22968/22968 [==============================] - 153s - loss: 1.2471 - acc: 0.5196 - val_loss: 1.1481 - val_acc: 0.5611\n",
      "Epoch 6/10\n",
      "22968/22968 [==============================] - 156s - loss: 1.2440 - acc: 0.5200 - val_loss: 1.1594 - val_acc: 0.5605\n",
      "Epoch 7/10\n",
      "22968/22968 [==============================] - 155s - loss: 1.2470 - acc: 0.5181 - val_loss: 1.1955 - val_acc: 0.5457\n",
      "Epoch 8/10\n",
      "22968/22968 [==============================] - 153s - loss: 1.2428 - acc: 0.5226 - val_loss: 1.1482 - val_acc: 0.5590\n",
      "Epoch 9/10\n",
      "22968/22968 [==============================] - 153s - loss: 1.2426 - acc: 0.5213 - val_loss: 1.1542 - val_acc: 0.5577\n",
      "Epoch 10/10\n",
      "22968/22968 [==============================] - 154s - loss: 1.2420 - acc: 0.5212 - val_loss: 1.1587 - val_acc: 0.5567\n",
      "EPOCH 111\n",
      "Train on 22968 samples, validate on 5741 samples\n",
      "Epoch 1/10\n",
      "22968/22968 [==============================] - 153s - loss: 1.2478 - acc: 0.5204 - val_loss: 1.1333 - val_acc: 0.5680\n",
      "Epoch 2/10\n",
      "22968/22968 [==============================] - 153s - loss: 1.2473 - acc: 0.5199 - val_loss: 1.1270 - val_acc: 0.5703\n",
      "Epoch 3/10\n",
      "22968/22968 [==============================] - 153s - loss: 1.2473 - acc: 0.5213 - val_loss: 1.1457 - val_acc: 0.5612\n",
      "Epoch 4/10\n",
      "22968/22968 [==============================] - 153s - loss: 1.2402 - acc: 0.5231 - val_loss: 1.1447 - val_acc: 0.5623\n",
      "Epoch 5/10\n",
      "22968/22968 [==============================] - 156s - loss: 1.2440 - acc: 0.5201 - val_loss: 1.1533 - val_acc: 0.5558\n",
      "Epoch 6/10\n",
      "22968/22968 [==============================] - 158s - loss: 1.2397 - acc: 0.5229 - val_loss: 1.1573 - val_acc: 0.5536\n",
      "Epoch 7/10\n",
      "22968/22968 [==============================] - 158s - loss: 1.2400 - acc: 0.5220 - val_loss: 1.1701 - val_acc: 0.5490\n",
      "Epoch 8/10\n",
      "22968/22968 [==============================] - 156s - loss: 1.2397 - acc: 0.5214 - val_loss: 1.1591 - val_acc: 0.5558\n",
      "Epoch 9/10\n",
      "22968/22968 [==============================] - 159s - loss: 1.2341 - acc: 0.5287 - val_loss: 1.1699 - val_acc: 0.5546\n",
      "Epoch 10/10\n",
      "22968/22968 [==============================] - 154s - loss: 1.2392 - acc: 0.5236 - val_loss: 1.1673 - val_acc: 0.5584\n",
      "EPOCH 121\n",
      "Train on 22968 samples, validate on 5741 samples\n",
      "Epoch 1/10\n",
      "22968/22968 [==============================] - 153s - loss: 1.2495 - acc: 0.5175 - val_loss: 1.0909 - val_acc: 0.5816\n",
      "Epoch 2/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.2476 - acc: 0.5162 - val_loss: 1.0883 - val_acc: 0.5846\n",
      "Epoch 3/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.2408 - acc: 0.5222 - val_loss: 1.1122 - val_acc: 0.5712\n",
      "Epoch 4/10\n",
      "22968/22968 [==============================] - 157s - loss: 1.2443 - acc: 0.5223 - val_loss: 1.1012 - val_acc: 0.5741\n",
      "Epoch 5/10\n",
      "22968/22968 [==============================] - 157s - loss: 1.2427 - acc: 0.5237 - val_loss: 1.1342 - val_acc: 0.5685\n",
      "Epoch 6/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.2425 - acc: 0.5208 - val_loss: 1.1506 - val_acc: 0.5558\n",
      "Epoch 7/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.2382 - acc: 0.5233 - val_loss: 1.1472 - val_acc: 0.5557\n",
      "Epoch 8/10\n",
      "22968/22968 [==============================] - 150s - loss: 1.2379 - acc: 0.5220 - val_loss: 1.1323 - val_acc: 0.5640\n",
      "Epoch 9/10\n",
      "22968/22968 [==============================] - 149s - loss: 1.2347 - acc: 0.5259 - val_loss: 1.1424 - val_acc: 0.5579\n",
      "Epoch 10/10\n",
      "22968/22968 [==============================] - 150s - loss: 1.2302 - acc: 0.5281 - val_loss: 1.1415 - val_acc: 0.5577\n",
      "EPOCH 131\n",
      "Train on 22968 samples, validate on 5741 samples\n",
      "Epoch 1/10\n",
      "22968/22968 [==============================] - 150s - loss: 1.2404 - acc: 0.5231 - val_loss: 1.1006 - val_acc: 0.5746\n",
      "Epoch 2/10\n",
      "22968/22968 [==============================] - 150s - loss: 1.2403 - acc: 0.5235 - val_loss: 1.1311 - val_acc: 0.5652\n",
      "Epoch 3/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.2421 - acc: 0.5228 - val_loss: 1.1311 - val_acc: 0.5684\n",
      "Epoch 4/10\n",
      "22968/22968 [==============================] - 150s - loss: 1.2345 - acc: 0.5238 - val_loss: 1.1310 - val_acc: 0.5668\n",
      "Epoch 5/10\n",
      "22968/22968 [==============================] - 150s - loss: 1.2372 - acc: 0.5254 - val_loss: 1.1143 - val_acc: 0.5774\n",
      "Epoch 6/10\n",
      "22968/22968 [==============================] - 150s - loss: 1.2364 - acc: 0.5232 - val_loss: 1.1375 - val_acc: 0.5633\n",
      "Epoch 7/10\n",
      "22968/22968 [==============================] - 150s - loss: 1.2353 - acc: 0.5256 - val_loss: 1.1397 - val_acc: 0.5649\n",
      "Epoch 8/10\n",
      "22968/22968 [==============================] - 150s - loss: 1.2358 - acc: 0.5258 - val_loss: 1.1377 - val_acc: 0.5631\n",
      "Epoch 9/10\n",
      "22968/22968 [==============================] - 150s - loss: 1.2241 - acc: 0.5327 - val_loss: 1.1567 - val_acc: 0.5511\n",
      "Epoch 10/10\n",
      "22968/22968 [==============================] - 149s - loss: 1.2229 - acc: 0.5289 - val_loss: 1.1644 - val_acc: 0.5572\n",
      "EPOCH 141\n",
      "Train on 22964 samples, validate on 5745 samples\n",
      "Epoch 1/10\n",
      "22964/22964 [==============================] - 150s - loss: 1.2414 - acc: 0.5220 - val_loss: 1.0908 - val_acc: 0.5833\n",
      "Epoch 2/10\n",
      "22964/22964 [==============================] - 150s - loss: 1.2327 - acc: 0.5260 - val_loss: 1.1014 - val_acc: 0.5770\n",
      "Epoch 3/10\n",
      "22964/22964 [==============================] - 150s - loss: 1.2296 - acc: 0.5255 - val_loss: 1.1210 - val_acc: 0.5716\n",
      "Epoch 4/10\n",
      "22964/22964 [==============================] - 150s - loss: 1.2291 - acc: 0.5298 - val_loss: 1.1284 - val_acc: 0.5697\n",
      "Epoch 5/10\n",
      "22964/22964 [==============================] - 150s - loss: 1.2324 - acc: 0.5280 - val_loss: 1.1416 - val_acc: 0.5558\n",
      "Epoch 6/10\n",
      "22964/22964 [==============================] - 151s - loss: 1.2294 - acc: 0.5300 - val_loss: 1.1589 - val_acc: 0.5502\n",
      "Epoch 7/10\n",
      "22964/22964 [==============================] - 150s - loss: 1.2291 - acc: 0.5271 - val_loss: 1.1375 - val_acc: 0.5619\n",
      "Epoch 8/10\n",
      "22964/22964 [==============================] - 151s - loss: 1.2261 - acc: 0.5301 - val_loss: 1.1396 - val_acc: 0.5645\n",
      "Epoch 9/10\n",
      "22964/22964 [==============================] - 150s - loss: 1.2247 - acc: 0.5294 - val_loss: 1.1400 - val_acc: 0.5556\n",
      "Epoch 10/10\n",
      "22964/22964 [==============================] - 151s - loss: 1.2256 - acc: 0.5277 - val_loss: 1.1545 - val_acc: 0.5520\n",
      "EPOCH 151\n",
      "Train on 22968 samples, validate on 5741 samples\n",
      "Epoch 1/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.2404 - acc: 0.5190 - val_loss: 1.1030 - val_acc: 0.5760\n",
      "Epoch 2/10\n",
      "22968/22968 [==============================] - 150s - loss: 1.2323 - acc: 0.5249 - val_loss: 1.1044 - val_acc: 0.5821\n",
      "Epoch 3/10\n",
      "22968/22968 [==============================] - 150s - loss: 1.2306 - acc: 0.5257 - val_loss: 1.1102 - val_acc: 0.5783\n",
      "Epoch 4/10\n",
      "22968/22968 [==============================] - 150s - loss: 1.2329 - acc: 0.5283 - val_loss: 1.1207 - val_acc: 0.5724\n",
      "Epoch 5/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.2302 - acc: 0.5255 - val_loss: 1.1097 - val_acc: 0.5790\n",
      "Epoch 6/10\n",
      "22968/22968 [==============================] - 150s - loss: 1.2219 - acc: 0.5294 - val_loss: 1.1338 - val_acc: 0.5708\n",
      "Epoch 7/10\n",
      "22968/22968 [==============================] - 150s - loss: 1.2240 - acc: 0.5296 - val_loss: 1.1127 - val_acc: 0.5774\n",
      "Epoch 8/10\n",
      "22968/22968 [==============================] - 150s - loss: 1.2247 - acc: 0.5275 - val_loss: 1.1337 - val_acc: 0.5666\n",
      "Epoch 9/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.2228 - acc: 0.5290 - val_loss: 1.1331 - val_acc: 0.5689\n",
      "Epoch 10/10\n",
      "22968/22968 [==============================] - 150s - loss: 1.2249 - acc: 0.5289 - val_loss: 1.1607 - val_acc: 0.5523\n",
      "EPOCH 161\n",
      "Train on 22968 samples, validate on 5741 samples\n",
      "Epoch 1/10\n",
      "22968/22968 [==============================] - 150s - loss: 1.2318 - acc: 0.5300 - val_loss: 1.1082 - val_acc: 0.5757\n",
      "Epoch 2/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.2266 - acc: 0.5301 - val_loss: 1.1064 - val_acc: 0.5776\n",
      "Epoch 3/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.2230 - acc: 0.5304 - val_loss: 1.1311 - val_acc: 0.5687\n",
      "Epoch 4/10\n",
      "22968/22968 [==============================] - 150s - loss: 1.2273 - acc: 0.5291 - val_loss: 1.1274 - val_acc: 0.5694\n",
      "Epoch 5/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.2268 - acc: 0.5286 - val_loss: 1.1281 - val_acc: 0.5731\n",
      "Epoch 6/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.2220 - acc: 0.5316 - val_loss: 1.1343 - val_acc: 0.5649\n",
      "Epoch 7/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.2114 - acc: 0.5354 - val_loss: 1.1440 - val_acc: 0.5647\n",
      "Epoch 8/10\n",
      "22968/22968 [==============================] - 150s - loss: 1.2179 - acc: 0.5317 - val_loss: 1.1350 - val_acc: 0.5677 ETA: 0s - loss: 1.2180 - acc: 0.5\n",
      "Epoch 9/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.2187 - acc: 0.5329 - val_loss: 1.1322 - val_acc: 0.5678\n",
      "Epoch 10/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.2186 - acc: 0.5297 - val_loss: 1.1692 - val_acc: 0.5508\n",
      "EPOCH 171\n",
      "Train on 22968 samples, validate on 5741 samples\n",
      "Epoch 1/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.2336 - acc: 0.5236 - val_loss: 1.0739 - val_acc: 0.5881\n",
      "Epoch 2/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.2295 - acc: 0.5275 - val_loss: 1.0740 - val_acc: 0.5856\n",
      "Epoch 3/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.2260 - acc: 0.5286 - val_loss: 1.0892 - val_acc: 0.5800\n",
      "Epoch 4/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.2282 - acc: 0.5327 - val_loss: 1.1023 - val_acc: 0.5725\n",
      "Epoch 5/10\n",
      "22968/22968 [==============================] - 153s - loss: 1.2235 - acc: 0.5302 - val_loss: 1.0852 - val_acc: 0.5813\n",
      "Epoch 6/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.2243 - acc: 0.5306 - val_loss: 1.0895 - val_acc: 0.5792\n",
      "Epoch 7/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.2230 - acc: 0.5307 - val_loss: 1.1182 - val_acc: 0.5706\n",
      "Epoch 8/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.2227 - acc: 0.5311 - val_loss: 1.1236 - val_acc: 0.5713\n",
      "Epoch 9/10\n",
      "22968/22968 [==============================] - 155s - loss: 1.2204 - acc: 0.5314 - val_loss: 1.1132 - val_acc: 0.5750\n",
      "Epoch 10/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.2224 - acc: 0.5286 - val_loss: 1.1209 - val_acc: 0.5684\n",
      "EPOCH 181\n",
      "Train on 22968 samples, validate on 5741 samples\n",
      "Epoch 1/10\n",
      "22968/22968 [==============================] - 148s - loss: 1.2249 - acc: 0.5300 - val_loss: 1.0599 - val_acc: 0.5908\n",
      "Epoch 2/10\n",
      "22968/22968 [==============================] - 149s - loss: 1.2208 - acc: 0.5337 - val_loss: 1.1061 - val_acc: 0.576453\n",
      "Epoch 3/10\n",
      "22968/22968 [==============================] - 149s - loss: 1.2222 - acc: 0.5323 - val_loss: 1.0866 - val_acc: 0.5839\n",
      "Epoch 4/10\n",
      "22968/22968 [==============================] - 149s - loss: 1.2260 - acc: 0.5323 - val_loss: 1.0948 - val_acc: 0.5802\n",
      "Epoch 5/10\n",
      "22968/22968 [==============================] - 149s - loss: 1.2184 - acc: 0.5354 - val_loss: 1.1199 - val_acc: 0.5708\n",
      "Epoch 6/10\n",
      "22968/22968 [==============================] - 149s - loss: 1.2179 - acc: 0.5332 - val_loss: 1.1171 - val_acc: 0.5671\n",
      "Epoch 7/10\n",
      "22968/22968 [==============================] - 149s - loss: 1.2130 - acc: 0.5390 - val_loss: 1.1317 - val_acc: 0.5611\n",
      "Epoch 8/10\n",
      "22968/22968 [==============================] - 149s - loss: 1.2144 - acc: 0.5335 - val_loss: 1.1493 - val_acc: 0.5563\n",
      "Epoch 9/10\n",
      "22968/22968 [==============================] - 149s - loss: 1.2117 - acc: 0.5361 - val_loss: 1.1228 - val_acc: 0.5659\n",
      "Epoch 10/10\n",
      "22968/22968 [==============================] - 149s - loss: 1.2123 - acc: 0.5330 - val_loss: 1.1369 - val_acc: 0.5635\n",
      "EPOCH 191\n",
      "Train on 22964 samples, validate on 5745 samples\n",
      "Epoch 1/10\n",
      "22964/22964 [==============================] - 150s - loss: 1.2249 - acc: 0.5325 - val_loss: 1.0762 - val_acc: 0.5923\n",
      "Epoch 2/10\n",
      "22964/22964 [==============================] - 149s - loss: 1.2195 - acc: 0.5296 - val_loss: 1.0865 - val_acc: 0.5866\n",
      "Epoch 3/10\n",
      "22964/22964 [==============================] - 150s - loss: 1.2187 - acc: 0.5347 - val_loss: 1.1074 - val_acc: 0.5765\n",
      "Epoch 4/10\n",
      "22964/22964 [==============================] - 152s - loss: 1.2148 - acc: 0.5353 - val_loss: 1.1421 - val_acc: 0.5558\n",
      "Epoch 5/10\n",
      "22964/22964 [==============================] - 150s - loss: 1.2188 - acc: 0.5320 - val_loss: 1.1058 - val_acc: 0.5772\n",
      "Epoch 6/10\n",
      "22964/22964 [==============================] - 149s - loss: 1.2118 - acc: 0.5363 - val_loss: 1.1611 - val_acc: 0.5497\n",
      "Epoch 7/10\n",
      "22964/22964 [==============================] - 150s - loss: 1.2109 - acc: 0.5364 - val_loss: 1.1288 - val_acc: 0.5652\n",
      "Epoch 8/10\n",
      "22964/22964 [==============================] - 151s - loss: 1.2106 - acc: 0.5348 - val_loss: 1.1244 - val_acc: 0.5615\n",
      "Epoch 9/10\n",
      "22964/22964 [==============================] - 150s - loss: 1.2129 - acc: 0.5348 - val_loss: 1.1176 - val_acc: 0.5699\n",
      "Epoch 10/10\n",
      "22964/22964 [==============================] - 149s - loss: 1.2056 - acc: 0.5383 - val_loss: 1.1436 - val_acc: 0.5607\n",
      "EPOCH 201\n",
      "Train on 22968 samples, validate on 5741 samples\n",
      "Epoch 1/10\n",
      "22968/22968 [==============================] - 149s - loss: 1.2292 - acc: 0.5260 - val_loss: 1.0535 - val_acc: 0.6029\n",
      "Epoch 2/10\n",
      "22968/22968 [==============================] - 149s - loss: 1.2229 - acc: 0.5289 - val_loss: 1.0660 - val_acc: 0.6009\n",
      "Epoch 3/10\n",
      "22968/22968 [==============================] - 150s - loss: 1.2203 - acc: 0.5297 - val_loss: 1.0695 - val_acc: 0.5964\n",
      "Epoch 4/10\n",
      "22968/22968 [==============================] - 149s - loss: 1.2214 - acc: 0.5315 - val_loss: 1.0951 - val_acc: 0.5849\n",
      "Epoch 5/10\n",
      "22968/22968 [==============================] - 150s - loss: 1.2153 - acc: 0.5313 - val_loss: 1.1059 - val_acc: 0.5802\n",
      "Epoch 6/10\n",
      "22968/22968 [==============================] - 150s - loss: 1.2147 - acc: 0.5307 - val_loss: 1.1096 - val_acc: 0.578553\n",
      "Epoch 7/10\n",
      "22968/22968 [==============================] - 150s - loss: 1.2119 - acc: 0.5320 - val_loss: 1.0939 - val_acc: 0.5795\n",
      "Epoch 8/10\n",
      "22968/22968 [==============================] - 149s - loss: 1.2126 - acc: 0.5330 - val_loss: 1.1338 - val_acc: 0.5665\n",
      "Epoch 9/10\n",
      "22968/22968 [==============================] - 150s - loss: 1.2098 - acc: 0.5354 - val_loss: 1.1268 - val_acc: 0.5699\n",
      "Epoch 10/10\n",
      "22968/22968 [==============================] - 150s - loss: 1.2112 - acc: 0.5368 - val_loss: 1.1163 - val_acc: 0.5746\n",
      "EPOCH 211\n",
      "Train on 22968 samples, validate on 5741 samples\n",
      "Epoch 1/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.2117 - acc: 0.5379 - val_loss: 1.0643 - val_acc: 0.5989\n",
      "Epoch 2/10\n",
      "22968/22968 [==============================] - 150s - loss: 1.2164 - acc: 0.5369 - val_loss: 1.0986 - val_acc: 0.5820\n",
      "Epoch 3/10\n",
      "22968/22968 [==============================] - 150s - loss: 1.2191 - acc: 0.5320 - val_loss: 1.0798 - val_acc: 0.5870\n",
      "Epoch 4/10\n",
      "22968/22968 [==============================] - 150s - loss: 1.2120 - acc: 0.5339 - val_loss: 1.0760 - val_acc: 0.5891\n",
      "Epoch 5/10\n",
      "22968/22968 [==============================] - 150s - loss: 1.2085 - acc: 0.5340 - val_loss: 1.1046 - val_acc: 0.5811\n",
      "Epoch 6/10\n",
      "22968/22968 [==============================] - 150s - loss: 1.2032 - acc: 0.5398 - val_loss: 1.1152 - val_acc: 0.5785\n",
      "Epoch 7/10\n",
      "22968/22968 [==============================] - 150s - loss: 1.2086 - acc: 0.5381 - val_loss: 1.1029 - val_acc: 0.5839\n",
      "Epoch 8/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.2026 - acc: 0.5388 - val_loss: 1.1287 - val_acc: 0.5706\n",
      "Epoch 9/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.2067 - acc: 0.5393 - val_loss: 1.1124 - val_acc: 0.5741\n",
      "Epoch 10/10\n",
      "22968/22968 [==============================] - 150s - loss: 1.2042 - acc: 0.5392 - val_loss: 1.1556 - val_acc: 0.5668\n",
      "EPOCH 221\n",
      "Train on 22968 samples, validate on 5741 samples\n",
      "Epoch 1/10\n",
      "22968/22968 [==============================] - 150s - loss: 1.2240 - acc: 0.5272 - val_loss: 1.0469 - val_acc: 0.5989\n",
      "Epoch 2/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.2209 - acc: 0.5366 - val_loss: 1.0668 - val_acc: 0.5935\n",
      "Epoch 3/10\n",
      "22968/22968 [==============================] - 150s - loss: 1.2135 - acc: 0.5341 - val_loss: 1.0845 - val_acc: 0.5820\n",
      "Epoch 4/10\n",
      "22968/22968 [==============================] - 150s - loss: 1.2134 - acc: 0.5354 - val_loss: 1.0857 - val_acc: 0.5813\n",
      "Epoch 5/10\n",
      "22968/22968 [==============================] - 150s - loss: 1.2160 - acc: 0.5371 - val_loss: 1.1079 - val_acc: 0.5802\n",
      "Epoch 6/10\n",
      "22968/22968 [==============================] - 150s - loss: 1.2140 - acc: 0.5314 - val_loss: 1.0904 - val_acc: 0.5781\n",
      "Epoch 7/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.2116 - acc: 0.5375 - val_loss: 1.1194 - val_acc: 0.5759\n",
      "Epoch 8/10\n",
      "22968/22968 [==============================] - 150s - loss: 1.2065 - acc: 0.5369 - val_loss: 1.1021 - val_acc: 0.5809\n",
      "Epoch 9/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.2122 - acc: 0.5376 - val_loss: 1.1105 - val_acc: 0.5802\n",
      "Epoch 10/10\n",
      "22968/22968 [==============================] - 150s - loss: 1.2135 - acc: 0.5329 - val_loss: 1.1226 - val_acc: 0.5727\n",
      "EPOCH 231\n",
      "Train on 22968 samples, validate on 5741 samples\n",
      "Epoch 1/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.2140 - acc: 0.5343 - val_loss: 1.0560 - val_acc: 0.5945\n",
      "Epoch 2/10\n",
      "22968/22968 [==============================] - 150s - loss: 1.2121 - acc: 0.5322 - val_loss: 1.0826 - val_acc: 0.5875\n",
      "Epoch 3/10\n",
      "22968/22968 [==============================] - 150s - loss: 1.2143 - acc: 0.5313 - val_loss: 1.1061 - val_acc: 0.5846\n",
      "Epoch 4/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.2131 - acc: 0.5348 - val_loss: 1.0880 - val_acc: 0.5844\n",
      "Epoch 5/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.2086 - acc: 0.5376 - val_loss: 1.0974 - val_acc: 0.5851\n",
      "Epoch 6/10\n",
      "22968/22968 [==============================] - 150s - loss: 1.2131 - acc: 0.5320 - val_loss: 1.1042 - val_acc: 0.5846\n",
      "Epoch 7/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.2078 - acc: 0.5348 - val_loss: 1.0990 - val_acc: 0.5800\n",
      "Epoch 8/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.2119 - acc: 0.5352 - val_loss: 1.1262 - val_acc: 0.5665\n",
      "Epoch 9/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.2120 - acc: 0.5365 - val_loss: 1.1115 - val_acc: 0.5760\n",
      "Epoch 10/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.2051 - acc: 0.5375 - val_loss: 1.1063 - val_acc: 0.5769\n",
      "EPOCH 241\n",
      "Train on 22964 samples, validate on 5745 samples\n",
      "Epoch 1/10\n",
      "22964/22964 [==============================] - 149s - loss: 1.2183 - acc: 0.5331 - val_loss: 1.0483 - val_acc: 0.6002\n",
      "Epoch 2/10\n",
      "22964/22964 [==============================] - 150s - loss: 1.2069 - acc: 0.5404 - val_loss: 1.0886 - val_acc: 0.5795\n",
      "Epoch 3/10\n",
      "22964/22964 [==============================] - 149s - loss: 1.2071 - acc: 0.5381 - val_loss: 1.0676 - val_acc: 0.5976\n",
      "Epoch 4/10\n",
      "22964/22964 [==============================] - 149s - loss: 1.2113 - acc: 0.5384 - val_loss: 1.0862 - val_acc: 0.5779\n",
      "Epoch 5/10\n",
      "22964/22964 [==============================] - 150s - loss: 1.2062 - acc: 0.5394 - val_loss: 1.0848 - val_acc: 0.5803\n",
      "Epoch 6/10\n",
      "22964/22964 [==============================] - 151s - loss: 1.2043 - acc: 0.5363 - val_loss: 1.0901 - val_acc: 0.5835\n",
      "Epoch 7/10\n",
      "22964/22964 [==============================] - 149s - loss: 1.2035 - acc: 0.5385 - val_loss: 1.1226 - val_acc: 0.5591\n",
      "Epoch 8/10\n",
      "22964/22964 [==============================] - 150s - loss: 1.2007 - acc: 0.5388 - val_loss: 1.1033 - val_acc: 0.5732\n",
      "Epoch 9/10\n",
      "22964/22964 [==============================] - 149s - loss: 1.2080 - acc: 0.5396 - val_loss: 1.1093 - val_acc: 0.5758\n",
      "Epoch 10/10\n",
      "22964/22964 [==============================] - 150s - loss: 1.2010 - acc: 0.5392 - val_loss: 1.1159 - val_acc: 0.5727\n",
      "EPOCH 251\n",
      "Train on 22968 samples, validate on 5741 samples\n",
      "Epoch 1/10\n",
      "22968/22968 [==============================] - 150s - loss: 1.2189 - acc: 0.5352 - val_loss: 1.0448 - val_acc: 0.6069\n",
      "Epoch 2/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.2148 - acc: 0.5331 - val_loss: 1.0523 - val_acc: 0.6037\n",
      "Epoch 3/10\n",
      "22968/22968 [==============================] - 149s - loss: 1.2075 - acc: 0.5364 - val_loss: 1.0668 - val_acc: 0.5931\n",
      "Epoch 4/10\n",
      "22968/22968 [==============================] - 149s - loss: 1.2046 - acc: 0.5371 - val_loss: 1.0798 - val_acc: 0.5973\n",
      "Epoch 5/10\n",
      "22968/22968 [==============================] - 150s - loss: 1.2068 - acc: 0.5371 - val_loss: 1.0873 - val_acc: 0.5912\n",
      "Epoch 6/10\n",
      "22968/22968 [==============================] - 150s - loss: 1.2086 - acc: 0.5345 - val_loss: 1.0864 - val_acc: 0.5891\n",
      "Epoch 7/10\n",
      "22968/22968 [==============================] - 150s - loss: 1.2029 - acc: 0.5378 - val_loss: 1.0868 - val_acc: 0.5844\n",
      "Epoch 8/10\n",
      "22968/22968 [==============================] - 150s - loss: 1.2054 - acc: 0.5399 - val_loss: 1.0879 - val_acc: 0.5874\n",
      "Epoch 9/10\n",
      "22968/22968 [==============================] - 150s - loss: 1.1981 - acc: 0.5411 - val_loss: 1.0873 - val_acc: 0.5867\n",
      "Epoch 10/10\n",
      "22968/22968 [==============================] - 149s - loss: 1.2050 - acc: 0.5364 - val_loss: 1.1017 - val_acc: 0.5809\n",
      "EPOCH 261\n",
      "Train on 22968 samples, validate on 5741 samples\n",
      "Epoch 1/10\n",
      "22968/22968 [==============================] - 149s - loss: 1.2093 - acc: 0.5365 - val_loss: 1.0789 - val_acc: 0.5912\n",
      "Epoch 2/10\n",
      "22968/22968 [==============================] - 150s - loss: 1.2060 - acc: 0.5358 - val_loss: 1.0789 - val_acc: 0.5907\n",
      "Epoch 3/10\n",
      "22968/22968 [==============================] - 150s - loss: 1.2084 - acc: 0.5372 - val_loss: 1.1093 - val_acc: 0.5769\n",
      "Epoch 4/10\n",
      "22968/22968 [==============================] - 150s - loss: 1.2028 - acc: 0.5368 - val_loss: 1.0977 - val_acc: 0.5797\n",
      "Epoch 5/10\n",
      "22968/22968 [==============================] - 150s - loss: 1.1951 - acc: 0.5416 - val_loss: 1.0935 - val_acc: 0.5767\n",
      "Epoch 6/10\n",
      "22968/22968 [==============================] - 150s - loss: 1.2017 - acc: 0.5431 - val_loss: 1.1104 - val_acc: 0.5755\n",
      "Epoch 7/10\n",
      "22968/22968 [==============================] - 150s - loss: 1.1998 - acc: 0.5415 - val_loss: 1.1015 - val_acc: 0.5773\n",
      "Epoch 8/10\n",
      "22968/22968 [==============================] - 150s - loss: 1.2013 - acc: 0.5394 - val_loss: 1.0962 - val_acc: 0.5785\n",
      "Epoch 9/10\n",
      "22968/22968 [==============================] - 150s - loss: 1.1992 - acc: 0.5405 - val_loss: 1.0978 - val_acc: 0.5827\n",
      "Epoch 10/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.1940 - acc: 0.5434 - val_loss: 1.1224 - val_acc: 0.5785\n",
      "EPOCH 271\n",
      "Train on 22968 samples, validate on 5741 samples\n",
      "Epoch 1/10\n",
      "22968/22968 [==============================] - 150s - loss: 1.2062 - acc: 0.5405 - val_loss: 1.0424 - val_acc: 0.6006\n",
      "Epoch 2/10\n",
      "22968/22968 [==============================] - 150s - loss: 1.2063 - acc: 0.5350 - val_loss: 1.0472 - val_acc: 0.6032\n",
      "Epoch 3/10\n",
      "22968/22968 [==============================] - 150s - loss: 1.2021 - acc: 0.5406 - val_loss: 1.0565 - val_acc: 0.5931\n",
      "Epoch 4/10\n",
      "22968/22968 [==============================] - 150s - loss: 1.2000 - acc: 0.5370 - val_loss: 1.0730 - val_acc: 0.5882\n",
      "Epoch 5/10\n",
      "22968/22968 [==============================] - 150s - loss: 1.2041 - acc: 0.5379 - val_loss: 1.0898 - val_acc: 0.5840\n",
      "Epoch 6/10\n",
      "22968/22968 [==============================] - 150s - loss: 1.1983 - acc: 0.5386 - val_loss: 1.0827 - val_acc: 0.5851\n",
      "Epoch 7/10\n",
      "22968/22968 [==============================] - 150s - loss: 1.2048 - acc: 0.5384 - val_loss: 1.0840 - val_acc: 0.5882\n",
      "Epoch 8/10\n",
      "22968/22968 [==============================] - 150s - loss: 1.2035 - acc: 0.5391 - val_loss: 1.0714 - val_acc: 0.5924\n",
      "Epoch 9/10\n",
      "22968/22968 [==============================] - 150s - loss: 1.1974 - acc: 0.5404 - val_loss: 1.0987 - val_acc: 0.5769\n",
      "Epoch 10/10\n",
      "22968/22968 [==============================] - 150s - loss: 1.2014 - acc: 0.5376 - val_loss: 1.0910 - val_acc: 0.5907\n",
      "EPOCH 281\n",
      "Train on 22968 samples, validate on 5741 samples\n",
      "Epoch 1/10\n",
      "22968/22968 [==============================] - 150s - loss: 1.2115 - acc: 0.5367 - val_loss: 1.0417 - val_acc: 0.6039\n",
      "Epoch 2/10\n",
      "22968/22968 [==============================] - 150s - loss: 1.2075 - acc: 0.5382 - val_loss: 1.0497 - val_acc: 0.5980\n",
      "Epoch 3/10\n",
      "22968/22968 [==============================] - 150s - loss: 1.2003 - acc: 0.5414 - val_loss: 1.0735 - val_acc: 0.5875\n",
      "Epoch 4/10\n",
      "22968/22968 [==============================] - 150s - loss: 1.1980 - acc: 0.5421 - val_loss: 1.0634 - val_acc: 0.5935\n",
      "Epoch 5/10\n",
      "22968/22968 [==============================] - 150s - loss: 1.2008 - acc: 0.5382 - val_loss: 1.0716 - val_acc: 0.5924\n",
      "Epoch 6/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.1975 - acc: 0.5442 - val_loss: 1.0719 - val_acc: 0.5887\n",
      "Epoch 7/10\n",
      "22968/22968 [==============================] - 150s - loss: 1.2000 - acc: 0.5396 - val_loss: 1.0946 - val_acc: 0.5795\n",
      "Epoch 8/10\n",
      "22968/22968 [==============================] - 150s - loss: 1.1960 - acc: 0.5435 - val_loss: 1.0982 - val_acc: 0.5842\n",
      "Epoch 9/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.1995 - acc: 0.5425 - val_loss: 1.0929 - val_acc: 0.5804\n",
      "Epoch 10/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.1937 - acc: 0.5449 - val_loss: 1.1242 - val_acc: 0.5684\n",
      "EPOCH 291\n",
      "Train on 22964 samples, validate on 5745 samples\n",
      "Epoch 1/10\n",
      "22964/22964 [==============================] - 150s - loss: 1.2067 - acc: 0.5385 - val_loss: 1.0502 - val_acc: 0.5981\n",
      "Epoch 2/10\n",
      "22964/22964 [==============================] - 151s - loss: 1.2077 - acc: 0.5351 - val_loss: 1.0611 - val_acc: 0.5906\n",
      "Epoch 3/10\n",
      "22964/22964 [==============================] - 151s - loss: 1.1979 - acc: 0.5409 - val_loss: 1.0676 - val_acc: 0.5880\n",
      "Epoch 4/10\n",
      "22964/22964 [==============================] - 152s - loss: 1.2008 - acc: 0.5415 - val_loss: 1.0550 - val_acc: 0.6009\n",
      "Epoch 5/10\n",
      "22964/22964 [==============================] - 151s - loss: 1.1996 - acc: 0.5390 - val_loss: 1.0865 - val_acc: 0.5781\n",
      "Epoch 6/10\n",
      "22964/22964 [==============================] - 150s - loss: 1.1995 - acc: 0.5408 - val_loss: 1.0906 - val_acc: 0.5826\n",
      "Epoch 7/10\n",
      "22964/22964 [==============================] - 151s - loss: 1.1962 - acc: 0.5422 - val_loss: 1.0886 - val_acc: 0.5782.1978 - acc: - ETA: 9s -  - ETA: 4s - loss:\n",
      "Epoch 8/10\n",
      "22964/22964 [==============================] - 151s - loss: 1.1961 - acc: 0.5443 - val_loss: 1.0953 - val_acc: 0.5765\n",
      "Epoch 9/10\n",
      "22964/22964 [==============================] - 151s - loss: 1.2016 - acc: 0.5396 - val_loss: 1.1083 - val_acc: 0.5706\n",
      "Epoch 10/10\n",
      "22964/22964 [==============================] - 151s - loss: 1.1968 - acc: 0.5413 - val_loss: 1.1028 - val_acc: 0.5800\n",
      "EPOCH 301\n",
      "Train on 22968 samples, validate on 5741 samples\n",
      "Epoch 1/10\n",
      "22968/22968 [==============================] - 149s - loss: 1.2065 - acc: 0.5380 - val_loss: 1.0252 - val_acc: 0.6137\n",
      "Epoch 2/10\n",
      "22968/22968 [==============================] - 149s - loss: 1.2096 - acc: 0.5372 - val_loss: 1.0469 - val_acc: 0.6046\n",
      "Epoch 3/10\n",
      "22968/22968 [==============================] - 149s - loss: 1.2005 - acc: 0.5396 - val_loss: 1.0699 - val_acc: 0.5954\n",
      "Epoch 4/10\n",
      "22968/22968 [==============================] - 149s - loss: 1.2004 - acc: 0.5373 - val_loss: 1.0827 - val_acc: 0.5898\n",
      "Epoch 5/10\n",
      "22968/22968 [==============================] - 149s - loss: 1.2009 - acc: 0.5422 - val_loss: 1.0780 - val_acc: 0.5941\n",
      "Epoch 6/10\n",
      "22968/22968 [==============================] - 150s - loss: 1.1987 - acc: 0.5401 - val_loss: 1.0811 - val_acc: 0.5905\n",
      "Epoch 7/10\n",
      "22968/22968 [==============================] - 149s - loss: 1.1905 - acc: 0.5435 - val_loss: 1.0846 - val_acc: 0.5865\n",
      "Epoch 8/10\n",
      "22968/22968 [==============================] - 149s - loss: 1.1955 - acc: 0.5399 - val_loss: 1.0843 - val_acc: 0.5881\n",
      "Epoch 9/10\n",
      "22968/22968 [==============================] - 149s - loss: 1.1969 - acc: 0.5384 - val_loss: 1.0923 - val_acc: 0.5797\n",
      "Epoch 10/10\n",
      "22968/22968 [==============================] - 150s - loss: 1.1975 - acc: 0.5395 - val_loss: 1.0838 - val_acc: 0.5886\n",
      "EPOCH 311\n",
      "Train on 22968 samples, validate on 5741 samples\n",
      "Epoch 1/10\n",
      "22968/22968 [==============================] - 149s - loss: 1.2064 - acc: 0.5342 - val_loss: 1.0507 - val_acc: 0.6023\n",
      "Epoch 2/10\n",
      "22968/22968 [==============================] - 149s - loss: 1.2031 - acc: 0.5409 - val_loss: 1.0577 - val_acc: 0.6008\n",
      "Epoch 3/10\n",
      "22968/22968 [==============================] - 157s - loss: 1.1944 - acc: 0.5417 - val_loss: 1.0766 - val_acc: 0.5846\n",
      "Epoch 4/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.1959 - acc: 0.5435 - val_loss: 1.0761 - val_acc: 0.5929\n",
      "Epoch 5/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.1916 - acc: 0.5456 - val_loss: 1.1015 - val_acc: 0.5832\n",
      "Epoch 6/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.1968 - acc: 0.5398 - val_loss: 1.1124 - val_acc: 0.5722\n",
      "Epoch 7/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.1910 - acc: 0.5475 - val_loss: 1.1039 - val_acc: 0.5790\n",
      "Epoch 8/10\n",
      "22968/22968 [==============================] - 154s - loss: 1.1910 - acc: 0.5467 - val_loss: 1.0928 - val_acc: 0.5844\n",
      "Epoch 9/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.1875 - acc: 0.5473 - val_loss: 1.1082 - val_acc: 0.5750\n",
      "Epoch 10/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.1905 - acc: 0.5417 - val_loss: 1.1082 - val_acc: 0.5783\n",
      "EPOCH 321\n",
      "Train on 22968 samples, validate on 5741 samples\n",
      "Epoch 1/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.2119 - acc: 0.5350 - val_loss: 1.0297 - val_acc: 0.6067\n",
      "Epoch 2/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.1995 - acc: 0.5401 - val_loss: 1.0246 - val_acc: 0.6088\n",
      "Epoch 3/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.1950 - acc: 0.5406 - val_loss: 1.0619 - val_acc: 0.5982\n",
      "Epoch 4/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.1990 - acc: 0.5400 - val_loss: 1.0486 - val_acc: 0.5971\n",
      "Epoch 5/10\n",
      "22968/22968 [==============================] - 154s - loss: 1.1958 - acc: 0.5396 - val_loss: 1.0533 - val_acc: 0.5945\n",
      "Epoch 6/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.1981 - acc: 0.5425 - val_loss: 1.0609 - val_acc: 0.5922\n",
      "Epoch 7/10\n",
      "22968/22968 [==============================] - 153s - loss: 1.1966 - acc: 0.5424 - val_loss: 1.0745 - val_acc: 0.5952\n",
      "Epoch 8/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.1996 - acc: 0.5377 - val_loss: 1.0773 - val_acc: 0.5900\n",
      "Epoch 9/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.1932 - acc: 0.5393 - val_loss: 1.0779 - val_acc: 0.5907\n",
      "Epoch 10/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.1924 - acc: 0.5441 - val_loss: 1.1016 - val_acc: 0.5799\n",
      "EPOCH 331\n",
      "Train on 22968 samples, validate on 5741 samples\n",
      "Epoch 1/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.1966 - acc: 0.5409 - val_loss: 1.0362 - val_acc: 0.6013\n",
      "Epoch 2/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.1970 - acc: 0.5395 - val_loss: 1.0569 - val_acc: 0.5901\n",
      "Epoch 3/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.1911 - acc: 0.5451 - val_loss: 1.0729 - val_acc: 0.5894\n",
      "Epoch 4/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.1931 - acc: 0.5394 - val_loss: 1.0786 - val_acc: 0.5891\n",
      "Epoch 5/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.1901 - acc: 0.5458 - val_loss: 1.0719 - val_acc: 0.5861\n",
      "Epoch 6/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.1942 - acc: 0.5420 - val_loss: 1.0659 - val_acc: 0.5966\n",
      "Epoch 7/10\n",
      "22968/22968 [==============================] - 153s - loss: 1.1925 - acc: 0.5448 - val_loss: 1.0869 - val_acc: 0.5839\n",
      "Epoch 8/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.1927 - acc: 0.5421 - val_loss: 1.0853 - val_acc: 0.5891\n",
      "Epoch 9/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.1888 - acc: 0.5459 - val_loss: 1.1076 - val_acc: 0.5762\n",
      "Epoch 10/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.1877 - acc: 0.5456 - val_loss: 1.0914 - val_acc: 0.5813\n",
      "EPOCH 341\n",
      "Train on 22964 samples, validate on 5745 samples\n",
      "Epoch 1/10\n",
      "22964/22964 [==============================] - 153s - loss: 1.1984 - acc: 0.5422 - val_loss: 1.0218 - val_acc: 0.6110\n",
      "Epoch 2/10\n",
      "22964/22964 [==============================] - 152s - loss: 1.1955 - acc: 0.5411 - val_loss: 1.0573 - val_acc: 0.5923\n",
      "Epoch 3/10\n",
      "22964/22964 [==============================] - 152s - loss: 1.1961 - acc: 0.5445 - val_loss: 1.0441 - val_acc: 0.6030\n",
      "Epoch 4/10\n",
      "22964/22964 [==============================] - 152s - loss: 1.1947 - acc: 0.5435 - val_loss: 1.0882 - val_acc: 0.5850\n",
      "Epoch 5/10\n",
      "22964/22964 [==============================] - 152s - loss: 1.1944 - acc: 0.5412 - val_loss: 1.0633 - val_acc: 0.5890\n",
      "Epoch 6/10\n",
      "22964/22964 [==============================] - 152s - loss: 1.1894 - acc: 0.5449 - val_loss: 1.0881 - val_acc: 0.5793\n",
      "Epoch 7/10\n",
      "22964/22964 [==============================] - 152s - loss: 1.1827 - acc: 0.5484 - val_loss: 1.0926 - val_acc: 0.5810\n",
      "Epoch 8/10\n",
      "22964/22964 [==============================] - 152s - loss: 1.1851 - acc: 0.5462 - val_loss: 1.0891 - val_acc: 0.5852\n",
      "Epoch 9/10\n",
      "22964/22964 [==============================] - 152s - loss: 1.1861 - acc: 0.5469 - val_loss: 1.0821 - val_acc: 0.5807\n",
      "Epoch 10/10\n",
      "22964/22964 [==============================] - 152s - loss: 1.1824 - acc: 0.5428 - val_loss: 1.0840 - val_acc: 0.5857\n",
      "EPOCH 351\n",
      "Train on 22968 samples, validate on 5741 samples\n",
      "Epoch 1/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.2009 - acc: 0.5396 - val_loss: 1.0336 - val_acc: 0.6086\n",
      "Epoch 2/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.1994 - acc: 0.5458 - val_loss: 1.0570 - val_acc: 0.5980\n",
      "Epoch 3/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.1915 - acc: 0.5436 - val_loss: 1.0611 - val_acc: 0.5947\n",
      "Epoch 4/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.1916 - acc: 0.5428 - val_loss: 1.0613 - val_acc: 0.5943\n",
      "Epoch 5/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.1905 - acc: 0.5435 - val_loss: 1.0684 - val_acc: 0.5907\n",
      "Epoch 6/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.1868 - acc: 0.5494 - val_loss: 1.0708 - val_acc: 0.5987\n",
      "Epoch 7/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.1858 - acc: 0.5448 - val_loss: 1.0814 - val_acc: 0.5853\n",
      "Epoch 8/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.1920 - acc: 0.5456 - val_loss: 1.0943 - val_acc: 0.5800\n",
      "Epoch 9/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.1938 - acc: 0.5412 - val_loss: 1.0830 - val_acc: 0.5931\n",
      "Epoch 10/10\n",
      "22968/22968 [==============================] - 155s - loss: 1.1847 - acc: 0.5451 - val_loss: 1.0846 - val_acc: 0.5868\n",
      "EPOCH 361\n",
      "Train on 22968 samples, validate on 5741 samples\n",
      "Epoch 1/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.1945 - acc: 0.5412 - val_loss: 1.0664 - val_acc: 0.5914\n",
      "Epoch 2/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.1941 - acc: 0.5414 - val_loss: 1.0432 - val_acc: 0.6027\n",
      "Epoch 3/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.1939 - acc: 0.5466 - val_loss: 1.1070 - val_acc: 0.5766\n",
      "Epoch 4/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.1925 - acc: 0.5397 - val_loss: 1.0696 - val_acc: 0.5950\n",
      "Epoch 5/10\n",
      "22968/22968 [==============================] - 153s - loss: 1.1933 - acc: 0.5468 - val_loss: 1.0919 - val_acc: 0.5786\n",
      "Epoch 6/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.1875 - acc: 0.5468 - val_loss: 1.1000 - val_acc: 0.5821\n",
      "Epoch 7/10\n",
      "22968/22968 [==============================] - 150s - loss: 1.1840 - acc: 0.5461 - val_loss: 1.0901 - val_acc: 0.5887\n",
      "Epoch 8/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.1896 - acc: 0.5439 - val_loss: 1.1145 - val_acc: 0.5764\n",
      "Epoch 9/10\n",
      "22968/22968 [==============================] - 153s - loss: 1.1822 - acc: 0.5479 - val_loss: 1.1026 - val_acc: 0.5849\n",
      "Epoch 10/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.1804 - acc: 0.5482 - val_loss: 1.1048 - val_acc: 0.5797\n",
      "EPOCH 371\n",
      "Train on 22968 samples, validate on 5741 samples\n",
      "Epoch 1/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.1988 - acc: 0.5416 - val_loss: 1.0197 - val_acc: 0.6149\n",
      "Epoch 2/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.1980 - acc: 0.5402 - val_loss: 1.0333 - val_acc: 0.6039\n",
      "Epoch 3/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.1910 - acc: 0.5477 - val_loss: 1.0732 - val_acc: 0.5959\n",
      "Epoch 4/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.1928 - acc: 0.5422 - val_loss: 1.0548 - val_acc: 0.6001\n",
      "Epoch 5/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.1913 - acc: 0.5439 - val_loss: 1.0381 - val_acc: 0.5983\n",
      "Epoch 6/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.1948 - acc: 0.5435 - val_loss: 1.0546 - val_acc: 0.5907\n",
      "Epoch 7/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.1873 - acc: 0.5433 - val_loss: 1.0765 - val_acc: 0.5823\n",
      "Epoch 8/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.1858 - acc: 0.5489 - val_loss: 1.0772 - val_acc: 0.5910\n",
      "Epoch 9/10\n",
      "22968/22968 [==============================] - 153s - loss: 1.1882 - acc: 0.5465 - val_loss: 1.0771 - val_acc: 0.5863\n",
      "Epoch 10/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.1829 - acc: 0.5441 - val_loss: 1.0690 - val_acc: 0.5907\n",
      "EPOCH 381\n",
      "Train on 22968 samples, validate on 5741 samples\n",
      "Epoch 1/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.2027 - acc: 0.5393 - val_loss: 1.0247 - val_acc: 0.6098\n",
      "Epoch 2/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.1932 - acc: 0.5469 - val_loss: 1.0280 - val_acc: 0.6072\n",
      "Epoch 3/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.1911 - acc: 0.5415 - val_loss: 1.0489 - val_acc: 0.6036\n",
      "Epoch 4/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.1887 - acc: 0.5468 - val_loss: 1.0742 - val_acc: 0.5889\n",
      "Epoch 5/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.1888 - acc: 0.5455 - val_loss: 1.0360 - val_acc: 0.6070\n",
      "Epoch 6/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.1902 - acc: 0.5449 - val_loss: 1.0750 - val_acc: 0.5891\n",
      "Epoch 7/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.1904 - acc: 0.5443 - val_loss: 1.0837 - val_acc: 0.5874\n",
      "Epoch 8/10\n",
      "22968/22968 [==============================] - 153s - loss: 1.1880 - acc: 0.5468 - val_loss: 1.0858 - val_acc: 0.5828\n",
      "Epoch 9/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.1946 - acc: 0.5439 - val_loss: 1.1224 - val_acc: 0.5701\n",
      "Epoch 10/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.1896 - acc: 0.5445 - val_loss: 1.0891 - val_acc: 0.5816\n",
      "EPOCH 391\n",
      "Train on 22964 samples, validate on 5745 samples\n",
      "Epoch 1/10\n",
      "22964/22964 [==============================] - 151s - loss: 1.1912 - acc: 0.5455 - val_loss: 1.0229 - val_acc: 0.6085\n",
      "Epoch 2/10\n",
      "22964/22964 [==============================] - 153s - loss: 1.1953 - acc: 0.5406 - val_loss: 1.0405 - val_acc: 0.6012\n",
      "Epoch 3/10\n",
      "22964/22964 [==============================] - 152s - loss: 1.1897 - acc: 0.5456 - val_loss: 1.0488 - val_acc: 0.5963\n",
      "Epoch 4/10\n",
      "22964/22964 [==============================] - 151s - loss: 1.1904 - acc: 0.5455 - val_loss: 1.0439 - val_acc: 0.5981\n",
      "Epoch 5/10\n",
      "22964/22964 [==============================] - 152s - loss: 1.1919 - acc: 0.5455 - val_loss: 1.0510 - val_acc: 0.5962\n",
      "Epoch 6/10\n",
      "22964/22964 [==============================] - 152s - loss: 1.1912 - acc: 0.5457 - val_loss: 1.0939 - val_acc: 0.5793\n",
      "Epoch 7/10\n",
      "22964/22964 [==============================] - 152s - loss: 1.1829 - acc: 0.5518 - val_loss: 1.0863 - val_acc: 0.5734\n",
      "Epoch 8/10\n",
      "22964/22964 [==============================] - 152s - loss: 1.1823 - acc: 0.5463 - val_loss: 1.0986 - val_acc: 0.5768\n",
      "Epoch 9/10\n",
      "22964/22964 [==============================] - 152s - loss: 1.1840 - acc: 0.5469 - val_loss: 1.1063 - val_acc: 0.5762\n",
      "Epoch 10/10\n",
      "22964/22964 [==============================] - 152s - loss: 1.1822 - acc: 0.5463 - val_loss: 1.1080 - val_acc: 0.5768\n",
      "EPOCH 401\n",
      "Train on 22968 samples, validate on 5741 samples\n",
      "Epoch 1/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.1973 - acc: 0.5455 - val_loss: 1.0139 - val_acc: 0.6224\n",
      "Epoch 2/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.1938 - acc: 0.5428 - val_loss: 1.0540 - val_acc: 0.600654\n",
      "Epoch 3/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.1937 - acc: 0.5403 - val_loss: 1.0495 - val_acc: 0.6013\n",
      "Epoch 4/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.1934 - acc: 0.5453 - val_loss: 1.0418 - val_acc: 0.6098\n",
      "Epoch 5/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.1851 - acc: 0.5454 - val_loss: 1.0493 - val_acc: 0.5999545\n",
      "Epoch 6/10\n",
      "22968/22968 [==============================] - 155s - loss: 1.1888 - acc: 0.5438 - val_loss: 1.0415 - val_acc: 0.6048\n",
      "Epoch 7/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.1897 - acc: 0.5419 - val_loss: 1.0449 - val_acc: 0.6036\n",
      "Epoch 8/10\n",
      "22968/22968 [==============================] - 153s - loss: 1.1890 - acc: 0.5449 - val_loss: 1.0672 - val_acc: 0.5952\n",
      "Epoch 9/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.1877 - acc: 0.5438 - val_loss: 1.0765 - val_acc: 0.5936\n",
      "Epoch 10/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.1763 - acc: 0.5489 - val_loss: 1.0654 - val_acc: 0.5982\n",
      "EPOCH 411\n",
      "Train on 22968 samples, validate on 5741 samples\n",
      "Epoch 1/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.1929 - acc: 0.5404 - val_loss: 1.0430 - val_acc: 0.6069\n",
      "Epoch 2/10\n",
      "22968/22968 [==============================] - 154s - loss: 1.1902 - acc: 0.5438 - val_loss: 1.0443 - val_acc: 0.5954\n",
      "Epoch 3/10\n",
      "22968/22968 [==============================] - 154s - loss: 1.1891 - acc: 0.5445 - val_loss: 1.0719 - val_acc: 0.5940\n",
      "Epoch 4/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.1850 - acc: 0.5459 - val_loss: 1.0524 - val_acc: 0.5973\n",
      "Epoch 5/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.1829 - acc: 0.5473 - val_loss: 1.0871 - val_acc: 0.5811\n",
      "Epoch 6/10\n",
      "22968/22968 [==============================] - 153s - loss: 1.1787 - acc: 0.5480 - val_loss: 1.0815 - val_acc: 0.5898\n",
      "Epoch 7/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.1854 - acc: 0.5456 - val_loss: 1.1116 - val_acc: 0.5800\n",
      "Epoch 8/10\n",
      "22968/22968 [==============================] - 153s - loss: 1.1821 - acc: 0.5450 - val_loss: 1.0948 - val_acc: 0.5833\n",
      "Epoch 9/10\n",
      "22968/22968 [==============================] - 154s - loss: 1.1762 - acc: 0.5522 - val_loss: 1.0837 - val_acc: 0.5867\n",
      "Epoch 10/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.1784 - acc: 0.5509 - val_loss: 1.0885 - val_acc: 0.5863\n",
      "EPOCH 421\n",
      "Train on 22968 samples, validate on 5741 samples\n",
      "Epoch 1/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.1912 - acc: 0.5416 - val_loss: 1.0116 - val_acc: 0.6110\n",
      "Epoch 2/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.1938 - acc: 0.5425 - val_loss: 1.0351 - val_acc: 0.6088\n",
      "Epoch 3/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.1839 - acc: 0.5438 - val_loss: 1.0398 - val_acc: 0.6076\n",
      "Epoch 4/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.1865 - acc: 0.5456 - val_loss: 1.0369 - val_acc: 0.6072\n",
      "Epoch 5/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.1840 - acc: 0.5460 - val_loss: 1.0483 - val_acc: 0.6049\n",
      "Epoch 6/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.1855 - acc: 0.5469 - val_loss: 1.0396 - val_acc: 0.6043\n",
      "Epoch 7/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.1763 - acc: 0.5438 - val_loss: 1.0526 - val_acc: 0.5999\n",
      "Epoch 8/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.1865 - acc: 0.5434 - val_loss: 1.0651 - val_acc: 0.5917\n",
      "Epoch 9/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.1813 - acc: 0.5480 - val_loss: 1.0858 - val_acc: 0.5846\n",
      "Epoch 10/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.1870 - acc: 0.5445 - val_loss: 1.0811 - val_acc: 0.5865\n",
      "EPOCH 431\n",
      "Train on 22968 samples, validate on 5741 samples\n",
      "Epoch 1/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.1946 - acc: 0.5475 - val_loss: 1.0162 - val_acc: 0.6133\n",
      "Epoch 2/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.1822 - acc: 0.5488 - val_loss: 1.0453 - val_acc: 0.6030\n",
      "Epoch 3/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.1918 - acc: 0.5436 - val_loss: 1.0505 - val_acc: 0.5999\n",
      "Epoch 4/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.1844 - acc: 0.5498 - val_loss: 1.0363 - val_acc: 0.6069\n",
      "Epoch 5/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.1805 - acc: 0.5497 - val_loss: 1.0711 - val_acc: 0.5908\n",
      "Epoch 6/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.1844 - acc: 0.5460 - val_loss: 1.0595 - val_acc: 0.5990\n",
      "Epoch 7/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.1824 - acc: 0.5444 - val_loss: 1.0619 - val_acc: 0.5959\n",
      "Epoch 8/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.1818 - acc: 0.5478 - val_loss: 1.0732 - val_acc: 0.5924\n",
      "Epoch 9/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.1855 - acc: 0.5435 - val_loss: 1.0867 - val_acc: 0.5856\n",
      "Epoch 10/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.1780 - acc: 0.5487 - val_loss: 1.0618 - val_acc: 0.5935\n",
      "EPOCH 441\n",
      "Train on 22964 samples, validate on 5745 samples\n",
      "Epoch 1/10\n",
      "22964/22964 [==============================] - 151s - loss: 1.1925 - acc: 0.5484 - val_loss: 1.0102 - val_acc: 0.6134\n",
      "Epoch 2/10\n",
      "22964/22964 [==============================] - 151s - loss: 1.1897 - acc: 0.5474 - val_loss: 1.0317 - val_acc: 0.5976\n",
      "Epoch 3/10\n",
      "22964/22964 [==============================] - 151s - loss: 1.1900 - acc: 0.5441 - val_loss: 1.0540 - val_acc: 0.5984\n",
      "Epoch 4/10\n",
      "22964/22964 [==============================] - 151s - loss: 1.1827 - acc: 0.5466 - val_loss: 1.0351 - val_acc: 0.6084\n",
      "Epoch 5/10\n",
      "22964/22964 [==============================] - 151s - loss: 1.1839 - acc: 0.5467 - val_loss: 1.0876 - val_acc: 0.5748\n",
      "Epoch 6/10\n",
      "22964/22964 [==============================] - 152s - loss: 1.1826 - acc: 0.5514 - val_loss: 1.0559 - val_acc: 0.5903\n",
      "Epoch 7/10\n",
      "22964/22964 [==============================] - 151s - loss: 1.1819 - acc: 0.5493 - val_loss: 1.1089 - val_acc: 0.5683\n",
      "Epoch 8/10\n",
      "22964/22964 [==============================] - 151s - loss: 1.1843 - acc: 0.5518 - val_loss: 1.0675 - val_acc: 0.5897\n",
      "Epoch 9/10\n",
      "22964/22964 [==============================] - 151s - loss: 1.1810 - acc: 0.5486 - val_loss: 1.0783 - val_acc: 0.5802\n",
      "Epoch 10/10\n",
      "22964/22964 [==============================] - 151s - loss: 1.1796 - acc: 0.5436 - val_loss: 1.0729 - val_acc: 0.5854\n",
      "EPOCH 451\n",
      "Train on 22968 samples, validate on 5741 samples\n",
      "Epoch 1/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.1877 - acc: 0.5455 - val_loss: 1.0105 - val_acc: 0.6154\n",
      "Epoch 2/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.1900 - acc: 0.5440 - val_loss: 1.0281 - val_acc: 0.6056\n",
      "Epoch 3/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.1855 - acc: 0.5449 - val_loss: 1.0442 - val_acc: 0.6036\n",
      "Epoch 4/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.1836 - acc: 0.5494 - val_loss: 1.0563 - val_acc: 0.6036\n",
      "Epoch 5/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.1877 - acc: 0.5438 - val_loss: 1.0435 - val_acc: 0.6098\n",
      "Epoch 6/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.1847 - acc: 0.5450 - val_loss: 1.0495 - val_acc: 0.6022\n",
      "Epoch 7/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.1818 - acc: 0.5475 - val_loss: 1.0694 - val_acc: 0.5973\n",
      "Epoch 8/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.1839 - acc: 0.5478 - val_loss: 1.0878 - val_acc: 0.5806\n",
      "Epoch 9/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.1802 - acc: 0.5495 - val_loss: 1.0710 - val_acc: 0.5900\n",
      "Epoch 10/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.1809 - acc: 0.5448 - val_loss: 1.0707 - val_acc: 0.5940\n",
      "EPOCH 461\n",
      "Train on 22968 samples, validate on 5741 samples\n",
      "Epoch 1/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.1892 - acc: 0.5472 - val_loss: 1.0556 - val_acc: 0.5983\n",
      "Epoch 2/10\n",
      "22968/22968 [==============================] - 153s - loss: 1.1869 - acc: 0.5450 - val_loss: 1.0356 - val_acc: 0.6079\n",
      "Epoch 3/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.1834 - acc: 0.5459 - val_loss: 1.0519 - val_acc: 0.5968\n",
      "Epoch 4/10\n",
      "22968/22968 [==============================] - 153s - loss: 1.1835 - acc: 0.5485 - val_loss: 1.0732 - val_acc: 0.5901\n",
      "Epoch 5/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.1787 - acc: 0.5501 - val_loss: 1.0897 - val_acc: 0.5868\n",
      "Epoch 6/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.1744 - acc: 0.5521 - val_loss: 1.0697 - val_acc: 0.5901\n",
      "Epoch 7/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.1771 - acc: 0.5495 - val_loss: 1.0685 - val_acc: 0.5915\n",
      "Epoch 8/10\n",
      "22968/22968 [==============================] - 153s - loss: 1.1848 - acc: 0.5462 - val_loss: 1.0966 - val_acc: 0.5804\n",
      "Epoch 9/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.1748 - acc: 0.5533 - val_loss: 1.0855 - val_acc: 0.5903\n",
      "Epoch 10/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.1748 - acc: 0.5516 - val_loss: 1.0829 - val_acc: 0.5889\n",
      "EPOCH 471\n",
      "Train on 22968 samples, validate on 5741 samples\n",
      "Epoch 1/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.1869 - acc: 0.5462 - val_loss: 1.0021 - val_acc: 0.6229\n",
      "Epoch 2/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.1888 - acc: 0.5434 - val_loss: 1.0135 - val_acc: 0.6150\n",
      "Epoch 3/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.1922 - acc: 0.5379 - val_loss: 1.0375 - val_acc: 0.6015\n",
      "Epoch 4/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.1872 - acc: 0.5456 - val_loss: 1.0373 - val_acc: 0.6055\n",
      "Epoch 5/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.1792 - acc: 0.5474 - val_loss: 1.0322 - val_acc: 0.6098\n",
      "Epoch 6/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.1859 - acc: 0.5468 - val_loss: 1.0566 - val_acc: 0.5936\n",
      "Epoch 7/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.1790 - acc: 0.5472 - val_loss: 1.0686 - val_acc: 0.5964\n",
      "Epoch 8/10\n",
      "22968/22968 [==============================] - 153s - loss: 1.1828 - acc: 0.5472 - val_loss: 1.0628 - val_acc: 0.5947\n",
      "Epoch 9/10\n",
      "22968/22968 [==============================] - 153s - loss: 1.1764 - acc: 0.5496 - val_loss: 1.0449 - val_acc: 0.6056\n",
      "Epoch 10/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.1842 - acc: 0.5497 - val_loss: 1.0527 - val_acc: 0.5982\n",
      "EPOCH 481\n",
      "Train on 22968 samples, validate on 5741 samples\n",
      "Epoch 1/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.1900 - acc: 0.5457 - val_loss: 1.0063 - val_acc: 0.6184\n",
      "Epoch 2/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.1842 - acc: 0.5497 - val_loss: 1.0342 - val_acc: 0.6056\n",
      "Epoch 3/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.1835 - acc: 0.5479 - val_loss: 1.0433 - val_acc: 0.5995\n",
      "Epoch 4/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.1803 - acc: 0.5482 - val_loss: 1.0278 - val_acc: 0.6128\n",
      "Epoch 5/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.1793 - acc: 0.5503 - val_loss: 1.0335 - val_acc: 0.6105\n",
      "Epoch 6/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.1808 - acc: 0.5504 - val_loss: 1.0500 - val_acc: 0.5976\n",
      "Epoch 7/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.1748 - acc: 0.5529 - val_loss: 1.0694 - val_acc: 0.5948\n",
      "Epoch 8/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.1788 - acc: 0.5491 - val_loss: 1.0651 - val_acc: 0.5955\n",
      "Epoch 9/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.1789 - acc: 0.5496 - val_loss: 1.0800 - val_acc: 0.5900\n",
      "Epoch 10/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.1755 - acc: 0.5499 - val_loss: 1.0620 - val_acc: 0.5961\n",
      "EPOCH 491\n",
      "Train on 22964 samples, validate on 5745 samples\n",
      "Epoch 1/10\n",
      "22964/22964 [==============================] - 151s - loss: 1.1954 - acc: 0.5442 - val_loss: 1.0213 - val_acc: 0.603354\n",
      "Epoch 2/10\n",
      "22964/22964 [==============================] - 151s - loss: 1.1810 - acc: 0.5459 - val_loss: 1.0295 - val_acc: 0.6080\n",
      "Epoch 3/10\n",
      "22964/22964 [==============================] - 151s - loss: 1.1817 - acc: 0.5509 - val_loss: 1.0205 - val_acc: 0.6064\n",
      "Epoch 4/10\n",
      "22964/22964 [==============================] - 151s - loss: 1.1831 - acc: 0.5509 - val_loss: 1.0373 - val_acc: 0.5922\n",
      "Epoch 5/10\n",
      "22964/22964 [==============================] - 151s - loss: 1.1740 - acc: 0.5537 - val_loss: 1.0474 - val_acc: 0.6033\n",
      "Epoch 6/10\n",
      "22964/22964 [==============================] - 151s - loss: 1.1808 - acc: 0.5462 - val_loss: 1.0703 - val_acc: 0.5922\n",
      "Epoch 7/10\n",
      "22964/22964 [==============================] - 151s - loss: 1.1732 - acc: 0.5518 - val_loss: 1.0541 - val_acc: 0.6002\n",
      "Epoch 8/10\n",
      "22964/22964 [==============================] - 151s - loss: 1.1775 - acc: 0.5521 - val_loss: 1.0591 - val_acc: 0.5890\n",
      "Epoch 9/10\n",
      "22964/22964 [==============================] - 151s - loss: 1.1739 - acc: 0.5528 - val_loss: 1.0767 - val_acc: 0.5882\n",
      "Epoch 10/10\n",
      "22964/22964 [==============================] - 151s - loss: 1.1770 - acc: 0.5504 - val_loss: 1.0751 - val_acc: 0.5869\n",
      "EPOCH 501\n",
      "Train on 22968 samples, validate on 5741 samples\n",
      "Epoch 1/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.1840 - acc: 0.5437 - val_loss: 1.0060 - val_acc: 0.6224\n",
      "Epoch 2/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.1838 - acc: 0.5453 - val_loss: 1.0313 - val_acc: 0.6036.1833 - ac\n",
      "Epoch 3/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.1851 - acc: 0.5432 - val_loss: 1.0358 - val_acc: 0.6077\n",
      "Epoch 4/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.1868 - acc: 0.5466 - val_loss: 1.0324 - val_acc: 0.6077\n",
      "Epoch 5/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.1804 - acc: 0.5465 - val_loss: 1.0438 - val_acc: 0.6056\n",
      "Epoch 6/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.1816 - acc: 0.5492 - val_loss: 1.0344 - val_acc: 0.6037\n",
      "Epoch 7/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.1783 - acc: 0.5467 - val_loss: 1.0572 - val_acc: 0.5954\n",
      "Epoch 8/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.1784 - acc: 0.5513 - val_loss: 1.0608 - val_acc: 0.6053\n",
      "Epoch 9/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.1785 - acc: 0.5455 - val_loss: 1.0504 - val_acc: 0.6065\n",
      "Epoch 10/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.1755 - acc: 0.5488 - val_loss: 1.0908 - val_acc: 0.5889\n",
      "EPOCH 511\n",
      "Train on 22968 samples, validate on 5741 samples\n",
      "Epoch 1/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.1871 - acc: 0.5485 - val_loss: 1.0423 - val_acc: 0.5966\n",
      "Epoch 2/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.1791 - acc: 0.5481 - val_loss: 1.0473 - val_acc: 0.6020\n",
      "Epoch 3/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.1779 - acc: 0.5514 - val_loss: 1.0907 - val_acc: 0.5851\n",
      "Epoch 4/10\n",
      "22968/22968 [==============================] - 154s - loss: 1.1786 - acc: 0.5477 - val_loss: 1.0606 - val_acc: 0.5950\n",
      "Epoch 5/10\n",
      "22968/22968 [==============================] - 153s - loss: 1.1808 - acc: 0.5470 - val_loss: 1.0517 - val_acc: 0.6025\n",
      "Epoch 6/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.1795 - acc: 0.5484 - val_loss: 1.0917 - val_acc: 0.5874\n",
      "Epoch 7/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.1764 - acc: 0.5499 - val_loss: 1.0785 - val_acc: 0.5863\n",
      "Epoch 8/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.1717 - acc: 0.5493 - val_loss: 1.0659 - val_acc: 0.5952\n",
      "Epoch 9/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.1636 - acc: 0.5562 - val_loss: 1.0985 - val_acc: 0.5724\n",
      "Epoch 10/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.1763 - acc: 0.5526 - val_loss: 1.0760 - val_acc: 0.5853\n",
      "EPOCH 521\n",
      "Train on 22968 samples, validate on 5741 samples\n",
      "Epoch 1/10\n",
      "22968/22968 [==============================] - 151s - loss: 1.1796 - acc: 0.5489 - val_loss: 1.0208 - val_acc: 0.6100\n",
      "Epoch 2/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.1754 - acc: 0.5480 - val_loss: 1.0163 - val_acc: 0.6154\n",
      "Epoch 3/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.1823 - acc: 0.5490 - val_loss: 1.0350 - val_acc: 0.6034\n",
      "Epoch 4/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.1802 - acc: 0.5489 - val_loss: 1.0223 - val_acc: 0.6070\n",
      "Epoch 5/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.1781 - acc: 0.5502 - val_loss: 1.0425 - val_acc: 0.6002\n",
      "Epoch 6/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.1805 - acc: 0.5462 - val_loss: 1.0555 - val_acc: 0.5962\n",
      "Epoch 7/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.1734 - acc: 0.5507 - val_loss: 1.0672 - val_acc: 0.5915\n",
      "Epoch 8/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.1753 - acc: 0.5482 - val_loss: 1.0285 - val_acc: 0.6072\n",
      "Epoch 9/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.1802 - acc: 0.5492 - val_loss: 1.0487 - val_acc: 0.5971\n",
      "Epoch 10/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.1809 - acc: 0.5475 - val_loss: 1.0605 - val_acc: 0.5980\n",
      "EPOCH 531\n",
      "Train on 22968 samples, validate on 5741 samples\n",
      "Epoch 1/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.1836 - acc: 0.5485 - val_loss: 1.0311 - val_acc: 0.6074\n",
      "Epoch 2/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.1826 - acc: 0.5465 - val_loss: 1.0491 - val_acc: 0.6032\n",
      "Epoch 3/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.1782 - acc: 0.5528 - val_loss: 1.0363 - val_acc: 0.6086\n",
      "Epoch 4/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.1793 - acc: 0.5483 - val_loss: 1.0336 - val_acc: 0.6065\n",
      "Epoch 5/10\n",
      "22968/22968 [==============================] - 153s - loss: 1.1825 - acc: 0.5476 - val_loss: 1.0322 - val_acc: 0.6023\n",
      "Epoch 6/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.1826 - acc: 0.5468 - val_loss: 1.0581 - val_acc: 0.6018\n",
      "Epoch 7/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.1803 - acc: 0.5499 - val_loss: 1.0375 - val_acc: 0.6044\n",
      "Epoch 8/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.1784 - acc: 0.5480 - val_loss: 1.0645 - val_acc: 0.5959\n",
      "Epoch 9/10\n",
      "22968/22968 [==============================] - 153s - loss: 1.1658 - acc: 0.5512 - val_loss: 1.0735 - val_acc: 0.5901\n",
      "Epoch 10/10\n",
      "22968/22968 [==============================] - 152s - loss: 1.1811 - acc: 0.5458 - val_loss: 1.0773 - val_acc: 0.5894\n",
      "EPOCH 541\n",
      "Train on 22964 samples, validate on 5745 samples\n",
      "Epoch 1/10\n",
      "22964/22964 [==============================] - 151s - loss: 1.1867 - acc: 0.5482 - val_loss: 1.0132 - val_acc: 0.6124\n",
      "Epoch 2/10\n",
      "22964/22964 [==============================] - 150s - loss: 1.1845 - acc: 0.5469 - val_loss: 1.0114 - val_acc: 0.6151\n",
      "Epoch 3/10\n",
      "22964/22964 [==============================] - 151s - loss: 1.1789 - acc: 0.5486 - val_loss: 1.0375 - val_acc: 0.6007\n",
      "Epoch 4/10\n",
      "22964/22964 [==============================] - 151s - loss: 1.1759 - acc: 0.5496 - val_loss: 1.0310 - val_acc: 0.6023\n",
      "Epoch 5/10\n",
      "22964/22964 [==============================] - 151s - loss: 1.1794 - acc: 0.5480 - val_loss: 1.0563 - val_acc: 0.5967\n",
      "Epoch 6/10\n",
      "22964/22964 [==============================] - 151s - loss: 1.1786 - acc: 0.5520 - val_loss: 1.0550 - val_acc: 0.5943\n",
      "Epoch 7/10\n",
      "22964/22964 [==============================] - 152s - loss: 1.1828 - acc: 0.5517 - val_loss: 1.0681 - val_acc: 0.5882\n",
      "Epoch 8/10\n",
      "22964/22964 [==============================] - 151s - loss: 1.1745 - acc: 0.5496 - val_loss: 1.0368 - val_acc: 0.5984\n",
      "Epoch 9/10\n",
      "22964/22964 [==============================] - 152s - loss: 1.1785 - acc: 0.5495 - val_loss: 1.0550 - val_acc: 0.5965\n",
      "Epoch 10/10\n",
      "22964/22964 [==============================] - 151s - loss: 1.1692 - acc: 0.5543 - val_loss: 1.0983 - val_acc: 0.5795\n",
      "EPOCH 551\n",
      "Train on 22968 samples, validate on 5741 samples\n",
      "Epoch 1/10\n",
      "22968/22968 [==============================] - 162s - loss: 1.1849 - acc: 0.5478 - val_loss: 1.0099 - val_acc: 0.6201\n",
      "Epoch 2/10\n",
      "12896/22968 [===============>..............] - ETA: 86s - loss: 1.1813 - acc: 0.5451"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-c9349965f9e5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m     model.fit(train_data_x[train,:,:,:], train_data_y[train], \n\u001b[0;32m     10\u001b[0m               \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data_x\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_sets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m%\u001b[0m\u001b[0mpartition\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_data_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_sets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m%\u001b[0m\u001b[0mpartition\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m               epochs=period, batch_size=32)\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\lukes\\Anaconda3\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[0;32m    865\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    866\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 867\u001b[1;33m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m    868\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    869\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[1;32mC:\\Users\\lukes\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1596\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1597\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1598\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1599\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1600\u001b[0m     def evaluate(self, x, y,\n",
      "\u001b[1;32mC:\\Users\\lukes\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1181\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1183\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1184\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\lukes\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2271\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m   2272\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2273\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2274\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2275\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\lukes\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    787\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 789\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    790\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\lukes\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    995\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 997\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    998\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\lukes\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1130\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1132\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1133\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32mC:\\Users\\lukes\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1137\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1139\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1140\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\lukes\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1121\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "period = 50 // partition  # total iterations to cycle through all partitions is at most 50 iterations\n",
    "for i in range(1000):\n",
    "    print(\"EPOCH \" + str((i)*period+1))\n",
    "    train = []\n",
    "    for j in range(partition):\n",
    "        if j != i % partition:\n",
    "            train += train_sets[j]\n",
    "    \n",
    "    model.fit(train_data_x[train,:,:,:], train_data_y[train], \n",
    "              validation_data=(train_data_x[train_sets[i%partition],:,:,:],train_data_y[train_sets[i%partition]]),\n",
    "              epochs=period, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "addr = \"ADAM8_8_8_8_8_16_16_16_16_16_8_8_8_8_8F32\"\n",
    "\n",
    "model.save(addr + \".h5\")\n",
    "model_json = model.to_json()\n",
    "with open(addr + \".json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computer Vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model acc: 49.32%\n"
     ]
    }
   ],
   "source": [
    "# load in the whole architecture, training methods, and weights with h5 file\n",
    "addr = \"ADAM_16_8_8_4F64_32_16\"\n",
    "model = load_model(addr + '.h5')\n",
    "\n",
    "# # load the whole architecture stored in json and create model\n",
    "# json_file = open(addr + '.json','r')\n",
    "# loaded_model_json = json_file.read()\n",
    "# json_file.close()\n",
    "# model = model_from_json(loaded_model_json)\n",
    "# # load weights into model from h5 file\n",
    "# model.load_weights(addr + '.h5')\n",
    "\n",
    "\n",
    "# evaluate model on test set\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "score = model.evaluate(test_data_x, test_data_y, verbose=0)\n",
    "print(\"model %s: %.2f%%\" % (model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prediction and true labels\n",
    "y_prob = model.predict(test_data_x, batch_size=32, verbose=0)\n",
    "y_pred = [np.argmax(prob) for prob in y_prob]\n",
    "y_true = [np.argmax(true) for true in test_data_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['angry', 593], ['disgust', 43], ['fear', 777], ['happy', 1972], ['sad', 1516], ['surprise', 884], ['neutral', 1393]]\n"
     ]
    }
   ],
   "source": [
    "counts = np.bincount(y_pred)\n",
    "labels = ['angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral']\n",
    "print([[x, y] for x, y in zip(labels, counts)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfEAAAHeCAYAAACLyDKeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzs3XV4FUcXwOHfCZJgCSTB3d0lUFwLLcUKFHcr7u4uxd2K\nlaLFCnwUSXAPLoVixRJKsAJRyHx/7E24SW5IQpKShHmf5z5wd2d2zw5Lzs7s7EaUUmiapmmaFvtY\nfe4ANE3TNE37NDqJa5qmaVospZO4pmmapsVSOolrmqZpWiylk7imaZqmxVI6iWuapmlaLKWTuKZp\nmqZFgohkEJG5InJCRDxFRIlIlnDWtRGRaSLiJiJepm1UCO++dRLXNE3TtMjJATQGXgBHIlh3OdAR\nGAnUBtyAP0SkSHgqi37Zi6ZpmqZ9OhGxUkr5m/7eAVgKZFVK3QujXmHgAtBOKbXCtCw+cBW4oZSq\nE9a+dU9c0zRN0yIhIIF/gjqAH7DBbFvvgPXA1yJiHdYGdBLXNE3TtM8jP3BXKeUZbPlVICHGMP1H\nxY+OqDRN0zTtvxYvUVql3vtE+XaV34urgLfZoiVKqSVRsGl7jPvowT03W/9ROolrmqZpcYJ674N1\nmq+jfLveD9Z7K6VKRPmGo4BO4pqmaVrcIIJIrLpL/ALIbGF5QA/8uYV1QcSqo9U0TdO0OOQqkFVE\nEgdbng/wBW6FtQGdxDVN07Q4QQDBKso/0eh3IAHQKPAYjEfMfgD2KqXCvMGvh9M1TdM0LZJEpKHp\nr8VNf9YSkafAU6XUIRHJDNwGxiqlxgIopc6LyAZglogkAO4CPwJZgebh2a9O4pqmaVoc8VnviW8K\n9n2B6c9DQCWMgYJ4hBwBbwtMAMYDyYGLQE2l1Lnw7FQncU3TNE2LJKWUhLH+HkYiD77cC+hr+kSY\nTuKapmlanBHLZqdHmk7imqZpWpwh8tEOcZzzZV2yaJqmaVoconvimqZpWhwhfGl90y/raDVN0zQt\nDtE9cU3TNC3O0BPbNE3TNC0WEvnykviXdbSapmmaFofonrimaZoWR0h0v+s8xvmyjlbTNE3T4hDd\nE9c0TdPijC/tnrhO4pqmaVoc8Vl/Acpn8WUdraZpmqbFIbonrmmapsUZuieuaZqmaVqsoHvimqZp\nWpwgGA+ZfUl0T1zTNE3TYindE9c0TdPiiC9vdrpO4pqmaVrcoN+drmmapmlabKF74pqmaVqcoXvi\nmqZpmqbFCronrmmapsURwpfWN9VJXNM0TYsz9HC6pmmapmmxgu6Ja5qmaXGCfIHPiX9ZR6tpmqZp\ncYjuiWuapmlxhnxhfVOdxDVN07Q4Qw+na5qmaZoWK+gkrmnRSES+FZFTIvKviCgRmRXN+xtt2k+l\n6NxPXCQiWUxtt/Jzx6J9IhEkGj4xmU7iWpwiIk4islJEbouIp+lzQ0SWiEjp/ziW7MAWICOwBBgD\n7PkvY/iczJKiEpE7EspPQxGpbVZuZyT3eU9E7kVmG5oWm+h74lqcICLxgBlAT8AXOABsBd4DOYAf\ngI4i0kopteY/CqsKkBDoq5Ra/x/tcx6wHrj/H+0vPN4BWYGKwEEL69uaynzun0ePgLzAq88chxYJ\nX9o98c/9n0bTospEjATuCjRUSt0zXykiyYBBQPL/MKa0pj/d/6sdKqU8AI//an/hdBQogZGsD5qv\nEBFH4Dvgf6Y/PxullB/w5+eMQYsc4cubnf5lHa0WJ4lITqA/RvKqFTyBAyilXiulhmMMa5vXLSwi\nv4nIUxHxEZG/RGSCiCQNVi7wfqmI5BCRrSLyQkTeish+ESkcvCzG8DmAi9lwcZaw7r2a1h0Mtiyd\niMwTkVsi4mXa9xURmSsiCczKWbwnLiIJRGSgqU5A/T0iUtHC/leatpFVRHqKyJ+mtvlbREZJxLs6\nb4HNwPfB2xVoDiQAQmuLXCIyTUQumGL2FpGrIjI82HEHtHlmILNZeysRGW0qUyngu4iUM/27vRKR\nF+bbMP93EZGWpmUbLcTWz7RufgTbQ9OijE7iWlzQBuNcXqyUevqxgkopn4C/mxLYCaA2xr3qmcBz\nYChwUEQSWdhEFuAkYA/8DOwDqmIk6tSmMi8xEvgh0/dVpu9jTOsiRESSAMeBTsBlYDbwC/DQtMw6\njPpWGLcWpmB0VuYCvwFlAWcRaRJK1WnACIw2WmRaNhoYF9FjAFYASYDGwZa3BS4B50Kp18BU5iaw\nHFiKcYtkHLDJrFxAm78yfcaYfQ4G22ZZwBnwAxYD20IL2nTrZT3QSETaBiwXkSIYoz/XMS4gtRjB\neGNbVH9iMj2crsUFX5n+dA5vBdM99J8BG6CyUuqQablgJJzWwEA+9KYDVAQGK6WmmG1rHDAcI9lM\nVkq9BEabeoAVgZVKqYNm5SM6pF8Vo4fZWyk1O9hxpAA8w6jfCvgW2At8q5R6Z6o7EzgDLBKR3Uqp\nf4PVKwYUUkq5mR3nX0APERmjlPKNwDEcAe5gXHD9bNpeUaAw0Pcj9VYDM8z3Zfo3WgJ0EJFySqmj\nZm3eBkApNfoj26wGtFZKrQ5n7F0wzrE5InIE4975OtO6Zkopr3BuR9OiXMy+xNC08Elj+vNRBOqU\nA7IBvwckcACllMLoiftiJPLg7mL0UM0tN/1ZMgL7/xQhkoVS6oVSyj+MegHHMTgggZvqXsVIqHZA\nPQv1xgUkcFN5D2A7kAzIHZHATe26Eigvxqx9MC56/DBGFUKr9zj4xYJpWwtNX6tFJA4T1wgkcJRS\nr4AWQGJgLcZISB5gmFLqwifsX4tGX1pPPGZHp2nRJ+Ae9qHgK5RSjzF6nFlNE+LMXbCQNB+a/oyu\nSXOHMCbHzReRjSLSTkRyRKB+YeC1Uuq8hXUHzcoE52phWWSOdRXgD7QRkYRAM2DXx26BiIiViHQU\nkWMi8lJE/E33vgNiSxta3Y84G9EKSqkjwGSgFNARY9Rn+ifsW9OilE7iWlwQMPs7fQTq2Jr+fBLG\nNm2DLQ8+5IxZ7zZeBPYfbqaeYBmMIdzqGD3/v8R4/r1ZODZhS8SPEywcK8ajYPAJx6qUug+4YAzv\n1wMcCGVCm5m5GEPn6TGeuZ+McYsj4LbCR+cDhCK0tgiL+b3zhaYRAS1GEQSrKP/EZPqeuBYXHAcq\nYTyXHd774gEJKnUo61MHKxeVAnryIf7/iYidpQqmGfetTPfyiwA1gV7AWhFxV0p97Lj/BVKFsi46\nj9OSFRjD5zOAf4BdoRU0TRT8EbgIlDG/9ywiThjH/ykinHxNkxxXAT4YtwCmi8h+0714LSaJ4cPf\nUe3LOlotrlqJkRg7ifHccahEJKDnFnAvs4KFMmmBXMAdpdTrKIwzQMAPfksjB0U/VlEp9V4p5aqU\nmoAxMx3Cfr76AmBrmlEdXEWzMv+FLRgXDOmBteb36C3IijGbfr+FyWNlQ6nznugZEfkJ40UwQzAu\nHjLx4b68pn02OolrsZ5S6i+MH7IpgV0ikjl4GRFJJiLmie8oxmzpOiJSLljxCRhvWgv35KcIxvsv\ncAMoZ35v23T/fZKF2POJiKWedEAv2juMXQYcxyRTTz5gu3mBDhiPZG0P/xF8OlMyrgXUB6aGUTzg\nrXNlTDPSAePZcYxkaslzwFFEbCIbq9n+vgW6AvuBWUqpnzEuRpqISMuo2o8WBeTLm9imh9O1uGIo\nkAjoAdwUkf3ANYweenaMe8m2QEsApZS/iLTDeD58v+llHo8whuVLY0ycCivJRMZ0jHu9J0RkE8YF\ndS2MR76CqwFMFZGjGBPunmOMFHyH0atfFsa+VgMNMR4zuyAiu4EUQBOMe8rtLDxeFm2UUsfDWe6x\niGzFSPhnRMQFSAfUAf4AvrdQzRnj7XD/Mz0O5gscVkod/pRYTRdPP2O0eWuz++CdMM6TeSJyVCl1\n91O2r2mRpZO4Ficopd4DPUXkV4znessDlTGS4wOMN4YtVkqdNqtzSETKACMxElwyjN7fJGBidD7/\nq5RaanrjWG+M3rAbxm2B8RiJx9wfGC+ZqYCRjBNjXHD8DEwJK4GYLljqYzyP3QpjONgb4yUuE80f\nsYuBWmP8m9THuEC7DQwDfsdyEh+HcYFSG+MciIcxEe6TkjhGG6cCvjc9tQCAUuqZiLTGePb+FxGp\nYDoHtc9IiPm/dSyqiZ5gqWmapsUFNkkyqYx5B0T5dm+59nRVSpWI8g1HgZg92K9pmqZpWqj0cLqm\naZoWZ8T0iWhR7cs6Wk3TNE2LQ3RPXNM0TYsjBL6wiW06iccQdvZ2KnXG0F6qFTPZJviUN15+fu8/\n/DbSWOV9LJyE+t4/dv5AtYmfIOxCMYzPe7/PHUKEPbr/hBfP/o26k0T44saXdRKPIVJnTMWC3bPD\nLhiDVEsfkd/BEXO89Ln1uUP4JG/efezlZjHTM+/Y+RM1b/JP+b0qn9ft14/DLhTDNKr8sd9Cq4WH\nTuKapmla3PGFDafHzstkTdM0TdN0T1zTNE2LQ3RPXNM0TdO02ED3xDVN07S44wvrmuokrmmapsUN\nAkoPp2uapmmaFhvonrimaZoWd3xZHXHdE9c0TdO02Er3xDVN07S4w+rL6orrJK5pmqbFEV/eL0DR\nw+mapmmaFkvpnrimaZoWNwh6YpumaZqmabGDTuIx3OGdRxnVfhzNSrbm2+z1aVuhE8snrcTzjWdg\nmal9ZlA9w7cWP+0qdg4s5+3lzfR+s2iQ/wdalW3PwR2HQ+xvw4LNdK7enffv3kfL8Tx44EbDhj2x\nsyuOrW0xGjTozv37QX+FoofHcxo06I6dXXEKFKiNs/OJENvp2nU0337bKcrje/TQg4F9FlKjYj/S\npWhACptvuX/vSZAyr197MmLwMmpXH0ymlA1JYfMtRw9dCrEtT09venSeRda0P1A0b3u2bArZ3rOn\nb6Zcye68i0R7uz3yYES/JdStMpCcKRuRMWldHvz9xGLZc6dv0KLeaPKnb0auVI2pVqon283i8vL0\noX/XuRTI2JyyBTuzY/ORENtYOHMLNUr3ilTM+3Yco3fL8XxdqC1OGb6nrlMX5oxbxdvXH87rk4cu\nMLjTNL4p1h6nDN9Tu0RHJvRfwPOnL4Nsy8vTm9G95lAhR1Nql+jIH1tDxrxizm80rtgjUjGHV+1v\nemAdvwSjRiwIXObh8ZLGDQeQ0r4iRQs3xsX5TIh6PbpPpu53vaI8nj+2H6N78wlUyd+Oomkb8k3J\nH5kxJmhbA7x6+YYRPefyVfbmFE/fiHb1RnDz6r0gZbw8fRjeYw6lszbj66Kd+N+WkG29fPZv1C/X\n8z9pa4usJOo/MZgeTo/hNi3egmMaB9oNbk3KtI7cvnaH1TN+5cLxS8ze/hNWVla06NWU2i2+CVLv\nycMnTOw2lTLVnQKXrZ+3CdcjF+g/sw93r99jSq/p5CiQnQzZ0gPw9LEHv85Zz8RfxhIvfrwoPxZP\nTy+qVGmNtXVCVq2agggMHz6bypVbcenSDpIkSQxA376TuX37Phs3zmLnzoM0bNiL27f3kSKFHQCu\nrldYvXo7ly7tiPIY795+zLbfjlK4aA7KlM2P8/5zIcq8ePaaX1bto3CR7FSqWpTftx23uK1Z0zbh\ncuAC85f24drle3RpN53CRbOTPYfR3o8eejB98no27RhL/Ei0973bbuzccpSCRXNQ6qt8HD5wwWK5\nA3vO0rHpJOo2rsDcn/uSIGF8/rr+AB8fv8Ay86dv5ojzBWYs6sn1K3/Tu+MsChbJTtYc6QDjgmHO\n1I2s2ToqUjGvnr+VVGnt6Tm8FanSOXLjyh0WTV3HmaOXWfW/qVhZWbF51R5ev3pLhz6NyZQtHffv\nPGbhlF857nKOTYfmkjhpIgBWzN7MyYPnGTu3N39du8ewrjPIUyg7mbMbMT957MGyGRuYv3FMpGIO\njw3r93D50s0Qywf2n8GdOw9Zu24yu3cfoekPg7h+cxspUtgCcM71OmvX7OLs+XVRHtOKeVtJndaB\n3iNbkia9I39evsP8yes5ffQyv/5htLVSim5NxvHowT8Mm9IJ2+RJWTpzM23qDGPL4dmkSe8IwLJZ\nmznucoGJ83tx89o9BnWZSd7C2cliamv3Rx4smr6RJZtGR3tbh+oLm9imk3gMN27lKJI72AV+L/xV\nIZIlT8bU3jO4eOIyRcsWJl2WtKTLkjZIvXNHzgNQvVHVwGVnDrpSt01tvqpRmq9qlObAVhfOH70Q\nmMQXjl5ChW/Lkb9Evmg5lqVLN3LnzgNu3NhDjhyZAShUKDc5c37N4sUb6Nu3LQD/+99h5s8fyddf\nl6dq1TKsXLmFkycvUKtWRfz9/fnxx9EMGtSBbNkyRnmMX5UvwM37awFY/fMfFpN4xsypuOu2AYCD\nB86HmsT373Wl44+1+aZ2ab6pXZpN61046HwhMIkPHbCEug3K4VQmcu3tVC4/5++uBmDdyr0Wk/ib\n15706zKHVh1rMXpqh8Dl5SsXCVLOZd852nT+lhrfOlHjWye2bTjEEZeLgUl89MBlfFu/LCVK541U\nzLPXjsDe8cN5XbJcQexSJGNEt5mcPXqZUhUKM3Tqj0HKlChbkMzZ09O+zhD2bj9KvebVATh6wJUf\n2temUi0nKtVyYvfmg5w6dCEwiU8btpTqdctRpFTkYg7Lixf/MqDfTKZN70OrFsODrPtjz3Fmzx1E\nja/LUKVqSdas2smpk5epWass/v7+9Og2if4DWpMtW4Yoj2vBuqBtXcrU1kN+nMXpo5cpXaEwzv87\nxblT11mxYzxO5QsBUKRkHqoX6cjyOVsYNsUY9Tqy35XmHb+lyjdOVPnGiZ2bDnHy4IXAJD556DK+\nrluWok7R29baB3o4PYYzT+ABchXOCYCH27NQ6+3b7EzOQjnIkjtz4LJ3vu+wtkkY+N0mkTW+Pr4A\nnHE5y8UTl+k4vF1UhR7Cjh3OlC5dODCBA2TNmpGyZYuxffuBwGW+vn4kSmQDQPz48UmYMCHe3kac\nS5Zs4NWr1wwc2DFaYrSyCvu/hITzSt/X9x2JEn1o70SJrfExHcf+vWc5evgyYyZGvr3DE/POrcd5\n5vGKTj3rfrScn+87bGyCxWw6R1z2nePEkSsMG9c6cgFDkKQSIH9R47z+x/1Z2GXMzv13fu+wSRT0\nvA6I+dgBV84eu0zvUW0iHXNYhg6ZS7782fmhSc0Q63x9/bCxsQYCzukEgTEuW7qFV/++od+AVtES\nl6V2LBDQjo+fA+Dyv9OkSmsfmMABktkloXLNkjjvPhW4zM/3HdaJrAO/G21tjOQc2e/K6aOX6T+m\nTXQcRvhJNHxiMJ3EI0lEEkh4f6pHkUsnrwCQKaflnuiVM9d4fO8xNRpWDbI8T9Fc7N18gGdPnnPm\noCu3r94lb7E8+Pr4MW/EYtoPaYOtaXgvOly9eosCBXKFWJ4/fw6uXbsV+N3JqTCLF2/g2bMXLF++\nidev31K8eH6ePn3OsGGzmD9/FNbWCUNsJ6YpUTIX6345gLvbcw7sc+XyxbuUKJUHHx8/BvVZzKhx\nbbB3iL72NnfmxDWS2yfjz6t/U61UT7LY1adU7nbMnLie9+8/3LssWiIXm3515on7cw7uP8fVS3cp\nVjI3Pj5+jOy/hCFjW5EimmJ2PWac11lDOa8BXI+byuT6UKZAsdz8vt6Zp+7POe58jhtX7lKohHFe\nTx68mJ4jWpPcPnrb+djRC6xds4vZcwdaXF+yVAGWLd3Cs2cvWfHzNl6/fkvRYnl5+vQFo0YsZPac\nQf/pOX3G1NbZchs9/1t/3idn3swhyuXIkwm3h095+8YLgEIlcrF9ndHWRw+c48/LdylcIje+Pn5M\nGLSEvqOiv621oGJlEheRHCKyRkTuioiXiNwRkYUikiJYuZUi8lBEiorIERHxFJG/RKSLhW1WE5Hz\nIuItIrdEpIOp/j2zMllERIlIVxGZKiKPAR+gmGl5iG6OWQxRcoPIw82D1T/9QrHyRcht6pEHt3/z\nAeIniE/lehWDLG/ZpxnvfN/RpHhLhrYYScNO9clXPC8bFmwiuYMttZrWiIoQQ/X8+avAe4Dm7O3t\nePHi38DvM2YM5vLlmzg6lqZLl9H89NNAMmVKx6BB06he/SuqVfsqWuOMKgOHNcPX9x15s7ak4Xcj\n6da7PqVK52X2T5twSGlLy7bR297mnrg9x8vThx7tZtCoRRXW/T6Whs2qMHvKBsYNXRFYrvfQJvj5\nvqNEjra0rDeGTj3rUtwpDwtn/IaDoy1NWlePpviesWDKWpwqFgnsbQf39rUn04YtJVuujFT+pnTg\n8s4Dm+Ln947qBVrTtfEoWnatR+GSeVgxZzMpHO2o3yJ629nX149uXSfSp28LcufOYrHMtJ/6cPXK\nLdKlrkb3rpOYPLU3mTKlYdiQOVStVoqq1Zws1osOTx4/Y96kXylTqXBgj/zVizfY2iUNUdYuRTIA\n/n35BoCuA5vi5+tHxbxt6NRwNG261aVIqTwsm/0b9g52fN8yes6PcBP0xLZYIh3wGOgHPAOyAkOB\n3UCZYGVtgV+BWcBYoC2wUERuKKVcAEQkH7ALOA00ARICIwA7wN/C/ocBZ4BOQDzgmul7Z2B7QCER\nSQ40BqYqpSI9VdPrrRcj24/DKn48+k/vY7GMr7cvh3YewalqSezsgw6jOaZ1ZPG+ebj97U5SuyTY\nprDF7W83Ni3awsytU/Hx9mHRmGUc23MCm0TWfN+xHvXa1Yls2BFWoEAubt/ex507D0iTJiW2tkk5\ndsyVLVv2cf36bjw8ntOt21j27z9BypQpGDeuF40a1frP4wxLuvSOHD0zj3t33LFLngR7B1vu3XFj\n7swt7HaeipeXD8MGLmPXjhMkSmRNt1716NQ1etrb31/h4+3LwFEt6NTDuNYsU6EgL56/ZvWS/9F3\naFNs7ZKQNp0De0/O5u+77tjZJSGFgy1/33Vn0eytbNk3GW8vX8YOXs6e30+SKLE1HbvXpe2PtSMV\nm+cbL/q0GE/8ePEYO9fy7Ox3794zuNM0/nF7zsrdU4JMmkqd1oGNh+bw8J47yeySkNzelof33Fk1\nbysrdk3B28uH6SOW47z7JDaJEtLyx3o07fhdpGI2N33aKry8fBg8NPRbI/kL5OD6zW3cufOINGkc\nsLVNyvFjF9i21YWLVzbj4fGSXj2m4HzgNI4pkzN6zI9837BalMUY4O0bL7o3n0C8+PGYMC/iM+FT\np3Ng69E5PLjnjq2prR/cc+fnuVv5ZbdxfkwZtpwDu4yfIa271aNFp8idHxEWs3NulIuVSVwpdRgI\nfC5GRI4Bt4AjIlJUKXXerHgyoKtZwj4MfA00BVxMZYYD/wJfK6U8TeWOAHcBdwshPAHqK6WUWQwL\ngOUiklkp9bdpcSuMC4Jllo5DRDphXAiQKn3Kjx6zj5cPI9qMwf1vd6ZvnkLKdI4Wy53Yd4o3r95S\no1FVi+tFJMgkuHkjFlGraQ2y58vGz1NWcfPSXyw9sAAPdw/6NhhEplyZKFauiMVtRVSKFLZBetwB\nLPXQ48ePT65cWQF4//49XbuOYcyYHqRNm4rmzfvx5o0nd+8e4NSpi3z3XRcKFcpN7tzZoiTOqCQi\nZM3+ob0H9l1Ey7Y1KFgoG+NGruLCub847roAt8cefFN1ELnzZKJilahpb3Mp7I0eVfnKhYMsr1C1\nCL8s38Nffz6guFOewJizZPsQ88j+S2jSujr5CmZlyug1XDx/i/2n5+Lu9ozvawwhZ56MlAu23fDy\n9vKhZ/NxPPzbneU7JpHawnnt7+/PiG4zOXX4InPXjSJX/qwhyogIGbN+iHny4MXUb1Gd3AWyMnfC\naq5duMXmI/P4x+0Z7WoPJlvuTDhV+LSYzd2/787kSStYtGQ4Pj5+QWb6+/j48fLla5IlS0y8ePFM\n57QxZP3+/Xt69pjCiFGdSZvWkdYth/PmjSc3bm3n9KkrNKjXlwIFc4Tas/8U3l4+dGs6ngf33Fm9\nc2LgjHMA2+RJ+ffVmxB1Xr14Hbg+gIiQyaytJwxcQsOW1clTMCuzxq3h6oVbbD8+jyduz2j5zRCy\n585ImYqRb2vNstg6nJ5QRIaKyJ8i4gX4AQEPLOYOVtwzIIEDKKV8gJtAJrMypYHdAQncVM4NsDzt\nGLaZJ3CT9cBLwHzGVWdgl1LqoaWNKKWWKKVKKKVK2FmYwBbgnd87xnaeyM1Ltxi/egxZ82YJteze\nTfuxs7elVJWSoZYJcGzPCW5fvUvr/i0AOHvQlRoNq5LcwY4c+bNTvEJRzrq4hrmd8MqfPwdXr/4V\nYvm1a7fJly9HqPXmzl2DlZUV3bsbce7Zc5QuXZpga5uU6tXLkj9/TvbvD/kseUyza8cJrly6y5CR\nxnEc2OdK0xZVcUxpR8HC2alcrSj790Vde5vLlTdT2IUs2PP7Sa5eukv/4c0AOLT/PI2aVcEhpR35\nC2WjQpWiHLQwgz88/Pze0b/tZK5duMW89aPImS+LxXLj+y1g77YjTF46IFyJ13n3CW5cuUPXwc0B\nOH7gHN81qYK9ox15CmajTOUiHDsQNe18985DvL19aNNqBKkdKwd+AGbOWENqx8pcuXwrRL358zZg\nZSV07dYYgL1/nKBjp++xtU1KteqlyZc/G84HTkdJjGC0de/WU7hy4RaLN44kV/4sQdbnyJORW3/e\nD1Hv9o0HpM2QkiSmx/mC27/rJH9euUOPIcb5cfTAOeo2Ndo6b8FslK1chKOfeH58KiUS5Z/wEJGM\nIrJZRF6JyL8iskVEwvUfT0QyicgqEblvukV8U0TGi0iSsOrGyiQOTAJGA78A3wKlgAamdTbByr6w\nUN8nWLm0wD8Wyll+Ywa4BV+glPIGVgDtRCS+iJQH8gGLQtlGuPj7+zOpxzQuHLvE6OXDyVc8T6hl\nXzx9wdlD56hcrxLxE3x8kMXby5sFoxbz4+iOJE6a+MNyT+/Av3t5eqMIfq3y6erUqcLJkxe5c+dB\n4LJ79x5y7Ng56tSpYrGOm9s/jB49j4ULRxMv3och1LdvvQL//ubNW0JeU8Usnp7eDO63mAlTO5Is\n2Yf2fvv2Q3u/feMN0XQcX9c27rkeOnA+yPJD+85jbZOQPPlDTmry8vRh9MBljJrcnqRmMXuanSNv\n33p9Usgc6Bc2AAAgAElEQVT+/v4M7fITZ45eYuaaYRQqYfm8nj5iOVt/2cuYub2o8k3wO2UheXl6\nM23oUvqP70ASs5i9zGL2fBt17Vy4SG727l8U4gPQrHkt9u5fRPYcQSfqubl5MH7sEubOGxLknPb0\nND+nPaPsnPb392dgp+mcOnKJub8MpXDJkG1duZYTTx4/C5zwBvDmX09c9pyhcq1SFrfr5enDpMFL\nGTQhWFu/DdrWUfkzJKYSkcSAM5AHaA20BHICLmElYtP6/UAFjNu432CM3vYDfg5r37FyOB3jvvVq\npdT4gAUiEnJWRvi5AaksLE8dSvnQzsqFQF+gLlAfuAf8EYm4mDtsIYd3HqVZzx+wSWTDNdc/A9el\nTOsYZFj9wNaD+L/3D3Uo3dzaWevJkD0DFb8rH7isWPmibF+5k4w5MvLsyTPOH71Aw071IxN+EB07\nNmbevLXUrduV8eN7ISKMGDGbjBnT0LnzDxbr9O07mcaNa1G69Ich5urVv2L8+IXY2SXl9OnL3L79\ngCpVSlus/ym2bzkKwIXzRg9q396zODra4ehoR9kKBY1lf5zF8603167cA+DYkSs8e/YviZPYUP3r\nEiG2OW3ienLmykD9hh/au1LVoixbtJNcuTPi5vaMQy4X6Nbr09p719ZjAFw6fxsAl73ncHC0xd7R\njjLlC5Anf2YatajC9PG/ovwVBYpk46jLRdat2kevQY0t9rRmT9lAtpzp+e77coHLylcpzMrFu8me\nKwNP3J5z7OAlOvWsF+F4Jw1cxL7tx+jQtzGJEltz6eyH8zp1OkdSp3NkxZzNrFm4jXrNq5MpW7og\nZVI42AUZPg+wdPoGMudIz9f1PrRz6UpFWL9sF1lyZuCp+3NOH75Iy64Rj9mS5MmTUbFSyH9vgEyZ\n0lpcN7D/DL5vVB2n0gUDl1WtVopJE5dja5uUs2eucuf2IypXDns0LTzG9V/EH9uO0blfYxIntubi\nmaBtnSa9I1VqlaJIyTwM6jSD/mPbBL7sRSlF+54NLG534bT1ZM2Znlr1P5wfX1Uqwq/LdpE1Vwae\nuj3n5KGLtOkWNW0dLvLZJqJ1BLIBuZVSt4xQ5BLwF8aI7IyP1C2LkfBrKqUC8oWLiNgD/UUksfko\ncXCxNYknxhhCN9c2Ets7CXxj3lgikhajcUP0ukOjlLotInuBAUARYKxSytLEuHA743IWgF/nbODX\nORuCrGvZpxmt+jUP/L5v0wGy5M5MzoKhD00D3L/1gB2rdjJ/9+wgy5v3asILj5dM7zeLhDbWdBjS\nhhIVi0Um/CCSJEmMs/Mq+vSZRMuWA1FKUbVqGWbNGkrSpCEvVp2dT7B//3Fu3NgTZPns2cPo0mUU\nTZr0xcEhOatWTf7ocHxEtWk2Kcj3/j2N12eWLV+QnfsmA9Cvx3we3P8weDN5vPGCmIyZUnHp5oog\n9W/eeMDyxTtxORG0vfsPbsLTJy/p3nkWiRJZM2p8G6pU/7T27tJyapDvw/oYvcHS5Qqwac8EI8Y5\nXUmT1oEVi3bi8c8rMmROxchJ7WjfLeQkr1s3HrJqyW52Hwn6s6fnwMY8/ecl/bvOxcYmIYPHtqJi\n1aIRjveoaTh72YyNLJuxMci6zgOa8uOgZhzdb5TZtnYf29buC1LmuyZVGDcv6OTOu389YMPyXfx6\nYFaQ5R37/sCzpy8Z3XMO1jYJ6TmiNV9VjrrzOiJcnM/gfOA0l6/9FmT59Jn96d51Ei2bD8XeITnL\nV4wmb76omeNxxDScvXj6RhZPD9rWXQc1ofvgZlhZWbFgwwimjfiZsf0X4evjS+GSeVi5YwJpM4Sc\nr3Pn5kPWLd/NJpeZQZZ37t8Yj6cvGd59DjaJEtJnVGvKVon4+REL1QFOBiRwAKXUXdN8rbp8PIkH\nPFv4Mtjylxij5R+9KpGYPgxpiYisw2iY/hgT2hoA1YDsQFul1EpTuZVANaVUhmD1DwIopSqZvucD\nLgCngJ8Aaz7MTn+nlMpmKpcFY7JbR6VUaJPV6mDMUPcDMiqlQhuSDyJX4ZxqQbCkGtNVSx91ifO/\n9NIn5D3K2ODNu3efO4QIe+YdO+/Y5U0espcf091+/TjsQjFMo8p9uXL+ryjrOtskz6oylB8VVZsL\ndHtnW1ellOUhF0BE3IHtSqnOwZYvABoppUKduSwiNsAljA7jj8B9jFvEa4GtSqmuH4sttvbEe2Bc\nnUwwfd+NMdv8k2aCKKWuici3wDRgI/AImALUBLJEcHO7AC+MCW3hSuCapmlaFImed285ishZs+9L\nlFJLzL7bY3n+1XMghYXlgZRS3iJSDvgNuGq2ahnQPazAYmUSV0p5YNwXD06ClWsTSv1KFpbtwxgC\nNzZk3GMfg5GUA8rcC74PC6oAiYjkhDZN0zQtxvD4WE88Mkw98Q0Yc7Ba8qEnPhJ4h9E7D1WsTOLR\nQUTmYjxS9hjjZTK9MK6gwjXGLSLZMSY2zATOKaUOhFFF0zRNi2qfZ2LbCyz3uEProZtrD1QCcprd\nUz8sIq+AJSKySCl1MbTKsfOGVfSwwRhC3wssAd5i3E8P+YuiLRsB/A/j8bXo+U0GmqZpWkx0Fchv\nYXk+jDd6fkxB4KX5pDiTgNvDH/2VcLonbqKUitSvxTIN3beJkmA0TdO0iPt8v3VsB/CTiGRTSt2B\nwInQZYHBYdR1B5KLSI5giTzghfqPPlZZ98Q1TdO0uEMk6j9hW4rxXpDtIlLX7CmlB8DiD6FJZhF5\nJyIjzequBF4Du0WktYhUFpEBGE9KuQLHPrZjncQ1TdM0LRKUUm8xJjXfBNZgPB52F6iilDJ/Kb1g\n/NIsK7O69zBe/X0BGI/xtFVHjNu61cN614geTtc0TdPiiHD3nKOcUuo+8H0YZe5hYcBfKXUN4zde\nRpjuiWuapmlaLKV74pqmaVrcIHxxXVOdxDVN07S44zMNp38uX9g1i6ZpmqbFHbonrmmapsUdX1ZH\nXPfENU3TNC220j1xTdM0LU5QgPo8707/bHQSjyGsrSBrsvefO4wIOfHkr88dwifJbhu72jlA8oS2\nnzuECPvH603YhbQokTFJss8dQoQltNKDwZGlk7imaZoWNwhf3Ox0ncQ1TdO0uOPLyuF6YpumaZqm\nxVa6J65pmqbFHV/YxDbdE9c0TdO0WEr3xDVN07Q44vP9FrPPRSdxTdM0LW4Q9MQ2TdM0TdNiB90T\n1zRN0+IOPbFN0zRN07TYQPfENU3TtLjjC+uJ6ySuaZqmxQ0C6svK4Xo4XdM0TdNiK90T1zRN0+KO\nL2w4XffENU3TNC2W0j1xTdM0Le7Qb2zTNE3TtFhIRA+nazGP2yMPxgxYTMNqAyiQpiE57Orw8O8n\nIcrdvH6frs0n8lXuNhRM24iaTt1YNmcr7969Dyzj5enD4G5zKJ65GZULd2LXb0dCbGfJrN+oXbZn\nkHoR5fz7UQa1GU+9Ym2olKUBTcp2ZuGElbx94/nhuO4/4as0tS1+Xr96E1jO29ObiX1m83WeJjR0\n6sD+bYdD7O+XeZtpVaV7pGIGePzQgyF9l/BNpYFkcWhE6sR1uW+hrc0N6LGA1Inr0rXdjCDLPT19\n6N1lLrnTN6dU/s5s2xyyrefN2EJlp16RjtuSE8cvU/ebAWRNX5+09t9QrlQnVq/cHbjew+MVzRqN\nJL1jbUoVacshl3MhttGnx0y+rzs4ymPbv+MYfVuN55vCbfkq4/c0KN2FueNWBTk/rl+8RffGo6hZ\nsDVlMjSgRr6W9Gwymktn/gyyLS9Pb8b2mkPlnE2pU7Ije7eGbOdVc3+jSaUe0dLOwdX+pgfW8Usw\nasSCwGUeHi9p3HAAKe0rUrRwY1ycz4So16P7ZOp+1yva4wsQk88PLfxiRU9cRA4CKKUqiUglwAWo\nrJQ6+BnD+igR6Q3cV0ptiey2/r7jxu6tRylQJAclyuTnqPP5EGWeuD2j+bdDSZPOgWGTOmDvkIzj\nhy4xZeRKnnu8YuDYNgAsnrmZYwcvMGVhL25cvUf/zjPJXyQ7WbKnA4wLhvk/bWTFb6OJHz/eJ8e8\nbuFWUqZ1oMvQ1qRK68BfV++y/KdfOXfsMot3TsPK6sP1Y6uejSj3tVOQ+omTJgr8+5q5mzlz+ALD\nZ/fh1rW7jO0xg9yFspMxW3oA/nnswcpZG5i5bmykYga4e8eNHVuOUrhIDpzK5uPg/gsfLX/6xHU2\nrz9EMtvEIdbN/Wkzh50vMHtxT65d+Zvu7WdRqEh2suUw2vrxQw9mTtnI+u2jIh13cFcu3aZOzf6U\ndMrH3IX9SJzYhm1bDtGt0zR8ffzo0LkuQwfM5+6dR6z6dSR7dp+kZZPRXPxzLSlSJAPg/LkbrPtl\nLydcl0dpbABrFmwlVRp7ug9vRap0jty8fIfF09Zx9thlVuyeipWVFa9fvSVj1rR817QqjqlS8Nzj\nFb8u3k7HukNYvnMKBYrlAmDlnM2cPHSe0XN789fVe4zoNoM8hbKTyXROP3nswfIZG5i7YUyUt3Nw\nG9bv4fKlmyGWD+w/gzt3HrJ23WR27z5C0x8Gcf3mNlKksAXgnOt11q7Zxdnz66I1vgAx/fyIlC+s\naxorkngw54AywLXPHUgYegNHgUgn8VJl83Pq1hoANqzaazGJu+w5w4tn/7Lhj8lky5kBgDIVC3P/\nrjtb17sEJvFD+1xp2fFbqn3jRLVvnNix8RDHXC4EJvHxg5dRq25ZijnljVTMU1ePJIWjXeD3YmUL\nYZs8KeN6zuTc8cuUKFc4cF26zGkoUDxPqNs64ezK922/pfzXTpT/2om9Ww5y5vDFwCQ+a8QSqnxX\njoIlIxczQJly+bl6bzUAv6zY+9Ek7uf3jv49FtB7YCPWLP8jxHrnvedo1+VbatZ2omZtJ7ZsOMRh\n54uBSXzEwGV8V78sJUtHPu7gNm905v17fzZunUhS0wVRlWoluHL5Dr/+spcOneuy94/TzJjdi2o1\nSlGpSnHWrt7DmVPXqFHTCX9/f/p0n0Wf/k3Jmi1dlMc365cRQc6PEmULYpsiGaO6z+TsscuUKl+Y\nUhWMj7mvqhajau7m7N7oEpjEjx9w5Yf2talY04mKNZ34328HOXX4QmASnz5sKdXqlKNwqahvZ3Mv\nXvzLgH4zmTa9D61aDA+y7o89x5k9dxA1vi5DlaolWbNqJ6dOXqZmrbL4+/vTo9sk+g9oTbZsGaI1\nxgAx/fzQwi/WXbMopf5VSp1USv37uWP5r5j3WkPj6/cOAFu7JEGW29olwd/fP/C7n987bBJZB363\nSWSNj48fAIf2u3L66GUGjWsT6ZjNf0AHyFvE+KH71O1ZhLb1zs8Pa5ugMfv6+AJw0tmV8yeu0G1E\n20hE+0F42jrA/Jlb8X/vT9fe9Syu9/V7h02ihIHfEyWyxtsUt/Pecxw/coWRE1pHLuBQ+Pq9I2HC\n+CRObB1kuZ1dEpTpfPDz/XAuxI8fjwQJE+DtbcS3YtlOXr16S+/+TaIlPkvnR/6iOYGPnx+JEtuQ\nMGEC4sX/8O/k5/cOa5sP7Wx+fhw/4MrZ45fpOapNFEUeuqFD5pIvf3Z+aFIzxDpfXz9sbALaOj4J\nEybAxxTjsqVbePXvG/oNaBXtMQbGE8PPj0gRifpPDBbjkriINBGRP0XER0Suikj9YOsriYgyDasH\nLPtaRI6LyCsReSMiN0RkZLB6TU3b9RaRyyJSR0QOBgzVm8q0MW07S7C6o0VEBVvWS0Sui4iXiLwQ\nkbMBsYrIPSAz0Ny0PSUiK6OifULzTb2ypHCwZVS/xTy4587rfz3Z+/sJtm1woX33D0mmcPFcbPnV\nmX/cn3N4/zmuX75LkZK58fHxY+yAJfQf3ZoU9rbREuP5E5cByJIzY5Dliyasonz6OlTP2ZiBrcZy\n+/q9IOvzFcvN/zYewOPJc066uPLXlbvkL54bXx8/ZgxbxI/DWmMXTTGH5u5tN2ZN2cjkWZ1JkMDy\ngFaxErnY+IszT9ye47LvHFcu3aV4KaOth/ZbwrCxrbB3iJ64W7SsiVIwoM9c3B578PLlG1Ys38lB\n53N069kIgBKl8vLzst959uwVq1bs4s1rT4oWy8XTpy8ZM3I5M+b0wto6YRh7ijqux68AkDVX0PPD\n398fP793uD38hymDFwFQv+XXgesLFMvNzg3OPHV/znHnc9y8cpeCxfPg6+PH1CGL6TG8Ncmj+fw4\ndvQCa9fsYvbcgRbXlyxVgGVLt/Ds2UtW/LyN16/fUrRYXp4+fcGoEQuZPWfQf9rWsfH80CyLUcPp\nIlIN+BXYBfQDUgKzgQTAjVDqZAN2AJuBsYAvkBPIZlamOrDWVK6vabuzABsg5A2ssONsDkw37e8I\nkAgoBNibitQHdgMXgdGmZU8jup+IcEyVgk37ptKl2QQqF+4UECc9hzSlU+/vA8v1GNyU9g1H81Xu\nNgB07FmfYqXyMHfKeuwd7Wjcqnq0xPfUzYOlU9dSskIR8hYxelwJrBNQr1VNSlUsRnIHW/6+9ZDV\nszfRufYAlu2ZEZjs2/drSt9mo6lT2OipNO/agIIl8vLz9HUkd7Dju2Y1oiXmjxnYayHf1C1DuYqF\nQi3Tf2gTmtYfQ6HsxihBtz71KemUh+kT1+PgaEvzNtHT1gD5CmRl9/6ZNGs0giULtwGQIEF8Zs3v\nQ8MfqgAwaWpXGtYbQpa09YgfPx4Tp/5Ixkyp+bHjFKpULU7lqsWjLb7g/nF7xqIpa3GqWIR8pvMj\nwOD2Uziw8zgA9imTM3vdKLLlzhS4vtOApvRoMpqaBY1RjVbdG1CoZB6W/LSOFI521GsRveeHr68f\n3bpOpE/fFuTOncVimWk/9aFend6kS12N+PHjMWVaHzJlSkOnDmOoWq0UVas5WawXXWLb+RFuwhc3\nOz1GJXFgDPAnUFcp5Q8gIn8CJwgliQPFgITAj2ZD7M4WtnsNqK+UUqbtXgHO8glJHOOe/CWl1Fiz\nZYHTOpVS50XEB/BQSp0MbSMi0gnoBJAuY8pPCOODZx6v6NZyEokT2zBv9WCS2yfj5OFLLJi2kYQJ\nE9C5j5HI06RzYOexOdy/645t8iSksLfl/l13ls3Zyvo9k/H28mXi0OXs3XmCRImsade9Hq06145U\nbJ5vvRjUejzx48dj2KzegcsdU9szcGr3wO9FShegdOXiNK/YlVWzNzJqXj8AUqZ1ZLXzXB797U4y\n2yTY2dvy6G93fl2whYU7puDj5cOc0cs4tPskNomsadK5Ho06fBepmD9m87qDXHC9xbELCz5aLm16\nB1xOzebvu+7Y2iXB3sGWe3fdmT9rK7/vn4yXly+jBi1n9+8nSZTImi4969Lhx8i1dYBbfz2kxQ+j\nyJsvC7Pm9SVRooTs+v0YvbvNxMY6IT80q06+Alm59Oda7t55TOo09tjaJuHE8cv8vu0IZy+twsPj\nFf16zsLF+RyOjnaMGN2O+g0rRUl85jzfeNG35XjixYvHqDkhZ2f3HNWW1j2/58kjDzb+vIvezcex\n8Ldxgck+VVoH1h+cw8N77iSzS0Jye1se3nNnzbytLN85BW8vH2aOXI7L7pPYJEpI8y71aNIx6s6P\n6dNW4eXlw+Ch7UItk79ADq7f3MadO49Ik8YBW9ukHD92gW1bXbh4ZTMeHi/p1WMKzgdO45gyOaPH\n/Mj3DatFWYzBxabzI6JUDB/+jmoxJomLSDygJDA5IIEDKKVOmoanQ3MB8APWi8jPwGGl1D/BtlsC\nmBSQwE3bdRWRu58Y7hmgq4jMBbYDx5VSnmHUCUEptQRYAlCwaE4VRvGPWjprCw/v/8Phy8uxS5EU\ngNLlC/L+vT+zJqylUavqgUO3IkLmbGkD644duIRGraqTt2BWpo9dw+Xzt9h9ch5PHj+jaa0h5Mid\nka8qFba437D4ePkwsOVYHt13Z8HWyaRK5/jR8qnTp6RwqXxcPx/02kpEyJDlQ8wzhi7iu+Y1yJk/\nG4smrebPC7f45eB8nro/o2vdQWTNnZES5Yt8Uswf8/aNFyMH/0z3vg2wto7Pq5fGo3ABQ76vXr4h\ncRKbwCF2ESGLWVsP67uE5m2qk79QViaOWsPFc7c4dGYu7o+fUaf6EHLlyUiFyp/W1ubGjFhGggTx\n2bh1IgkTJgCgUpXiPH/2LwP7zaNRk6pYWVkRP348cpqGr9+/f0/fHrMYOrINadI60L7VeN689eLK\nzV85e/o6jesPJX/BbOQy6wVHlreXD71bjOPR3+4s2T6J1BbOjwxZ0pAhSxryF81F+RolaVy+Owsm\n/sK8jWMCy4gIGbN+aOepQxZTr0V1chXIyvwJq7l24RYbD8/jH7dndPhuMNlyZwoxae5T3L/vzuRJ\nK1i0ZDg+Pn6B80sAfHz8ePnyNcmSJSZevHjEjx+fXLkyA0Zb9+wxhRGjOpM2rSOtWw7nzRtPbtza\nzulTV2hQry8FCuYItWcfWbHl/NDCFpPuiTtiDJtbeig31Ad1lVK3gK8xjmUN4C4iJ0WkYrDt/mOh\n+scfAA7dauBHwAn4A3guIluC30v/L924do9MWdIEJvAAhYrnxM/vHX/feWyx3r6dJ7l++Q69hzYD\n4PD+czRoVgUHRzvyFcpGucpFOLw/5POh4fHO7x1DO0ziz4u3mL52NNnzZvmk7QR36H8n+OvqHToM\nbA7AKRdXajWuSgpHO3IVyEapSkU56fxpMYfl2bN/efb0FRNHrSFXuuaBn0cPPdjx2zFypWvOvv+d\ntVh3946TXLl0l0EjjLZ22Xeexi2q4JjSjgKFs1GpalFc9kVN3Fev3CF/gWyBP6ADFC+Zh+fP/uXp\nPy9D1Fk0fytWVlZ07mpMQ9m39wztO9bB1jYJVaqVIG++LBx0do2S+MCYkDaw3WSuX7jFnHWjyJkv\nS5h1EiRMQM58WXhw1y3UMi67T3Dzyh26DDbOj+PO56j9QxVSONqRu2A2SlcqwvEoOo67dx7i7e1D\nm1YjSO1YOfADMHPGGlI7VubK5Vsh6s2ftwErK6Frt8YA7P3jBB07fY+tbVKqVS9NvvzZcD5wOkpi\ntCQ2nB+fzCoaPjFYjOmJAx4YPerUFtalBv4OraJSygVwERFroCzGvepdpqQasN1UoWz3vtl3b9Of\nwWdrOATbnwIWA4tFJAVQA+Me+QaMxP6fS5k6BedO/8mrF2+CJPKLZ40ebeq0DiHqeHn6MG7wUoZO\n7EDSZB+ec/Z86x3497dvvTEbwAg3f39/Rnf9Cddjl/hpzciPPkJmzv3hP1w8fY0KNUtbXO/t6c2s\n4UvoNaYjSZJ+iNnL60PMnm+9Pinm8EiVOgVb9owPsbxzq5/IWyAzvQc2Ik++zCHWe3r6MGLAMsZO\nbf+RtvYiqsJOncaeq1fu4OvrF+QH9dnT17GxSUgK+2RByru7PWPSuJVs2TmVePE+PEttHt+bN95R\nFp+/vz/Du/zE2aOXmLV2JAVLhO/88PL05trFW2TOnj7U9T8NW0rfcR2Cnh+e5ufHp53TlhQukpu9\n+xeFWF6jWheaNa9Fm7Z1yZ4j6EQ9NzcPxo9dwu+75gZta0+vwL+/eeMZbecwxPzzQwu/GJPElVLv\nReQM0FBERpvdE3cCsvCRJG62DR/AWUSSYgxzZ1VKeYjIWeB703YD7okXB7ISNIkH7KMApnvlIhIf\nI0mHts8XwAZTnJ3NVvlgTHiLEv/bdgyAqxeMq/pD+1yxd7TD3tEOp3IFaNquJjs2HqJN/ZF06NmA\nFPbJOHX0MsvnbqNG7dKkyxDynvu8qevJmiM93zYoF7isbOUirFm6i+y5MvDE7TknDl0MMrs9vKYP\nXojz70dp3fsHbBLbcMX1w1u2UqV1JFU6R+aMWoaVlRX5i+fGNnky7t9+yOo5m7CysqJ17x8sbnfF\nzPVkypGBqnXLBy4rWaEov/28k8w5MuDh/hzXIxdp2qW+xfrh8ftWo60vnb8NgPMf53BIaYuDox1f\nlS9A2QoFQ9SxsUlIylTJLa4DmDF5A9lzpafu9x/aukLVwvy8aDc5TG19xOUSP/aMeFtb0vnH+rRs\nOprG9YfSoXNdEiWyZvfO42za4Ey3Xg1D9MCGDFhA/YaVKOWUL3BZlarFmTppDbZ2SXA98yd37zyi\nYqWiURLf5EGL2L/jGO37NCZRYmsunzU7P9I5kjqdIxP6zcM2eTLyFclBcntb3B4+ZePynXg8ec64\n+X0tbnfZ9A1kzpGeGvU+nB9OFYuwcfkusuTMwFP355w5cpEWXaOmnZMnT0bFSiUsrsuUKa3FdQP7\nz+D7RtVxKv3hXKlarRSTJi7H1jYpZ89c5c7tR1SuXDJKYrQkpp8fn+wLnNgm0Xm1F1Gm2el7gZ0Y\nPd2UGJPSEgI3LL2xTUS6ABUwJpY9wBg+HwKkBXIopbxMs9P3YiT2JaYyozGS7HWlVBXT/uNjTKwT\nYBBGIu4K5AUyK2X8unkRWQK8xphw9w+QC5gEHFVKBTxmthVjVKAd4I4xye1eaMdesGhOte3QjNBW\nk8OujsXlpcoV4NddEwE4f+ZP5k3ZwLVLd3jz2pP0mVLxXcMKtO9eL8iz4QC3bz6kQZV+bD80M/BF\nL2Dc8x07cAn7d53CJlFC2natS4eelhPiP16hjzM1KNEO94eW7mBAu35N6TCgOTt/3cuWVf/j0b3H\neL71xi5FMoqXK0y7fk3JnCPkSy/u/fWADrX6smLvrMAXvYDR854xdDFH/jiJtU1CmnSqR7OuDUKN\nLbvtx1+9mTpxXYvLvypfgK1/TLC4rkSejpT6Ki8Lfg6ZXP668ZCaFfqz79iMwBe9gNHWQ/suYc+u\n09jYJKRzjzp07R36xUfi+BF7TGrvnlPM/Gkd16/dw8fbl6zZ0tG2Q23adfwuSG/qkMs5Wjcfy7kr\nq7E3exTrnyfP6dVtJocPnsfewZbho9ryQ7OIzai/afb6XHO1i7XH7YHl86PTgKZ0HtiM7Wv3sW3t\nXv6+9QgvT29SpnWgQLFctO3VyOLQ+92/HtC6Rj9+2T8r8EUvYEycmzpkMYf2nMLaJiHNutSlVbfQ\nzwmAiLIAACAASURBVA+AAinSfnR9WKzjl2DwkHaMGdc1yHIX5zO0aDaEy9d+w97+w7PyT548o3vX\nSRx0OYO9Q3JGj+lC02a1IrRPX//XESofE86PCqU7c871RpRlXes0OVW6FqH/HP1U96bXcVVKWb5a\n+8xiVBIH43lujASbBbgFDAd6geXXropIGWAwxiz1VMBzjDelDVdK3TDbbjNgVLDtjgTuBSReU7n8\nwHyMyXDPMR5FswVGmSXx1kBbIB9gx//Zu++wKI4+gOPfQaoFLBh7L4gQGyrWWLDFhr23GHtvYIvd\nV40NrIm9ayxRY4sVjLErRBE1RgE7GkFFASnCvH8cnOABgh6gYT7Pc4/c7Oze78a7m53ZmVl4DOyN\nyfMqJk8ZYBVgh+ZkYYOUsldi7/tDlfjnKKlK/HP2oUr8c5XSSvxzkFgl/rn71Eo8PaS0Ev8cqEr8\n03023emxpJTbgPcXEN4TZ/tJNC3l2OfngISbTvGPuxXNHHQAhBAF0bSwd7+X7zpQN4FDTI2TZwOw\n4QOv9zdQO6k8iqIoip5lsO70z64STw1CCDNgIXAczUC34oAzEAqsTsfQFEVRFOWjZYhKHIgC8gJL\n0Yw0D0Gz0lp7KWXic1UURVGUL0vGaohnjEpcShmBZilURVEU5b9KgMxg3elf5sgkRVEURVEyRktc\nURRFySBUS1xRFEVRlC+BaokriqIo/x0Z7C5mqiWuKIqiKF8o1RJXFEVR/hsEGa5pqipxRVEU5T9C\nqO50RVEURVG+DKolriiKovx3qClmiqIoiqJ8CVRLXFEURflvEGS4lriqxD8TRgYG5DHLlt5hpEgJ\n8/zpHcJHOf7oTnqH8FEqW4amdwgpFh71Zf6gvox4lN4hpNhbmd4RpFyUjNL7MaUa2KYoiqIoypdA\ntcQVRVGU/44M1jTNYG9XURRFUf47VEtcURRF+W8QZLjFXlQlriiKovxHiAw3Ol11pyuKoijKF0q1\nxBVFUZT/DtUSVxRFURTlS6Ba4oqiKMp/g4h5ZCCqElcURVH+EyQgVXe6oiiKoihfAtUSVxRFUf47\nMtg8cdUSVxRFUZQvlGqJK4qiKP8NGfBWpKolriiKoihfKNUSVxRFUf47MlZDXLXEv1Tnzl7DsakT\nxQq0Jl/OptSq2o+N6w9ptwcEBNGl/WQKWDanaoXv+MPdU+cYI4e60NZxXFqGzYMH/rRrNwwLCzvM\nzSvRps0Q7t9/HC9PQMBz2rQZgoWFHba2zXFzO6dznEGDptKsWT+9xnbqwGmmfD+DLlV60qxEa777\nph9rZq8nNDhUm2fuyIU0LNgswUfvOv21+cLehLFgtCttbDrSo+b3nNx3Suf1ti/fRf+GQ4h6G/VJ\ncT96GIDzyJ9oVGc0+XO0IYdpM+7ffRovz+vXoUwat5rmDcdROHc7cpg24/QfXjrHCg0NY2h/V4rl\n60hF6+/ZvVM37kULdlGryhDefkLcbvtPM7bXTFpV6kXdom3oVLM/P/1vPSFxytr//lNq5G2e4ON1\nULA2X1hoGLNGLqJxmU60s+/D8b26MW9euose9T8tZoDHDwMYP2olTes6UzRXe/JkduT+vadJ7uM0\ndDl5MjsyqPfCeOmhoeGMGLAEqwJdqWrTn727/tTZd+nC3dSzH/5JcT9+FMAPo1fSop4zJSzbUyCL\nIw/ei/nBvacUyOKY4CPo5buyfhMazuiBS7Ap2JUatv35LYGYly/cTYNPjPljCcDAQP+Pz5lqiX+B\nvL18aNlkDFXsy7Lkp9FkzmzK3t1/MLjfPCLCI+nT35EJTsvw833Ehq2TOXzoPN07TeXq31vIkSMb\nAH953mLb5qOc81iTZnGHhr6hfv2emJgYs2HDjwgBP/ywiHr1euDltY8sWTIDMGrUHHx87rNjhysH\nDpykXbvh+PgcI0cOCwA8PLzZuPE3vLz26TW+nSt2Y5k3F73H9SR3Pkt8bviyceFWrpz1YtFv8zEw\nMKDb8M4079Y03n5PHz5l1uC5VG9or037ZelOPP68whiXkfjdvMuPwxdQ0rYEBYsXAODZ4wC2Lv6F\nWZunk8kw0yfF7efzmL2/nqZ8xZJUr2mD23HdE7YXga/ZvOEY5SuUoK5DRfbvPZvgsVzn7cT9xBWW\nrRrJjWt3GdB7AeUrlqBESU3cjx4GsGDOL+zcNx3DT4h72097yJ0vFwMm9OSrfLm4fd2PNfO34nnm\nGisOzMMgzi9nj2HtqdXYPt7+mbOaaf/etGQXl05d4YdFI7lzw4/pQxdiVa4EhWLK+t/HAax33Y7L\ntk+LGcDP1599u09TvkJJ7GuW5eTxK0nmv3juJrt++YNs5pl1ti2Zv4tTbldYtGIYN7zvMeR7V8pV\nKEHxkvkBzQmDy487+OW3KZ8U910ff/b/eppyFUtiX6Msf5xIPOYhY9rRqFnVeGlZs70r66ULNDG7\nxMQ8vI8rX8eN+VEAi+buYPPeT4tZSb4MWYkLIXoD44EiQKiUMns6h5Qiu3a4ERUVzY49s8ga82NW\nv0FlvK/5snXzUfr0d+TokYssXDScBo2qUre+HVs2HubShRs0amJPdHQ0I4e4MnJMZ4oVz59mca9a\ntQNf3wfcunWYkiWLAFCunBWlSjVmxYrtjBr1HQC//36KZcsm07hxbRwcqrN+/W7On7/Ct9/WITo6\nmoEDpzJ2bB+KFy+k1/hmrJ9C9lwW2ufla5QjW/ZszB2xkKvnrlGxZnnyF81H/qL54u3n+edfADRs\n76BNu3TSA8dezanRqBo1GlXjxB53/jp9RVuJ/zR1Jd80q4VN5bKfHHeN2rb8c38LABvXHkmwEi9U\n5Cv8/LcDcPLEX4lW4sePetB3YHOaNq9G0+bV2PmLOyfdrmgr8QlOK3FsUwv76p8W99yNk8lh+a6s\nK9Ush3n2rMwY5oLn2WtUrlVeuy1/kbzY2pVJ9Fjn3Dxo+10zaje2p3Zje47uPsmlU1e1lbjrpJXU\nb1GLr6tYf1LMANVr2XD97kYANq87mmQlHhn5ljFDlzPCuT2b1hzR2e521JPeA5rRpLk9TZrbs3v7\nH5xyu6qtECc5r6ZF65pUqfZpcVerZcPVmJi3rj+aZCVepFge7KpaJbrd/agn3/VvRqNm9jRqZs+e\n7X/wp/u7mKc4r6a5HmL+FBlshlnG604XQuQHVgJngfpAg/SNKOUiIt9ibGxI5swm8dItLLIgo6MB\niIx4i6mZZruhYSaMjI0IC4sAYN3qAwQFhTBiTKc0jXvfPjeqVSuvrcABihUrRM2alfjttxPatIiI\nSMzMTGNiN8TY2Fgb+8qV2wkKeo2zc1+9xxe3Ao9VunwpAAL8AxPd79guN0qVK0lRq3fv623EW0xM\njbXPTc1MiAjXvIdL7pe5eu4afX/orZe4DZLR3yeS+csWEfEWM7N3cZtlNiE8puyPH73M6VPXmDbr\n0+OOW4HHsq5QGoBnSZR1Qt5GRmJi+u67ELesz7t58Nc5bwZP+u4Ton0nOWUda5nLHqKjohk0olWC\n2yMi32Iat6zNTAiLidvtqCdn//Rm8v96flrApCzmD4mI0I059vPhftSTc396M3Hmp8esJF+Gq8SB\nUkAmYIOU8rSU8nJqv6AQwkgk91c0Gbp1b4KU4DRyCf6PA3j5Mph1aw5w0s2TwcPaA1C5qjVrV+8n\nMDCIDesOEvw6lIqVSvPs2UumTV7DwsXDMTEx/sAr6df163ewtS2tk25jU5IbN+5on9vbl2fFiu0E\nBr5gzZqdvH4dgp2dDc+ePWfiRFeWLZuSZrF7nfcGoHCphFv93pdu8PjuYxq1c4iXXqZiaY7uOkHg\n0+dcOumBz3U/rCuVISI8kqWTVvD9+F6Y5zBP9fhTqnKV0mzbfIIn/s85ccyDa1f9qFy1DOHhkYwd\nuYIpM3qRM1fqxP3XuWsAFH2vrH/+3wZqF2hJw1IdcO4xHZ+bd+NtL1vJit93nCDg6XPOu3tw29sP\nGzsrIsIjWTjxZwZO7IlFzrQtaz8ff1x/3MEc1/4YGSXc4Vmpcml2bHbjqf9z3I954u3lh11VK8LD\nI5kweiUTp/dItbJOzOwpmyhs3poy+TrTq/1MbnrfjR9zldLs3KKJ+eQxT657+VEpJuYfxqxkQjrE\nHI/QtMT1/UjWSwtRSAixSwgRJIR4JYTYLYQonOzQhbAWQuwUQgQIId4IIW4JIYZ/aL8M1Z0uhFgP\nxJ4mnoipVzdIKXsJIfoBgwErIBj4DXCSUj6Ps/8QoGtMHgPgb2CGlPJgnDxFAb+YYxUFugF5gVzA\nC328j7K2xTh03IUu7Sex8qe9ABgZGeK6bCTtOtYHYPbcQbRrNZ6i+VphaJiJWXMHUqhwHgb2/ZH6\nDnbUc7DTRygp8vx5EDkSqLhy5rTgxYtX2ucLF46jWbP+WFpWw9DQkAULxlK4cH569x5Pw4Y1aNCg\nRprEG+AfwMb5m6lUuwJWMS3y9x3fdQJDI0PqtaoTL737yC5M6D6FTnbdAegwoC1l7azZ5LKV7LnM\n+bZzo1SP/2M4T+xCe8cpWBfTxD10VFuqVrNm7v+2kiu3Od2/S524n/kHsGruFqp8UwHrCpqyNjIx\nolWPJlStU4nsucy5d+chGxftpH9zJ1YfXqit7L8f3ZlRXabSsnwPALoOasPXla1Zu2Ab2XNZ0KJL\n2pe18/CfaOpYnVp1yiWaZ8yETnRuPY1yJTS9BINHtqaKfRkWzPqFXJbmdO3VMK3CxdjYiG7fN6aO\nQ0VyWZpz559HLJm3E0eHsRw6tYCSVgUBGDmhE91bTaNSSU3MA0e0prJ9GVxma2Lu3DPtYk6YSHav\nk15fVYjMgBsQjqaOkcBMwF0IUU5KGfKB/SvH7H8S6AMEoWlwZv3Qa2eoShyYAXgAi9FUsp7AMyHE\nHGB0TLoTUADNf4CtEKKGlDJ2mGUxYD3gg6Y13wI4IIT4Vkp5+L3XmghcAvrF5A3T15u4c/sh3TpO\nwbpsUVyXjsLMzJiD+88wYrALpibGdOzSkLK2xfD6ewt+vo/Jkzcn5uZZOHf2Gvv3/sllrw0EBAQx\nepgr7m6eWFpaMGlqb1q3q6uvED+JrW1pfHyO4ev7gLx5c2NunpUzZzzYvfsYN28eIiDgOYMHT+f4\n8XPkzp2DGTOG0779t3qN4U3IGyZ/PwMDw0yMWTAywTwRYRH8ceBP7B2qYJEzfvewZT5LVhxbiv+9\nJ2S1yIJ5DnP87/mz8+fduOyZS3hYOD9PW82Zw+cwNTOhbd9WtOrdUq/v4WPkL2DJ6UtLuev7BIvs\nWciZy5y7vv4scdnNIbe5vHkTzkTn1Rzcdw4zMxMGD29Fv0GfFndoyBvG9pyJoWEmJrqO0KZb5smJ\n89wh2ucVqtlSrZ4dXesMYsOiHUxZOhqA3Pks2ei2hEf3npDNPAsWOc15dO8JW5fv5qd9PxL+JpzF\nU1fzx6HzmJqZ0Kl/K9r3afFJMSdl17aTXPG4w5kry5PMl69ALtwvLOKe3xPMLWLK2u8Jy1z3sP/4\nHN68iWDK2DUc2n8eMzMTBgxzpM/A5qkSc558Oflx8SDtc/uaNtRtWJH6lYeyaO5OlqzRfAfy5c/F\nsfdivuf3hJ9c97Dn2BzC3kQwddwaDu87j1lmE/oNdaR3KsX8mekLFAespJR3AIQQXsBtoD+wMLEd\nhRAGwEbghJSydZxN7sl54QxViUspfYQQN2Oe3pBSno9pOTsB06SU02PzCiH+AU6jqaj3xuw/Os52\nA+AEUBoYCLxfiT8FWkspZWLxxLT++wEUKpwn2e9j2qTVGBkZsmPPLIyNjQCoW9+O54GvcB69lPad\nHDAwMMDQMBOlSmtaK1FRUYwa6sqEyb3Imy8X3/eYSXDIG7z/2crlizfp0HoCNl8Xp7RVsnt/UixH\nDvN4Le5YCbXQDQ0NKV26mDb2QYOmMW3aUPLl+4quXUcTHByKn98JLly4SosWAyhXzgorq+J6iTP8\nTTiTek3jyb0nLNj1I7nzWyaY79yxCwQHhdCovUOC24UQ8QbBLZ30M992bkSJssVZ++MG/vG6zaoT\nywl4EsCoNmMpXLowlWpV0Mt7+BRCCIqVeBe386if6f5dI74uV5wZkzdwxfM2Zz2W4/84gKYOY7Eq\nU5g69T8u7vA34Th3n86j+09YvmcOXyVS1rHyFMhN+aplufnXPzoxF4xT1gsn/EyLro0oZVOcn2dv\n5O8rd9h8chnPngQyyHEsxawKUbm2/ss6JPgNk8etZcioNpiYGGqnZ0VHRxMZ+Zagl8FkzmKq7WIX\nQlC0+Lu4J45aSddeDbEpV4xZUzZx1fMOf1xawpPHgbRsOJ7SZQrxTb3yCb62vhUomJuq1ctyxUO3\nrOPG/MPolXTuqYl5ztRNeHnewe3SEvwfB9Km0XhKlSlE7TSKWZBuA9taAudjK3AAKaWfEOIM4EgS\nlThQF7BGU9mnWEa8Jv6+hmjKYYsQwjD2AVwAXgPfxGYUQtgJIQ4IIZ4Cb4HImP0TGs65N6kKHEBK\nuVJKWVlKWdkygYE+ibnu7YuNbXFtBR7LrkoZnge+4tm/L3X2+XnZHgwMDOg/SHOid+zoJb7v2xJz\n8yzUb1AZ67JFOenmkewYPoaNTUmuX7+tk37jhg9ly5ZMdL8lSzZhYGDAkCHdADh8+DQDBnTC3Dwr\nDRvWxMamFMeP684l/xhvI98yvf8s/vG6w8yN0yhmXTTRvEd3HscipzlV61f54HHPHD6Hz3U/eo7R\nvIfLJz1o1M6B7LksKGlTArtvKnLZPXXL/2Mc3HcOby8/xk/WxH3imAeduzlgmduCr8uXoF6Dihw/\n9nFxv418y4Q+s/n76h0WbJlKiSTKOiX++P0ct6/70se5KwAX3D34toMDOSwtKG1bnKp1K3LeTXcE\nvz4EBr4i8FkQs6ZsonT+rtrHo4cB7Pv1DKXzd+XY7wkPwzm07zzeXn6MndQFAPdjf9GhW30sc1tg\nW744dR0q4n4sdeL+WIf3n+eGlx9OMTGfPPYX7bvWJ1dMzHUcKnLyM4s5ldgA3gmkXwc+NJWjVsy/\npkKI80KISCHEv0KIxUIIsyT3JIO1xBPxVcy/dxLZngs0gxbQtLxvAEOB+2gq8hlozqLe56/fMN/J\nkzcn1719iYiIjFeRX754E1NTY3LkzBYv/xP/QGbPWM/uA3PJlOnd3M3QkHc9/MHBYSR9yvHpWras\nz5gxc/H1faCdHnb37kPOnPFkzpzRCe7j7/8vU6cu5fDh1fFiDwl5Eyf2ED5wvpQs0dHRzB46jytn\nvJixYQplk5jW9OLZCy7/4UnLns0xTGTgUqywN2Esn7KCgVP7kjnru/nCYaHvyv9NaBiSVP4PSKHQ\n0DDGjV7B/+b2JVu2d3GHxPnchASH8TEfnOjoaKYOmo/HGS/mb5qc5BSyuJ48/JerF2/wTZNqCW4P\nCw3D9YeVDJ/WlyxxyvrNm3cxh4a80cvnJSFf5cnB7sMzddL795iPtW0RRji3p0zZIjrbQ0PDmeS0\nmulzvydrnLKO+x0NCXmT6t/RuB49eMbFczdo3Nw+we1vQsOZ7LSaKT8mEXNw2sYMqdYStxRCxD37\nWimlXBnneU4SHvP0HMjxgWPHzvPdDiwFxgGVgelAIaB1IvsBqhIHiJ3P0oiE/xNitzcBLIAOUsqH\nsRtjBjQkJNU+uv0HtqZ756l0aD2BPv0dMTMz4dCBs+zc7sbg4e10WujjnZbTul1dqtq/OyGs72DH\n3NmbMLfIgselv/HzfUSduhVTK2QA+vbtwNKlW3B0HMTMmcMRQjBp0iIKFcpL//4dE9xn1Kg5dOjw\nLdWqvev6bNiwBjNn/oSFRVYuXryGj88D6tdP+Ec9JZZM/IlTB07TZVhHTM1MueHxt3Zb7nyW8brV\nT+w5SXRUdKJd6XFtcf2FgiUKUqdFbW1apdoV+W39AQqVLETg00D+On2Fdv2S/K4m6bfdpwG48pfm\nXPTY0ctYWlpgaWlBzW++1qQduUxoSBg3YkYcn/nTm8DAV2TOYkrDxpV1jjlv1i+UKl2Q1u3exV3X\noSKrfz5AaatC+PsH8of7FQYPT3ncC8b9hNv+0/Qc0RHTzKZ4xynrr/JZ8lV+SxZPWY2BgQE2dlaY\nZ8/GfZ+HbFy8EwMDA3qOSPjzss7lFwqXLIiD47uYq3xTkV/XHqBIyYIEPHmOx59X6Tzg48t6/54z\nAHj95QOA2xFPcuU2J5elBTVq22rLOy5TU2Nyf5U9wW0AC+dsp0TpAji2raVN+8ahPGt/PkTJ0gV5\n6v+cP929GDgs4elqH3Lg/ZiPepLLUhNz9dq2TBu3FgMDQaWqVmTPkRWf249YOv9XDAwMGObcPsFj\nus7ZTolSBWgZN+b65Vm34hAlrQryxP85p0960f8jY/4oAkTq9C8HSCl1vyT6ERvxZinl5Ji/Twoh\nMgFzhBDWUsqbieyrKnHgGBANFJZSHksiX2xlHRmbIIQoDdQEHia4Rypp1bYOv+6bg8v8bQwZMJ/w\nsAiKFc/PwsXD6d03/oCdP9w9cXfzwNN7Y7z0uQuHMHywC991m0HOXOasWDOOMmWLpmrcWbJkxs1t\nAyNHzqZ7d2eklDg4VMfVdQJZs2bRye/mdo7jx89y61b84QaLFk1kwIApdOo0ily5srNhw5wku+OT\n65K75kR76+LtbF28Pd627iO70GN0V+3zYztPUNSqCKW+Tvp17995wL4NB1h2aFG89K7DO/Ei4CUL\nRrtibGpCn/G9qFyn0kfH3qvL7HjPxwzTDKqqWftrDhybA8Dooct4cP9fbZ45MzULxBQq/BVe/6yL\nt/8/tx6wZsUB3M/Fj3vMuE48e/qSIf1dMTMzYcrMXtRvmPK4z8Vcutngup0NrvHLuvfozvRx6kpx\nq8Ls3vA7+7ceITQkDIsc2bCrVZ7eoztTpGRBnWPevf2AX9cdZN1R13jpvUZ25Pmzl8wauQgTU2MG\nTuyFfd2PL+s+XefGez52xM+AZtGdPUf+l+Lj3b71kHUrDnHsTPzLpqPGdiDg6UtGDlyCqakxP8zo\nQd0GH3ei3b9b/JgnxMRcvbYtuw7/Dyvrwmxc/TvbNhwjJDiMHDmzUbNOOUZO6EjJ0rplfefWQ9av\nPMTvp+PHPHxsB579+5LRMTFPmN6DOh8Z8xfmBQm3uBNroccV21B8v/45CswBKgCJVuIitbqVPldC\niAZoCquelPJkTNosYCSwBPgDzUjyQmiud6+WUroLIWyAK2imASwA8gHT0JwAGEgpi8YcqyiaKWZ9\npZSrkxtXJTsreer8ik9/g2koq1HarfamT8cfJXbl5PNWOekxX5+lmy+/zN+XEuZpv+73p3r7BRb1\nt7VGcdXzjt46wE2LlpFFflj54Ywp9E/fOh5JtcSFEG6AsZSy1nvpJ9HUs3US3FGTpxuwCWgppdwf\nJ70imhlUXaSU2xLbXw1sA6SUE9CMEv8G2IFmjvhYNGdQt2PyXEczR7wIsA9wRnPtQvduC4qiKEpG\nsg+oJoTQTpGJadDVjNmWlN/RzC9v/F56k5h/LyW1c4brTpdSHieBm9VJKTehORtKat8daCr5uH55\nL8/dhI6vKIqipC4BGKTPr+8qYAjwmxDiBzRjomYADwBtF6sQogiadUamx05pllIGCiFmA5OEEK/Q\n9PZWBiajWYwsya7DRCtxIUSHlLyDmApOURRFUdJNeswTl1KGCCHqAy5oGoMCzWymEVLK4DhZBZrF\nv97vBZ+OZkrzIGAMmtlN89CcCCQpqZb4L0lse59Et4WqKIqiKBmClPI+0PYDee6ScE+wRLMgTFKL\nwiQoqUo8/e4lpyiKoigfIaPdijTRSlxKeSstA1EURVEUJWVSNLBNCGEF1Eazitl6KeXTmJXMAqWU\noakRoKIoiqIkiyBd7mKWnpJViQshjIC1QBc0/fkSzVzrp2iWibsOTEilGBVFURRFSUBy54nPQHOX\nlr5o5knHPdU5hO78NkVRFEVJc8JA/4/PWXK707sCk6SUa2PWc43LF819thVFURQl3aTjrUjTTXLP\nMXKT8G3WYpnqIRZFURRFUVIguZX4PSCxmyZXJmZpUkVRFEVJN0LTEtf343OW3Ep8MzBRCNEWzWoz\nAFIIUR0YBaxPhdgURVEURUlCcq+JzwYqATuB2CXk3IFswB7ANZH9FEVRFCXNfO4tZ31LViUupXwL\ntBZCNERzZ5XcaO6BelhKeSQV41MURVGUZEunG6CkmxQt9iKlPIbujcsVRVEURUkHKV2xrTpQHSgA\nPATOSynPpUZgGY0QhphmypHeYWQI3+TNk94hfJQyg/zSO4QU81pqmd4hfJQv8bv45m1AeoeQYpl0\nZix/mow4xSy5K7ZZANvQLOoigBAgC5rBbb8DXaWUQakWpaIoiqIoOpI7On0R8A2aFduySSmzoRnU\n1g+oixrYpiiKonwGMtoUs+R2p7cCJkop18YmSClDgDVCiGzAVOA7/YenKIqiKMkkQGSwkW0pWRX2\nRhLpUg+xKIqiKIqSAsmtxPcDbRPZ1gY4oJ9wFEVRFOXjqe70GEKIGnGebgeWCSF+RbPgy1MgD9AB\nsAMGpWaQiqIoiqLoSuqa+Gnid5MLoBDQOiY97vnJPt4tx6ooiqIo6eJzbznrW1KV+LdpFoWiKIqi\nKCmWaCWullNVFEVRviRqsRdFURRF+VIJtXZ6ooQQpdHMBbcCTN/bLKWUzfQZmKIoiqIoSUvusqt2\nwJ9oRqUXBm4BOYGvgMfA/dQKUFEURVGSK6N1pyd3nvgc4CBQCs1lh25SyrxA85hjjE2d8BRFURRF\nSUxyK/HywHogOuZ5JgAp5SFgFjBX75EpiqIoSgoJA/0/PmfJvSZuAgRLKaOFEM/RLPQS6wZQTu+R\nKYqiKEoKZMTR6ck9x/AFCsb8fR3oFWdbN+BfPcakKIqiKEoyJLcS/x1oEPP3bMBRCPFcCPEv0BNY\nnBrBKQk7euQsDRv0pWB+B7KYVaFo4UZ07ujEjRs+2jwBAS9o33YUuXLUokK5tri7XdQ5zpDB+WNl\n5gAAIABJREFU/6Nl8yFpGToPHvjTrt0wLCzsMDevRJs2Q7h//3G8PAEBz2nTZggWFnbY2jbHze2c\nznEGDZpKs2b90irseJo3HYqJYWWmTFquTQsIeEmHdk7kzlmHiuU74O52SWe/oUPm4NhiuN7j2Tqq\nDr4r2iX4WDesFgC2hbOzblgtzs5pxs2lrbkwtzlrh9SkYvGc8Y5lapSJOd3t8FzYEveZTWhWuaDO\n6/VrVJqDPzQgUyrM5Tl39hqOTZ0oVqA1+XI2pVbVfmxcf0i7PSAgiC7tJ1PAsjlVK3zHH+6eOscY\nOdSFto7j9B5bQr7k7+Kpk1doVG84X1k0pXDe1vT9bg7/Pn0RL09gQBBdO0ylYO6W2Ffswx/uf+kc\nZ+TQRbRznJBWYSdNgBBC74/PWbK606WUE+L8fVgIURtoB2QGDksp96VSfFpCiKnAFMBISvk2tV/v\nc/b8eRCVKlkzYEAHcufOwf37T5g3dy21avTgr6s7KVIkP2NGL8DH9yHbfpnLwYOn6NhhDLduHyBH\nDnMAPDxusHnTATyv7EyzuEND31C/fk9MTIzZsOFHhIAfflhEvXo98PLaR5YsmQEYNWoOPj732bHD\nlQMHTtKu3XB8fI6RI4dFTOzebNz4G15eqf6x07H9l8Nc8/pHJ915zEJ8fR+yZdscDh36k84dx3Lz\nn73a8vb0uMmWTQe5/Nc2vcc0eZsnWU2N4qVVKp6LHzqU58RVzQmSeWZj7v0bzK9n7/JvUBi5spnQ\nu0Fpto2uS4d57njd1fx4D2hiRa2yeXBaf4kyBS1Y8F1Vrt9/yd1/gwHIm92MwU2t+W7xaaKi9Xvz\nQm8vH1o2GUMV+7Is+Wk0mTObsnf3HwzuN4+I8Ej69HdkgtMy/HwfsWHrZA4fOk/3TlO5+vcWcuTI\nBsBfnrfYtvko5zzW6DW2xHyp38Wzp6/RqtlYGjSqwqZfpvD8+StmTl1HiyZOnDq/HBMTYwDGO/+E\nn+9j1m+ZpCnvztO5enNjnPL+h1+2HOPs5ZVpFrsS30ct9iKlPA+c13MsSjJ16vwtnTrHXxW3SlVb\nbMu2Yvevxxk5qgdHDp9h8ZJxNGpcg/oOVdm4YR8XznvR5NtaREdHM2Tw/3By/o7ixXVbWqll1aod\n+Po+4Natw5QsWQSAcuWsKFWqMStWbGfUKM0t6X///RTLlk2mcePaODhUZ/363Zw/f4Vvv61DdHQ0\nAwdOZezYPhQvXijNYgd48eIVTqNdmLdgJD26/RBv25HDZ1m0ZCyNGlenvkMVNm04wIXz12jybU2i\no6MZOng2Y5x6pkp53/F/rZPWqVYxwiOj2H/pAQBn//6Xs3/Hv+p16vpTLi9oQetqRbSVeF3bvGx0\nv8MJL39OePnjWLUwNct8pa3EJ3Uoz+8eD/H0DdT7+9i1w42oqGh27JlF1qxmANRvUBnva75s3XyU\nPv0dOXrkIgsXDadBo6rUrW/Hlo2HuXThBo2a2BMdHc3IIa6MHNOZYsXz6z2+hHyp38U5MzdSqHAe\ntu6chqGh5rYXVmUKU7fGYDau+52+AxwBOHbkEgsWDaVBoyrUrV+JrZuOcunCTRo1qaop76GLGDGm\nU5qVd3J85g1nvfvMx90pyZUrl6aVminmCxkREYmZmWZNHkNDQ4yNjQgLiwBg1cpfeRUUzBinXmka\n4759blSrVl5bgQMUK1aImjUr8dtvJ7RpurEba2NfuXI7QUGvcXbum6axA0wYv4SyNiXo2KmJzraI\niEhMTU2Ad+UdHq6JefWq3QS9Cma0U480idPUKBPf2hXEzcufoNDIRPOFRrwl4m00UVHvWtRGmQwI\ni4zSPn8TEYWJkeYz9Y1NHuytcjNn97VUiTsi8i3GxoZkzmwSL93CIgsyWjMxJjLiLaZmseWcCaM4\nn+t1qw8QFBTCiDGdUiW+5PoSvouXLt6kvkMlbQUOUMnOipy5zDnw2xltWmREJGamccvbUPu5Xrf6\nIK+CQhgxukOaxv4hGe1WpIlW4kKIm0KIG8l8XE/DmIsJIQ4KIYKFEPeEEJOF0EwCEEKYCiFchBDe\nMdufCCH2CyHKvPfeegkhpBDiGyHE3pi8gUKIZUIIszj5isbkGySEWCiE+FcIESqEOCCEKBon334h\nhM7FIiFEMSFEtBBiQGoURFRUFBERkdy+fY9BA2aSN68lnTppWgVVq9qyauUuAgNfsnbNHl6/DqGS\nnTXPnj1n8qSlLF4yXttlllauX7+DrW1pnXQbm5LcuHFH+9zevjwrVmwnMPAFa9bs5PXrEOzsbHj2\n7DkTJ7qybNmUNI/9zOkrbNl0kEVLnBPcXqWqLatX7SYw8CXr1u7l9esQKlay5tmzF0yZ9BOLFo9N\ns5gbV8xPNjMjfj1/T2ebEGBoIMifw4xpnSoC8MtpX+32K3ef07Z6EXKbm1K7bB7KFsrOX36BGBsa\nMLVjBebuvsbLkIhUibtb9yZICU4jl+D/OICXL4NZt+YAJ908GTysPQCVq1qzdvV+AgOD2LDuIMGv\nQ6lYqTTPnr1k2uQ1LFw8PM0/G/DlfRczZTLAyNhIJ93ExIgbN+5qn9tVsWbt6gMEBgaxcd3vBL9+\nQ4WKpQh49pLpU9ayYNHQdClv5Z2kutOvEv9WpJ+LPcA6wAVoAUwDHsSkmQDmaAbfPQJyoLnX+Tkh\nhLWU8sl7x9oM7ACWA1WByUAW4o++BxgPXEGz7OxXaObGHxVC2EgpI4GfgINCiKpSyrijVvoBIcCW\nT3/bumpU746nxw0ASpYsxNHjK/nqK81ApXkLxuDYYih5v6qLoaEhc+ePonDhfPT5fgoNGlTDoUG1\n1AgpSc+fB2mvA8aVM6cFL1680j5fuHAczZr1x9KyGoaGhixYMJbChfPTu/d4GjasQYMGNXSOkZoi\nIiIZPGgWI0d1w8qqaIJ55s0fSauWI8ifpwGGhpn4cd5IChfOS78+03BoUBWHBvZpFm/rakUIeBXG\nH97vf9xhad9qfGun6bYNeBXG90tOx+uOX3zgBuuG1uLCvOYArDhyi798nzO0mTWBwRHsOHM31eIu\na1uMQ8dd6NJ+Eit/2guAkZEhrstG0q5jfQBmzx1Eu1bjKZqvFYaGmZg1dyCFCudhYN8fqe9gRz0H\nu1SLLylf2nexZOlCXLp4M17a/XtPeeL/HCOjd9XC7HkDaN9qIsXyt8XQMBP/+3EAhQrnYVC/edRL\nx/JOyufecta3pO5ilr59UolbIKVcF/P3cSFEfaAzsE5KGQR8H5tRCJEJOIJmudjOaCr+uA5JKcfE\n/H1UCCGB6UKIWVLKuKOXXgOOUsromOP+g+Z+6z2ANcBhNNPw+gMXY/IYoan0t0gpdS9aavL0Q1PR\nU7hwvhQXxPoNM3n1KgQ/34csXLiRbxsP4OSpdRQtWgBb25Lcur0fX99H5M2bC3PzrJw58xd795zg\n2vU9BAS8YNiQ2Zw4cYHcuXMwddog2rVvlOIYUoOtbWl8fI7h6/uAvHlzx8Tuwe7dx7h58xABAc8Z\nPHg6x4+fI3fuHMyYMZz27VPvzrkL5m3gzZtwxk3onWgeG9uS3Pxnb7zyPnvmCnv3uHPVexcBAS8Z\nPvRH3E5cxDJ3dqZOG0jbdg0SPd7H+srClJrWeVjvdjvBgWdzdl9jxZFb5MtpRve6JVk9pCbdXf/k\n2j3NNfGnL8NoOuM4hS2z8OpNJC9DIihkmYW+jUrTYd5JTI0y8UP7cjSqWIA3EVGsOf4PG919dF7n\nY9y5/ZBuHadgXbYorktHYWZmzMH9Zxgx2AVTE2M6dmlIWdtieP29BT/fx+TJmxNz8yycO3uN/Xv/\n5LLXBgICghg9zBV3N08sLS2YNLU3rdvV1Ut8SfnSvosDh7Shb6/ZTJ+yloGDW/Pi+WuGDXbBwEBg\nEGfWQVmbYly9uQk/X3/y5M2BuXkWzp/1Zv/e01y6upbAgCBGD18cU97Z+WFqL1q3rZOqsSvxfYl3\nMTv43nNvoGLsEyFEB2A0mhu1WMTJZ5XAsXa89/wXYCaaVnncSnxXbAUOIKU8I4R4CFQH1sQsgrMC\nmCKEGBVzMtEKzaI4KxJ7I1LKlcBKALvKNinu9bC2Lg6Avf3XNPm2JiWLN2Xuj+tY/pNm0JWhoSGl\nS2uuP0dFRTF0yGwmTx1Ivny56d5tPMHBodz2OcjFC9do5Ticr8uVTrSlqQ85cpjHa3HHSqiFrom9\nmDb2QYOmMW3aUPLl+4quXUcTHByKn98JLly4SosWAyhXzgorq+J6j/n+/SfMmb2On1f+QHh4JOHh\n764xh4dH8vLla7Jly0ymTJl0ynvY0B+ZNKU/+fJZ0rP7DwQHh3Lrzm9cvOBNm1ajsP26pN7Lu5V9\nYTIZCH49p9uVDvAgIIQHASF43XuBm5c/h6c0YpSjDd8tPh3/fQeEaP+e2qkCO07f5e+HQYx2tOHr\nojloMu0oebKbsd2pLnf8X+sMmvsY0yatxsjIkB17ZmEc09Vbt74dzwNf4Tx6Ke07OWBgYIChYSZK\nldYMaoyKimLUUFcmTO5F3ny5+L7HTIJD3uD9z1YuX7xJh9YTsPm6OKWtCn9yfEn50r6LHTs78M+t\n+yxx2cn8OVsRQtCmfV0aNbHn5nW/eHk15V1QG/uoYYsZP6mnprx7ziI4+A3Xbm3m8sW/6djmB2xt\ni1PKKm0HncYSZLy7mH2JA9uev/c8nJi7qgkhWgDbgZtAF8AeqAI8Q/fOa6BpoSf0vMAH8sWmxc23\nBs1ytN1jng8ALkopdSdWpoLs2c0pUbIwPj4PEty+dOk2DAwEgwdrOliOHjlLv/7tMTfPSoOG1Slr\nU4ITJ1J3woGNTUmuX7+tk37jhg9ly5ZMdL8lSzZhYGDAkCHdADh8+DQDBnTC3DwrDRvWxMamFMeP\n684l1wc/34eEhYXTq8ck8ljW0z4AXBZuIo9lPbyv3dHZb9nS7RgYCAYN1gz6OXrkHH37tY0p72qU\ntSmO2wnd+cKfqk31Itx48JK/HwZ9MG9klOTvh0EUyZ010TwNy+fHumB2XPZphr18Y5OXX8/d43lw\nBDcfBnH6xlO+scmT6P4pcd3bFxvb4toKPJZdlTI8D3zFs39f6uzz87I9GBgY0H9QawCOHb3E931b\nYm6ehfoNKmNdtign3Tz0El9yfQnfRYBJU7/D7/GvnPNYye17O1i3aSI+dx5RraZtovv8vGwvBgaC\n/oM0o9ePH73E931bxJS3HdZli+Lupjt3P83E3IpU34/P2ZfYEk9KJ+COlLJXbEJMt3bORPLnQbMC\nXdznoLme/n6+hPa9EvtEShkohNgB9BdCHAHqAX1SFP0nePo0kFt/+9G5S1Odbf7+z5gx7WcOHFpO\npkzvRqOGhLx593dwKDKVR0C0bFmfMWPm4uv7QDs97O7dh5w548mcOaMT3Mff/1+mTl3K4cOrE409\nODgEmUrBl69gxdHjP+ukN2owgC5dv6XXd46UKBm/1eHvH8DM6SvZf3BJvJhDQ+PGHKr3mL8ukoPS\n+S2YueNqsvKbGmXi6yI58H2a4NUeTI0yMbljeWbuvEpI+LulGTIbv/vZyGxiiEA/v3J58ubkurcv\nERGR8SryyxdvYmpqTI6c2eLlf+IfyOwZ69l9YG78cg4J0/4dHByW6p/r930J38VYWbKYYWOr6UU4\nduQi/9y6z7IVCX8Xn/gHMmfmRn7dPzt+7KFxy/tNqn0XlYT91yrxzMD7C8F0J+aGLQnoALjFed4J\nzU1eLryXr50QYmqca+I10SxD+37zb3lM2mogCE33vN61azOSipWs+frrUpibZ+Wff+6xeNFmDA0z\nMXKU7jQmp9ELaNe+EdWqvVvivkGDasyetQoLi6xcuuSNj89D6tWrkhrhavXt24GlS7fg6DiImTOH\nI4Rg0qRFFCqUl/79Oya4z6hRc+jQ4VuqVaugTWvYsAYzZ/6EhUVWLl68ho/PA+rXT53BQdmzZ6NO\n3coJbitcOF+C25zHLKRt+4bYV/tam+bQoCqzZ63B3Dwrly9dx9fnkd7Lu3W1wkRGRfPbRd07A8/s\nWomgkAiu3XvB8+BwCuTKTI+6JcltYcrodbqrywEMbWaN79NgDnk81KadufmU7vVK4PPkNXmym1Kj\nzFesPqbbu/Ix+g9sTffOU+nQegJ9+jtiZmbCoQNn2bndjcHD2+m00Mc7Lad1u7pUtS+rTavvYMfc\n2Zswt8iCx6W/8fN9RJ26Fd9/Kb35Ur+LV6/c5tiRS5SvoOkBO3fWm8ULdzJidEfsq9skuM94559p\n3bZOvPKu52DHvNlbMDfPgsflv/HzfUydeqlX3h+i6U7PWCcR/7VK/DDQSgjhAhwAKgNDAd1+OI2m\nQoh5wFE018GnABullO//KmUD9sZc986NZvT7bWBj3ExSyvMxU82+AZZIKUP187bis69Wjp07j+Ky\ncCMREW8pVCgP39SpzNhxvSlaNP6VAHe3i5w4cYHrN/fGS1/o6szggTPp2mUcuXJZsHbddMqWLZEa\n4WplyZIZN7cNjBw5m+7dnZFS4uBQHVfXCWTNmkUnv5vbOY4fP8utW4fjpS9aNJEBA6bQqdMocuXK\nzoYNc5Lsjk9L7m6XcDtxkWs3fo2XvsBlDEMGzaZ71wnkzJWdNeumYl1Wf9fwDQ0ELaoU5tT1JwS+\nDtfZftXvOR1qFaNT7WJkNjHkycs3XPV7zriNl7n1WHecQvE82ehWtwSOs07ES1966CaW5qb82LMy\nYRFRzN3jzembCV1tSrlWbevw6745uMzfxpAB8wkPi6BY8fwsXDyc3n1bxMv7h7sn7m4eeHrH+woy\nd+EQhg924btuM8iZy5wVa8ZRpmxRvcSXkC/1u2hsbMTRwxdYtGA74eGRWJUpjOvS4XTrqbsGAsAf\n7n9x0s0Tj2vr4qXPXTCYEUNc6d19JjlzmvPzmrGUsS6S4DGU1CG+lK6PxJZdFUKsB+pKKYvGzBef\nDvQGsgOXgBFopqWdjO1mF0L0QjMlrQ6aQXAOQASwDRgjpXwTk68o4AcMBkqiadVnAdyBIVLK+CNA\nNPuMRzMFzVZKmez583aVbeSFi1uTm/2zYGhg9uFMn6GIqIS7jz93ZQbpfNw+e15LLdM7hI9imilH\neoeQYm/eBqR3CClWp/ogPD1u6e2qs0XpMrLG0tX6OpzW4ca1PaSUCXfJpbNkt8SFEHmA4WhamTmB\ndlLKG0KIQWgGcF1OpRgBkFJOBaYmkN4rzt/RwA8xj7iKJnLYx1JKx2S8fISUchQwKhl5mwOnU1KB\nK4qiKMrHSFYlHrPi2SnACE3rtjrvRntbATXQ3JI0QxJCmACV0NzprQaQnBMDRVEURc++xClXnyK5\nLfH5aLqVGwPBaLqeY51Bc404I8sHnEVz7X1WWtzVTVEURYlPDWxLXB2gm5TyZcwqaHE9QVOJfTGk\nlOuB9cnIdxc+PH8mufkURVEURZ9SMjo9KpH0XMCbRLYpiqIoSpr53Bdn0bfkXj64zLuVyN7XFnVv\ncUVRFEVJc8ltif8POCyE2I/mjlwS+EYI0R/Ngin1Uik+RVEURUkWgRrYliAp5fGYG4u4As1ikhcC\nj4EOUsozie6sKIqiKGnhC1jrXN+SfU1cSrlbCLEHsEFzT+1A4Frcu3spiqIoipJ2UrTsqtQs7+ad\nSrEoiqIoyicRaoqZrpiu9CRJKd+/N7eiKIqiKKkouS3xxO7GFfeUR1XiiqIoSrrRLPaS3lGkreRW\n4tYJpOVCs054O6Cn3iJSFEVRlI+kRqcnQEp5K5FNZ4UQUcBAdO+trSiKoihKKtLH/cTdgd16OI6i\nKIqifDSBVGunf4TKQKgejpOhSfmWsKgX6R1GimT9Qu8n/iYqML1D+CjnXY3TO4QUG/KF9s+trPk2\nvUNIMf83X97PcES0mqH8qZI7Ot05gWRjwBZoDazSZ1CKoiiK8jHUwLaEzUkgLQp4BLgA0/QWkaIo\niqIoyZLcSjyhftNItVqboiiK8jlRo9PfI4QwBqYCu6SUHqkekaIoiqJ8BJEB107/4EmLlDICGA5k\nSf1wFEVRFEVJruR2p18FygKnUjEWRVEURfkkGW2KWXIvHzgDY4UQDVIzGEVRFEVRki+5LfG1QHbg\niBAiFHhC/HXTpZTSSt/BKYqiKEpyqbXTE+dB/EpbURRFUT47anR6AqSUnVI7EEVRFEVRUibRkxYh\nhK8QonxaBqMoiqIon8JASL0/PmdJ9TwUBUzSKA5FURRFUVJIHzdAURRFUZR0pwa26fq8+xEURVEU\nJVYGXLHtQ5X4NCFEQDKOI6WUPfURkKIoiqIoyfOhSrwCEJ6M46gWu6IoipKuBBlvitmH3m8rKWWx\nZDyKp0m0ita5s9dwbOpEsQKtyZezKbWq9mPj+kPa7QEBQXRpP5kCls2pWuE7/nD31DnGyKEutHUc\nl5Zh8+CBP+3aDcPCwg5z80q0aTOE+/cfx8sTEPCcNm2GYGFhh61tc9zczukcZ9CgqTRr1k/v8T16\n+AynEcto+M0I8mVvSXaTxty7+0Qn38sXrxk6wIXi+duTP0dLHJuM5bq3X7w8oaFhDOm/kKJ521Kh\nTC927zypc5xF83dQs/IA3r6N+uiYHz8MYPyolTSt60zRXO3Jk9mR+/eeJrmP09Dl5MnsyKDeC9+L\nOZwRA5ZgVaArVW36s3fXnzr7Ll24m3r2wz8p5oQcc3JmQ516eK5ek2iecwsWsqFOPf6c+b946W/D\nwjjz41y2NW/Jr5274ufmprOv99Zt7Ov9PdF6jvt9zZsOxcSwMlMmLdemBQS8pEM7J3LnrEPF8h1w\nd7uks9/QIXNwbDFc7/E8eRTADKcVdGzoRPl87bDK3pKHCXw+bnr58n3bKVQs0IFKhToyoNNM7vnG\n/26+CQ1nwpDFVC3ahQYV+nFot+7nY9WiX2lZc5jePx+fOyFEISHELiFEkBDilRBitxCi8EccZ5wQ\nQgohTicnf0Y7aflP8PbyoWWTMURGvmXJT6PZsmM6lSpbMbjfPFav+A2ACU7L8PN9xIatk/mmbkW6\nd5rKixevtcf4y/MW2zYfZb7LsDSLOzT0DfXr9+Tvv33ZsOFHNm2ay+3b96hXrwchIaHafKNGzcHH\n5z47drhSr5497doN58WLIO12Dw9vNm78jSVLJuk9Rl+fx+z99RTZs2elek3bBPNIKenUZgonjl5m\nrssgNv4yici3UbRo5Myjh8+0+VzmbefkCU+WrxpD156N6P/dPHxuP9Juf/TwGfPnbGPhkqEYGmb6\n6Jj9fP3Zt/s02bNnxb5m2Q/mv3juJrt++YNs5pl1ti2Zv4tTbldYtGIYnbo7MOR7V3zvvPshf/ww\nAJcfdzB30YBPivl9vsdP8OKOT5J5/r12Dd9jxzDKonsvpmtbtuJ/2YOa48dS8tsmnP7fbF49fKjd\nHvLvM7w2babaqJEY6DHu923/5TDXvP7RSXcesxBf34ds2TaHOnUr07njWF68eKXd7ulxky2bDuKy\nyEnvMd3z9ef3vacxz56VytVtEsxz1+cxXZqOJ/hVKPNWjmLW0mE8uv+Urk0nEPjspTbfSpddnD15\nhdnLh9OmqwPO/V246/Pu8/HkUQA/zd/B1IUD9fr5SIn0mGImhMgMuAFlgJ5Ad6AU4C6ESPbNw4QQ\nxYEfgH+T/X6Tm1H5OEKI9UKIu/o85q4dbkRFRbNjzyyat6xF/QaVWbx8NFXsy7J181EAjh65iNO4\nbjRoVJU58wcTGfmWSxduABAdHc3IIa6MHNOZYsXz6zO0JK1atQNf3wfs3buMVq0a4OjYgH37lnPv\n3mNWrNiuzff776eYOHEAjRvXxsVlPJGRkZw/f0Ub+8CBUxk7tg/FixfSe4w1a3/N7Qfb2blvJq3a\n1k4wz6H95zh/9jo/r3WiXcd6NGhchW2/TiM6OppFC3Zq8x0/cpm+A1rStEV1nMZ3oVjxfJx0e9cj\nMn7Mzzi2rY19Ij+syVW9lg3X725k697JtGhdM8m8kZFvGTN0OSOc25M9e1ad7W5HPek9oBlNmtsz\nalwHihbPyym3q9rtk5xX06J1TapUs/6kmOMKf/2aS8uWUXnwoETzRL99y7kFCynXrRvG2XTjfnTh\nImVat6JwzZqU79GdbPnz8/jyuzsnX1q6lCJ16/CVbcInZvrw4sUrnEa7MHf+SJ1tRw6fZdz43jRq\nXJ35C0YRGfmWC+evad5bdDRDB89mjFNPihcvqPe4qtS04eztTazaOYUmrRL+fKxy/ZVMBgas2jmF\nBs2q0cSxJqt2TiHoxWvWLNmjzXfquAdd+zbDoak9g5w6UqhYXs6evKLdPmv8apo41qSSvf4+Hyll\nIPT/SIa+QHE0vdd7pZS/AS2BIkD/FIT/E7AFuJns95uCgyufiYjItxgbG5I5c/xp/BYWWZDR0QBE\nRrzF1Eyz3dAwE0bGRoSFRQCwbvUBgoJCGDEmbRfi27fPjWrVylOyZBFtWrFihahZsxK//XZCmxYR\nEYmZmWlM7IYYGxtrY1+5cjtBQa9xdu6bKjEaGHz4K/H7wfPky5+Lb+pW0KZZWGShSbNqHDrwrus/\nIiJS+38AYJbZhLCwSACOH7nE6VNeTJ/VJ01ijrXMZQ/RUdEMGtEqwe0RkW8xNTPWPjczMyEsXFP2\nbkc9OfunN5P/p98xrB4/ryBHsWIUb+CQaB7vbb8go6Kx6dQxwe3RbyPJZPKurDOZmhAVoYn70YWL\nPLlyBbsBKfktTbkJ45dQ1qYEHTs10dkWERGJqWns99EQY2MjwmPKdfWq3QS9Cma0U49UiSs5n4+r\nl29RoaoV5nFO7PIWsKSUdRGOHzivTYuMeKt9H6D5fETEfKZPHffgwulrOE3vpb/gvxwtgfNSyjux\nCVJKP+AM4JicAwghugCVgPEpeeFE/3ellAZSyospOZiSNrp1b4KU4DRyCf6PA3j5Mph1aw5w0s2T\nwcPaA1C5qjVrV+8nMDCIDesOEvw6lIqVSvPs2UumTV7DwsXDMTEx/sAr6df163ewtS3DedrhAAAg\nAElEQVStk25jU5IbN7Sffezty7NixXYCA1+wZs1OXr8Owc7OhmfPnjNxoivLlk1J89jj+vvGPazL\nFtVJt7YuwsP7/xIc/AaAylXKsG3zMZ74B3Li6GWuXfWlin0ZwsMjcB65nKkze5Mzl3maxe3n44/r\njzuY49ofI6OEx7RWqlyaHZvdeOr/HPdjnnh7+WFX1Yrw8EgmjF7JxOk99BrzU69r+Bw9iv2IxK8F\nv3r4CK9Nm7EfOQIDw4TjtrS2xufIEUIDA3l08SIv7viQu2xZoiIiuLBoMZX69cPUwkJvcb/vzOkr\nbNl0kEVLnBPcXqWqLatX7SYw8CXr1u7l9esQKlay5tmzF0yZ9BOLFo9N18+0gYFBgp8JYxND7vs9\nITzmJLp85dLs2ebGv0+e8+cJT25e86N8FSsiwiOZ6bySMVN7kiNn2n2m3xc7sE3fj2SwAbwTSL+O\n5jbeScctRA7ABXCWUj5P3ktqqMVeACFEaeBHoCZgjuZ6xAWgM5oymg00RLOKXTBwCXCS8v/snXVY\nFdkbxz8HkFCkUTFQEUEBYxV7DcpusdZY9WeLhd255trYHWvsutauLiqChS12rYKuhQEWDcr8/rhw\nJa6Bgnk+zzOPd86858x3xrn3nfc9gXI1TTtuwHRU/2n3gGlZodfBqTC7/GbxU/NRLFm4DYBs2XSY\nPb8/ni1dAZg8rSeejYdRyKoxOjraTJrWgwLWuenRZSqubmVxcSubFdLeypMnzzE1Tf8FNzMzTtU/\nOHPmUOrV64aFRUV0dHSYMWMI1tZ56dRpGB4elXF3r/wpZafj6ZMIrAvmTlduapYTUA16MzQ0YMjI\ntng2HEmxQj8B0Me7OeUrOjD1l3VYWBrTrmP6iC0rGdx3IXUbVeLH6iXfaDNweCtaNxlHySIdAejV\nvwnlKhRjxqSNmFsY0aaDR6bpeZWQwNEZM3Bs2RJj6zeP/zk2cxYFq1XFqswPb7Qp1eFn9g0eyh9N\nPQFwbNWSXE6OnFu1Gn0TE4rWq5tputMSH59Ar56T6O/dFnv7Qhptpv/an8YN+5E3tzs6OtpMnd4f\na+s8dO08Djf38ri5V8gyfe9D4aL5OHPiKgkJL9XOPDIimhtX7qAoCs+fRZIrjxleQ1rT2XMsVYt1\nAOB/fZrwQ/li+EzdiJmFMZ7tMu/5+MKwEEKcSrG/RFGUJSn2zYCnGuo9AUzfo/3pwL/AqowKk05c\nxU5U/wE9gDAgH1AX1UuYHirHPhmVYzYFegJHhRDFFUV5ACCEKA7sAk4BrZLqjQUMgUwdpnnj+l3a\nthxDcYdCzPbxxsBAl51/BdKv1yz09XRp+ZMHDk6FOX/1N26G3Cd3HjOMjHJw9MgF/tp2iFPnVxMW\n9pwBfWYT4B+EhYUxo8Z2oolnjcyU+cE4OdkRHLyXkJA75MljiZGRIYGBp9myZS9XruwiLOwJvXqN\nx8/vKJaWpkyY0Jfmzet8btnpyJvPgsBTC7kVEoqxiSFm5kbcCgll3szN/BMwg5iYOEYMWszfO45g\nYKBHr77N6NbrvTJvGWbzhv2cPX2DwLML3mpnlc+cgONz+O/mA4yMc6g033zA/Nlb+ctvCjEx8YwZ\nspxdfx3DwECP7n0a0blH/Q/SdHHDRl7FxVOyXds32gTv2UvYtas0WbvmrW3lsLSkwYplRNy/j66h\nIfrGxkTcv8/FjZuo4zOXV3FxnJy/gNuHDqOjp4dDi+YUb9b0g3SnZcb01cTExDF0eKc32jg62XLl\n322EhNwjTx5zjIwMORJ4lm1bAzh3cTNhYc/o23sq/vtOYGFpwthxPWjm6Z4p+t6Hdt0a4LstkDH9\nF9B3eBtevnzF1JEriI5SZZW0kjqGc+c1Z0fgXO7cekBO4xyYmhlx59YDls/byoZ/phAbE8/kEcvx\n+/so+gZ6dOzVmHbdPuz5+FCyaLGXMEVRnLOiYSFEVaA9UEZRlAxP1/7unbgQwgKwBRopirIjxaH1\nSf/GA/9LYa8N7AYeoorUZyUdGglEADUVRYlKsj0CBAOp52m8bqsr0BWggHX6yO5NjBu1jGzZdPh9\n6yR0dbMBUMO1LE/CXzB4gA/NW7mhpaWFjo42Re1Ug79evXqFd+/ZDB/dgTxW5vyv/UQio2K4+O96\nTp24Qosmw3EsYYOdfYZnRLw3pqZGqSLuZDRF6Do6OtjZFVZr79lzHOPG9cbKKhdt2gwgMjKamzf3\ncfz4ORo06E7JkvbY23+amY4mpoY8exqZrvzpk4ik4znVZUIIChd5PXhwcP8FtOtYmxIlizBh9ErO\nBF3naNBi7t8Pp67rAIoVt6a665sjzg8hKjKG0UNX4OXdFD09HZ4/U2lPTEwkIeElz59Fkj2HvjoC\nE0JQyMZKXX+E9xLadPDAsWRhJo1Zy7mgGxw4OY8H98Np6DEMu2IFqOaSsb+VFPnwIRfWrqPy4IEk\nxicQH5+gPpaYkEB8RCQIODV/ASVat0Y7m66qDCBRIfHlS+IjItEx0Fen2IUQGOXLp27n+Jy5FK1f\nDzNbW4KWLiP82jUarVpB9OMw/undB5NCBbEq+3EZqdu3HzBl8koWLRlJXFwCcXGvryMuLoFnzyLI\nmTM72traSc+0ajzIq1ev6NN7KqPGdMPKyoKf240kMjKaaze2c+L4RZo29saphO0bI/vMxrmSA6N/\n7c7M8Wv4c50fAJVrlKJxa1d2/L4f4zTPtHXh18/HhMFLaN7Og2IlCjNrwlounrnB30d9eHg/nJ/q\nDsO2WAEqVf/m/5bWUzRH3G+K0FOyGFgO3BVCmCSV6QDaSfsxiqK8cb0WObANwoEQYIoQoosQomha\nAyFECyHEcSHEM+AlEIUqwrZPYVYJ2JXswAEURbmDamCDRhRFWaIoirOiKM4WFu/fX3fpYgiOTjZq\nB55M2XLFeBL+gsePnqWrs2j+VrS0tOjWswkAe/ec5H9dGmJklANXd2eKOxRiv//pdPUyE0dHWy5d\nup6u/PLlYBwcbN9Yb968tWhpaeHlpYrYfH0P0717K4yMDPHwqIKjY1H8/NLPJc8qijkU5OqV/9KV\nX716m/zWuTA0NNBY7+/tR7hwPpjhY1QDmPz2nKJ1Ww8sLE0oWaoILu5l8NtzSmPdjyE8/AXhj58z\nacxa7PK2UW/37oax489A7PK2Ye8/ms+7a8cxLp6/yZBRqi6BgL1naNHWFQtLY5xK2VDD7QcC9qZf\ng+BdRN4P5VV8PIcmTmJD/QbqDeDSxk1sqN+AyNAHxD57RtDSZalsoh494lbAfjbUb8Ddo8c0tn/7\n0GGe3Ajmh06qboF7J05QpFYt9E1MMCtqS95yztw7kX6udka5GXKX2Ng4OrQfRW4LF/UGMGvmWnJb\nuHDxwo109eb7bEJLS9CzVwsA9uw+SpeuzTAyMsTdoyIOjjb47/u0Q5LadK7L0etr+fuoD/svLmfl\ntgk8evCEUmXt3jiGwu/vY1y5EEKf4arn45BfEE1au2JmYUzxkjb86FKag34Zfz4+BiGUTN/eg0uo\n+sXT4gBcfkfd4kB3VM4+easCVOR1hviNfPeRuKIoihDCA1XqezJgLoS4CUxXFGWhEKIBsAlYDYxD\nlW5PRJU610/RlBWq6DwtD4HCmak5dx4zLl0MIT4+IZUjP3XiCvr6uuq+2WQehIYzecIqtvw9DW3t\n13M3o6Ni1Z8jI2PJeCInYzRs6MrAgdMICbmjnh5269ZdAgODmDJlgMY6oaGPGDvWB1/fZam0RyWl\n+VTao/iALNQHU6deJX5bvYfDB8/zYzVV//KLF1H47jyGZ0sXjXWio2MZOnAhk6Z3I2fO7KnKk4mK\njM2S68iV25QtvhPTlXdr/yvFnQrSb3BzijkUTHc8OjqOUYOWMX7a/zBMqTnFcxMVFfNBz42ZrS21\nZs9KV767X39sPDwoWq8uOfPl02hzYPx4TAvbULJdW0wKp/9qvYyN5cQ8H8r36km27NlTlas/x8Rk\nyr0uVdqePX6L0pXXdO/OT23q0KFjI4rYpp4KGRoaxsTxS/hr57zU38folM909Cd9ppPR1ctG0eKq\nbNy1S7c4uv8cUxf102gbEx3HL0OXMmxS51TPR0yKZzo6KpYs/2FJgfh8a6fvAH4VQtgoihKi0iIK\noXLG71pRS9OPxmxAG+gNpH8LTMF378QBkm56eyGEAEoBXsCCpPndrYAbiqJ0SLYXQmRDlSZJSSig\nKSf+/nny96Rbjya0az2WFk2G07lbIwwM9Nj19xH+2ORPr76e6SL0YYMW0MSzBuUrvB4k6epWlmmT\n12JknIPTJ69yM+Qe1Wtkbho3LV26tMDH5zcaNerJxIl9EUIwatQcChTIQ7dumqcOeXtPoUWLOlSs\n+Ho6l4dHZSZOXIixsSEnTlwgOPgOrq4VM03n9qRVqM4GqbIGfrtPYmFpgrmFMT9WK0ndBhUpX7E4\n3TpOZfzkLpiYGDJz+iYURaHvgOYa25w+aT1Fi+aniWd1dZmLWxmWLtxBUbsCPAgN50DAGbz6Nfsg\nzX9tVSV8zp9RLZjivzsIc0sjzC2MqVzViSrVSqSro6+vi2UuE43HAGZO2UQRu3w0avajuqyaWylW\nLNqFrV1+HoY+4VDAeXr00Txd7W3o5jQkzw+lNR7LkSe3+pgmG21dXQzMTN9Y/9yatRgVKEAh19e/\njXmdnbm6dSvG1tZEh4URGhSEQ8sWGdadFhOTnFSvobmr1NraSuOxwQNn0qy5BxUqvr7vbu7lmTxp\nOUZGhpw6eYmQ4Hu4uJT7aH3J+G5XPR8Xz6r8wUG/05hZGGNmbkz5H514cC+MDSv+4YfyxdDVy8bF\nMzdYPGszHg0qUT/FM5uSBdM3UrhoPuo2ef18VHYpzbqlO7Epmp+HD55w9MA5Onpl/Pn4ClmKym9s\nF0KMRLUU+QTgDqp0OQBCiIKouljHK4oyHkBRlP1pG0vK+upoOpYW6cRTkDSo4KwQwhtVP7gTkB1V\nCj0l7VC9JaXkKFBXCJEjRZ94AVRvYhr7xD+Uxs2q8+eOKcz6dQNe3X8lLjaewjZ5mTm3L526NEhl\neyAgiAD/0wRdTD0waNpML/r2mkXHthMwMzdi8fKhFNMwbSozyZEjO/7+q+nffzLt2g1GURTc3Cox\ne/ZwDA3TL2rk738UP78jXLvmm6p8zpwRdO8+hlatvDE3N2H16ilvTcdnlJ9bp45aB/TxAaBKtZLs\n3DsdLS0tNm0dz8ihSxnQZx5xsQmUq1Ccv/ZMI3+BXOna+/fqbZYt+ov9R31SlQ8c9hOPHj3Fq9sM\nDAz0GDuxE64eH9ZH27lN6okQQ/qposPKVZ3YuvsXTVXeyvVrd1m5eBd7A1Mvy+o9pAVhD5/Rv8c8\n9PV1GTmhPTXcs/blLyM8/+8217Zuo/7SxanKS7ZrR8yTpwROnYa2nh5lunYlX7nMc5LvS4D/Sfz3\nneDC5T9Tlc+YNRCvnpNp12Y4ZuYmLF85luIOmTfGo+/PU1Ptjxugej7KV3Fi7c5J6GTT5typf9m4\n0peoyBisC1vRa1BL2vdoqLG94H/v8tuyXWzZnzpT0mNgC8IfPWO411z0DHQZMPZnfszkMR7v4nP0\nESuKEiWEcEU1Rmotqtlu+4B+iqKkHEAjUPmOTJMpPkfK5ktCCFESmIMqZX4D1Q3uAHii6pNwBhah\nSm/8nbTfG8gBbE+O0JNGp59DNf1sOqCLKkWfE3ilKEqht+koU9ZeOXhs8dtMvjgMs3261d4yk+fx\ntz63hA8i7lXsu42+MAaf/Hxzhj+GJVVyvtvoC+NWZKbGCp+EpjW8uXjmeqYlwK0c7JVOa94+A+ND\nmFTO/XRWjU7/WGQkDg+A24A3kB+IBS4A9RVFOS2EOAMUADqhWj7vJNAA2JqyEUVRrggh6qJy4JtQ\nTUebimrAW41PciUSiUTyHSN4v7XOvyW+eyeuKMojVAvWv+l4IqrpYyPTHCqkwdYPSJs7+rrCa4lE\nIvmK+UwD2z4bcoqZRCKRSCRfKd99JC6RSCSSbwcZiUskEolEIvkqkJG4RCKRSL4JkudvfU9IJy6R\nSCSSb4bvbXS6TKdLJBKJRPKVIiNxiUQikXwTfMa10z8bMhKXSCQSieQrRUbiEolEIvlmkJG4RCKR\nSCSSrwIZiUskEonkm0AA2t9ZJC6duEQikUi+GWQ6XSKRSCQSyVeBjMQlEolE8k0g+P4We5FO/AtB\nS+hgoG3+uWV8FyQq8Z9bwgeRM5vl55aQYRZW/twKPoyi4x9/bgkZ5soo088tIcPoan1vi6RmPtKJ\nSyQSieTb4Dtc7EU6cYlEIpF8E3yPfwBFDmyTSCQSieQrRUbiEolEIvlm+N7S6TISl0gkEonkK0VG\n4hKJRCL5ZpBTzCQSiUQi+Qr5Hpddlel0iUQikUi+UmQkLpFIJJJvBjmwTSKRSCQSyVeBjMQlEolE\n8k0g5IptEolEIpF8vXxvTlym0yUSiUQi+UqRkbhEIpFIvglUU8y+r3niMhKXSCQSieQrRUbiEolE\nIvlm+N4i0+/ter8J/ty8h6ZN+lKooAeGOcrhULwBw4fPISIiSm0TFvYUz2b9MTOtTKmSTfD3P56u\nHa9eE2lQv9enlM6dO6F4evbB2LgsRkZlaNrUi9u376eyCQt7QtOmXhgbl8XJqT7+/kfTtdOz51jq\n1eua6fru3Q1jSP/F1Kw+kHymzTDTb8DtWw9T2ezfd5Yu7adT2v5/5DVpRpniXRjQewGPHz1LZRcd\nHUvvbnOxsWpNmeJd2PLHoXTnmzvjT6qW683Ll68y/VoAfP85godLDyxN3Mht5k6VCp3YH3AKgLCw\nZ7RqPow85h44l26jLk9JX6/pNGk4IEu0fa2aXYpa8HvH8lwe7s7FYe781bUSlQubAfBr4xL8N662\nxm2f14/qNvSzaTGtkRPnhrhysG816jvmSXeeblUK80+PymhnwUit2m69yZGtqsatUT3VvQsLe0br\n5iOwMq+Nc+n27A84na6dfl4zaNpwUKbrk7w/MhLXgBCiBhAAuCiKsv/zqknPjJmryZc3F7/80pd8\n+XNz7txVxo9bxP79Jzh8eC1aWloMHDCdkJA7bNg4nV07D9KyxQD+vb4LU1MjAE6fvszatX9x5uyf\nn0x3dHQMrq4/o6eny+rVUxECRo6cg4tLe86f30GOHNkB8PaeQnDwbX7/fTZ//70fT8++BAfvxdTU\nOEn7Rdas2c758zsyXePN4FC2/XmYUj8UoWIVRwL8zqSzWbXcl+fPovAe0oIitnkJvnGfqRPX4783\niEOn5mFoaADA7Omb2b/vDPOX9uPShVv06DSTUj8UoYhtXkD1wvDrlE38sWMcOjqZ/1eQly3Zhnff\nGXTv6cnQER1JTEzk/LnrREfHATB04FxuBt9j7YYJ/LPzCG1ajuDitT/Uz0jQ6ausX+fLiaA1ma7t\na9X8k3MBxtctzuoTt5l7IBgtIXCwyol+NtX/39wDN/jt1O1UdfKbGODTvDR+1x6py3r+aMOPNuYM\n2HaB4rlzMqtpSS6GvuDWk2gA8hjp0btaEX5ed4pXiZnfxztrnjcRL6JTlR0/dpGhg3yoV1/1sjF0\noA8hwfdYs2EcvjuP0LblKC5c24SpaU4Azpy+xvp1uzketCrT9X0ogu9vdLp04poJAioBlz+3EE1s\n3z4PS0sz9X6NGuUwMzWmY8eR7N9/ElfXCvj6BjJv3nBq1aqCm1sFVq/ezrFj56hTpyqJiYn06jWR\nQYM7YWOT/5PpXrr0d0JC7nDtmi+2tgUBKFnSnqJFa7F48Sa8vTsC8M8/B5k/fzS1alXFza0Sq1Zt\n4dixs9SpU53ExER69BjLkCGdsbEpkOkaK1d15NrttQCsWbFboxP/dU4PLCyN1ftVqpXAtmg+6nsM\nY9vmw7Tt4AHAvj2n6dKjPnXqV6BO/Qr8sXE/B/zPqp348EFLadT0RypUKp7p1/HfrVAGD5jNpCle\nePVtqS73qFlR/XnP7mPMmjsAj5oVcXF1Zt2aXZw4folatSuRmJhIX6/peA9qS2GbfJmu72vUnN/E\ngDG1izFpzzVWHPtPXX4wOEz9+fbTGG4/jUlVr2oRCwA2n32dcapR1JLVJ27jd+0xftce07hkXn4s\nYq524mNqF2fX5QecvpM6u5NZFHconK5s5fK/0NXNhmdLNwD27j7GzLneeNSsgItrWdat+SfpXldM\nutcz8B70E4Vt8maJxg/le3Pi30w6XQihLYT4qJeS5DYURXmhKMoxRVFeZJa+zCSlA0/GuZwTAPfv\nqd724+MT0DfQA0BHRwdd3WzExcYDsHTJZl48j2DQoI6fSLGKHTv8qVixlNqBAxQuXIAqVcqwffs+\ndVl8fAIGBvoptOsSm6R9yZJNPH8eweDBXbJEo5bWu78SKR14Mj84FwUg9H64uiw+/iX6Brrq/ezZ\n9dTX4bfnNIEHLzBuUoePVKyZ1av+RktLi87dGr/RJv0zoqPWt3zpdl68iMJ7YJss0aeJL11zix/y\nkago/HbqTobqNS2Vl/P3nnP9caS6LJu2IC5FF0pMwiv0dFTPXnVbCyoWMmPSnmuZI/w9iI6OZeuf\nAdStXxkzM1VWIz7+JQZv+A1ZsXQHL15E0n/gT59Mo0Qzn9yJCyHshBBbhRCPhBCxQojbQog/hBA6\nQogOQghFCFEoTZ2xQqSeN5Bk94sQYqgQ4iYQD5QQQtRIOtZMCLFKCPFUCPFCCPGbEMI8g23USGFb\nSwhxRAjxXAgRKYS4JoQYnaa9UkKIHUnnjBFCBAohqmbqDXwDBw+o+gaLFbcBoHz5Eixdspnw8Ges\nWL6FiIgoypR14PHjJ4waNY+580agp6f7tiYznUuXbuDkZJeu3NHRlsuXb6j3K1QoxeLFmwgPf8ry\n5X8QERFF2bKOPH78hBEjZjN//phPrv1dBB66CIBdsdfZgbLl7Nm4zp8HoU/YtzeIC+du4ly+GHFx\nCQztv5jRE37GzNwoS/QcDTyHnX1B/tjkh6O9Jzn1q+JUrDmLFrzuPilX3oHlS7cRHv6cVSv+IiIi\nmjJl7Hn8+CnjRi9m1twBn/Q+f+may1mbEhwWRQMnKw72rUbw6Joc6FOV9uWt31jHuYAJhc1z8Oe5\ne6nKz959TrNS+chlqEe1IhY45DHizJ3n6GoLxtUtzlS/f3kWk5Al16GJHdsOEhERTZt2dV5rL+/A\n8qXbCQ9/zuoVfxMREc0P6nu9lJlzvb+476EQCtpZsH3JfI50+k7gKdADCAPyAXX5sBeKDkAIMBCI\nAu4DyWHSbMAPaA0UBSYBeQGXDLQBgBDCBtgBbAbGo3L2RQGbFDZlgEPAGaALEA10B/yEEJUVRUk/\nKiSTuHfvIWPHzsfNrSLOzo4A/DpjIA0beJE7VzV0dHSY/usArK2t6Py/0bi7V8LdveI7Ws18njx5\nru67TImZmTFPn75OesycOZR69bphYVERHR0dZswYgrV1Xjp1GoaHR2Xc3St/StnvJCIimhEDl2JX\nrAD1Gr6+r4NHtKZFo7E4FP4ZgN7eTSlfsRjTftmAuaUx7TrWzDJNoaFhhN4PY8TQ+Yyd0A2bIvnY\nsjkA774zePXyJb36tGTK9D40bTSQAnnqoKOjzZRpvSlgnYdunX/B1b0crm7lskzf16g5V049cufU\nZ3hNe6bt+5fbT6Kp65iHCfUc0NYSrEyRYk+mael8xL9MZPuF0FTls/ffYHVbZ04OUv0cLTocQtDd\nZ/SpXoQnUfFsDLqbZdehifXrfLHMZUrN2hXUZVOme9Gs0WCs89RHR0ebydO8KGCdm+6dJ+Pq7oyr\nm/Mn1SjRzCd14kIIC8AWaKQoSspRSeuTjme4SaCmoijqTighRHIH4yVFUZLzxb5CiCfAOiGEm6Io\n+96zjWTKALpAjxQpdv80NtOB24CroijxSe3sBi4Co4B0OUIhRFegK4C1tdV7XnJqIiOjadqkLzo6\nOixfMV5d7uRUlH+v7yQk5C558lhgZGRIYOAZtm7dx8VL2wgLe0pvr0ns23cMS0tTxo3zwrN51jmV\njODkZEdw8F5CQu6QJ49lkvbTbNmylytXdhEW9oRevcbj53cUS0tTJkzoS/Pmdd7dcBbw8uUrurSf\nTuj9J/wTMDXVALW8+cw5dHIut0IeYGySAzNzI26FPMBn1lZ2+U8lJiaOkYOXs3PHMQwMdOnZtzFd\nezbIFF2JiQoREdEsXj6Sxk1qAFDDxZn//gtl+rS19OrTEkenIly69gc3Q+6TO485RkY5OBp4nh3b\nDhB0YT1hYc/o32cGAftOYmFpwuixXWnq6Zop+r5GzVpCkFNfh24bz+B7RTVj4cjNJxQwMaDnjzbp\nnLiejhb1HfPg/+8jnkanjqofRsRRe2Eg1qYGvIh9ybOYBAqYGtCtSmE8lx9HP5sWo2oVo1bx3MQm\nvGLZ0VusOp56wFxmEXo/jIB9p+nZ2xMdndcuwdHJhovXNmq41wc5fWEtYWHP8O4zi4B9p7CwNGHU\n2M409UwbI316vrc+8U8diYejinqnCCFyA/sVRbn+Ee35pnS+afg9zf4fwBpUA9ZSOvG3tZHMWSAB\n2CiEWAEcVBRFPdRUCGEAVEcV7Sem6Zv3AzR20imKsgRYAuDs7JjhnE1MTCyNGvUmJOQu/gEryJ8/\n9TQVHR0d7OwKAfDq1St6e/3CmLE9sLKypF3boURGRnMj+B+OH79A40a9KVGyKPb26Qe8ZBampkap\nIu5kNEXoKu2F1dp79hzHuHG9sbLKRZs2A4iMjObmzX0cP36OBg26U7KkPfb2NunazkoSExPp+b9Z\nHPA/x8atY3Askf7eCSEoXOT1C9oQ78W07eiBU8nCTBy9hrNBNwg87UPo/XDquQ3Fvpg11V1LfbS2\n5H5NN/fUkam7e3n27j5GaGgYVlYW6OjoUNROlQ5+9eoV/Xr/ysjR/8PKyoKO7cYSGRnN5et/cvLE\nJTwbD8apRBHs7AumO19m8KVrTk5vH0oxkA1UA9tqFLUkl6EejyLjXuu2z4WxQXqJx2MAACAASURB\nVLZUA9rSknIQ3Pi6xdkYdJcrDyMY5FaUknmNqTn/MHmM9PmjUwWuP4ok8OaTj76OtGxYv5vExMRU\nqfRk0t/rmYwY3SnpXo8nMjKaS9d/5+SJyzRvPDTpXr+5eyGr+R5Hp3/SPnFFURTAAzgFTAb+FUKE\nCCF6fGCToW85lmpyb1J0/BRV+v5920iuewOohep+rQUeCCGOCSGqJ5mYAdqoIu6ENJsXYCqEyNR7\nnZCQQIvmAzh96hJ//T2fEiXS9zWnxMdnPVpaWvTq1RqA3bsD6dqtOUZGhnh4VMLRsQj79qWfS56Z\nODraculS+ne2y5eDcXCwfWO9efNU0+a8vNoC4Ot7mO7dWyVpr4KjY1H8/NLPJc9qvL0WsHXzIZat\nHfRejnfnjqNcPB/CsNGqd7p9e4No1dYVC0tjSpSyoYZ7afbtzZxel+IOGX+hWeizGaEl6N7LE4C9\ne47RuWsTjIxy4OZenuIOhfHfl35edmbxpWv+91FEhuw9S+clPCqegOuP32lbs1guHPIYMdNf9f2o\nbmvBn+fu8SQ6gcsPIjgUHEb1opYfpPtdrF/rS4mStpQs9ebvIMBCnz/R0tKie6+mAPjtOU7nro2T\n7nU5ijsUIiALnw+JZj75wDZFUUIURWkPWAI/oEpLLxBC1AFik8zSjpYwRzNvi15zp9wRQugCpsC9\nNHbvFQErihKgKEptwARwB14CO5O6CJ4BicA8oJymTVGUxPc5z/uQmJhIu7bDCAg4wZ9bZlOx4tsd\nSGjoY8aPW4TP/BFoa79O90ZHvY4CIiOjUb1jZR0NG7py7Ng5QkJej+69desugYFBNGyoOeUZGvqI\nsWN9WLhwbCrtUam0R2W59rSMHLKctSv34LOkL/UaVnqnfXR0LMMGLGXitM7kzJn9dXlUrPpzVGRs\npl1Hw8bVANUPbUr27jlGvvy5sLKySFUeGhrGLxOWM9dn0BufkaiomCy9z1+65t1XVMm36rapdVS3\nteT+85hUUbhFDl2qFbFg+4X7vHzHPG/9bFqMqVOc8b5XiYp/PWLdINvra8quq0NWBJhBp65y5fIt\n2rSr/Va70NAwJk1YyRyfAW/8Hmb18/G+aInM375kPts88aSo/KwQwhv4H+AEHE467AT8C5CUmv6Q\nztoWwIoU+81RvbR8VMimKEoc4C+EMAS2A4UVRTkphDgElAKCMtNha6K31y9s3ryHYcO7kCOHAceO\nnVMfy58/d7q0+sAB02nevGYqZ+/uXolJk5ZgZGzIyZMXCQ6+i4tL+ayUTZcuLfDx+Y1GjXoycWJf\nhBCMGjWHAgXy0K1bS411vL2n0KJFHSpWLK0u8/CozMSJCzE2NuTEiQsEB9/B1TXzBupt3xIIwLkz\nwYBqOpi5hTEWFkZUqVaCOb9uZsGcbbT52QMb27ycPH5VXdfCwjhV+jyZXydtwtYuH008X09WqOFW\nmqWLdlLUPj8PQp9wMOAcvfq+eXpVRqhdpzLVa5Shd89phIU9p7BNXrZs9sdv7wkWLxuRzn7ooLk0\n9XSlfEUndZmrezmmTl6FkbEhp05eJiT4HjVcymaKvq9Rs//1xxwJCWdSA0dMs+ty+2k09RzzUN3W\nggFbL6SybVwyLzraWvz5llR6Mn2q2xISFsXOSw/UZYeCw/m5fEGCw6LInVOPKoXNWHrkZqZcR0rW\nr/NFR0eblj+9/Sd26CAfmnq6UL6io7rM1d2ZqZPXYGRsyOmTVwgJvk91lzKZrlHydsSnfHMSQpQE\n5gCbgBuoUtAdAE+gInAOuIqqa2MIEAf0BIoDBRVFESnaUoBfFEUZmeYcNVCttnYXVX/0RsAO+AU4\nrSiKSwbacFEUZb8QojtQDdgF3AEsgGGAFWCrKEpM0uj0g6heEpajStNboBoUp60oytC33RtnZ0fl\n+ImNb71/yRSxqc1//2n+cRg1ujtjxvRU7/v7H+en1oO5fGUHZmavB90/fBhOzx4TCAg4gbm5MePG\nefFTm3rvdf5ktLX0MmQPcPv2ffr3n8zevYEoioKbWyVmzx5OoULpF53x9z9Ky5b9uXbNFzMzkxTa\nw+jefQz+/scwNzdhwoS+tGnT8L01PI37963HzfQ1Dy6rUtWJv/ZOpoHHMPWUsrS0buvK/GX9U5X9\ne+0O7j8OIODobPVCLwCRkTEM6b+Yf/4+joGBLt17N6J3/6Zv1KWv/aaElGZevIhi9IiFbNsSwNOn\nEdjbF2TA4Ha0bJ36B3t/wCna/zSas5c2qvulAR4+fEKfXtM4EHAaM3NjRo/tQqufamVIQ0b5UjQX\nm/BcY7mhnjZD3O2o45AHY/1sBIdFsfBwSLrR5//0qIyWENRaEPjW8xSxyMH2LpWov/iIeqEXgOy6\n2oyrW5ya9rmIfZnI8qO3WHLk1lvbujLK8L2uLZmEhJfYWjemXAVHNm+b+ka7/QGn+fmnMZy5tD7d\nve7b61cOBARhZm7EqLGdafWOl4G0/FihM0Gnr2ZarGtXsqgyd9fczGpOTZ0CdU8rivJFDsf/1E48\nF6pR3JWA/KjS5xeASYqi7E6ycQTmA87AE1RTxYyAMRl04s2AhqhGhWsDfwF9FEUJy0AbyU68EjAU\nlUPOlaTrMDBSUZRrKeoVB8YArqimqT1GtfrbIkVRdr3t3mTEiX8pfIgT/xJ4lxP/UsmoE5d8OG9y\n4l8yGXXiXwKZ7sRLFVV8ds3JrObU1Mpf74t14p80nZ40ovvnd9hcAmpoODQ2jd27/uNfKIrS4R3n\n0thG0nrpIsX+UaDRO86HoihXgFbvspNIJBKJJDOQa6dLJBKJ5Jvhm1lL/D353q5XIpFIJJJvhm8u\nEk+bCpdIJBLJ94Fc7EUikUgkEslXwzcXiUskEonk+0X7O4vEpROXSCQSyTeBKp3++VeN+5TIdLpE\nIpFIJF8pMhKXSCQSyTeDHNgmkUgkEonkq0BG4hKJRCL5JhBfwV8dy2ykE5dIJBLJN8P3ll7+3q5X\nIpFIJJJvBhmJSyQSieSbQXxn6XQZiUskEolE8pUiI/EvhEQlkfjEyM8tI0MYfKV/T1xP2+RzS/gg\nIhIef24JGSY0+uuME66PtvrcEjJM033Rn1tChgmJyPw2v7NAXDpxiUQikXwbCGQ6XSKRSCQSyVeC\njMQlEolE8s3wvUWm39v1SiQSiUTyzSAjcYlEIpF8M4jv7K+YSScukUgkkm+G72xcm0ynSyQSiUTy\ntSIjcYlEIpF8E8gpZhKJRCKRSL4aZCQukUgkkm+G7ywQl5G4RCKRSCRfK9KJSyQSieTbQIBWFmzv\ndWohCgghNgshngshXgghtgghrN+jXjkhxHIhxHUhRLQQ4rYQ4jchROH3Oa9Mp0skEonkm+FzpNOF\nENkBfyAO+BlQgIlAgBCipKIoUW+p3hJwBOYCF4C8wCjglBCitKIod952bunEJRKJRCL5OLoANoC9\noig3AIQQ54HrQDdg5lvqTlMUZWDKAiFEIHAzqd3RbzuxTKdLJBKJ5JsgeYpZZm/vQUPgWLIDB1AU\n5SYQCDR6W0VFUR5pKPsPeAzke9eJpROXSCQSieTjcAQuaii/BDhktDEhRHEgF3DlXbbSiX/F+P5z\nBA+XHliauJHbzJ0qFTqxP+AUAGFhz2jVfBh5zD1wLt1GXZ6Svl7TadJwwCfVfOdOKJ6efTA2LouR\nURmaNvXi9u37qWzCwp7QtKkXxsZlcXKqj7//0XTt9Ow5lnr1uma53tpuvcmRrarGrVG9AUl6n9G6\n+QiszGvjXLo9+wNOp2unn9cMmjYclCUa798NY5j3EurWGEwh8+bkzt6I2/89fGudQb0XkDt7I3p2\nSp3li46Oo1/3edjna0N5x25s23woXV2fmVtwqdCXly9ffbDmvTsC6dduIrVKdqRC/mY0qtCduRNW\nExURrbY5duAsQ7tOp26Z/1EhfzPqO3fhl4ELePL4Waq2YqJjGdt3LtVsW1PfuQu7t6bXvHLun7So\n3vujNL8v9ev2Rk/HmTGjFqjLwsKe0cJzEJZm1fmhVAsC/E+mq9fbawqNGvTNcn0nhg9kZ61qXFu1\nNFV5xK2bnBo/Ar/WTfBtWJMDXdoT/McGEl+9VNu8io3l3Mwp7GlWj4AOrbi/f1+69oN/X8/B7h1T\n1fuUiCzYAAshxKkUW9ofHzPgqQY5TwDTDOkXQgdYhCoSX/4u++++T1wIUQjoAKxRFCUkk9uuAQQA\nLoqi7M/Mtpct2YZ33xl07+nJ0BEdSUxM5Py560RHxwEwdOBcbgbfY+2GCfyz8whtWo7g4rU/MDU1\nAiDo9FXWr/PlRNCazJT1VqKjY3B1/Rk9PV1Wr56KEDBy5BxcXNpz/vwOcuTIDoC39xSCg2/z+++z\n+fvv/Xh69iU4eC+mpsYAnD59kTVrtnP+/I4s1zxrnjcRL6JTlR0/dpGhg3yoV/9HAIYO9CEk+B5r\nNozDd+cR2rYcxYVrmzA1zQnAmdPXWL9uN8eDVmWJxpshoezYcphSpW2pUMWB/X5n32p/4ugVNm88\nQE6j7OmOzft1Mwf9zzJncR8uX/wPr//NpmTpItjY5gVULwyzpv7Oxu1j0NHR/mDNa+ZvJZeVGX1G\ntidXXguuXQxh0bQNnDx8gdX/TENLS4vNq32JeB5F5/4tsLbJy+2Q+yycup4jAUH8cWAe2Q0NAFg5\nZzPH9p9h/Lx+XL98ixE9Z1KsZBEKFlFpfng/jGUzNzH/93Efpfl92LTRlwvn/01XPnjgTEJC7vLb\nhins2nWI1i2HcOXfbSm+j1f4be1OTp3ZkKX67gX48eLmjXTlseFhHBvcB31zSxy690bX2JiwM0Fc\nXb6I+OfPKN65BwA3Nv1GWNApSg0cxoubwZyd/gvGRe3Ika8AADGPH3FjwxrKTZyOlvbncS9ZNLAt\nTFEU56xpOh0+QGWgnqIoml4MUvHdO3GgEDAGOAxkqhPPKv67FcrgAbOZNMULr74t1eUeNSuqP+/Z\nfYxZcwfgUbMiLq7OrFuzixPHL1GrdiUSExPp6zUd70FtKWzzzi6XTGPp0t8JCbnDtWu+2NoWBKBk\nSXuKFq3F4sWb8PbuCMA//xxk/vzR1KpVFTe3SqxatYVjx85Sp051EhMT6dFjLEOGdMbGpkCWay7u\nkH6Wx8rlf6Grmw3Plm4A7N19jJlzvfGoWQEX17KsW/NP0r2umHSvZ+A96CcK2+TNEo2VfnTk0i3V\ny9i6lXve6sQTEl4ysPcC+g1uztrlu9Md998TRKfu9ahdvwK161dgy6YDHPQ/p3biowYvo0GTKpSr\nWPyjNM/5bRRmFsbq/XI/lsDYNCejes3i1OELlK9WiuHTeqSyca5SgoJF8vG/hsPYs/0wjdt4AHB4\n32la/q8+NepUoEadCuzavJ/jB86qnfj0EUvxaPQjpct/nOZ38fTpCwYNmMX0Gf1p33ZkqmO7fY8w\nZ94QataqhKtbOdau/pvjxy5Qu04VEhMT6d1rMgMH/YyNTf4s05cQEcGVxT4U7+bF2SnjUx17dPwI\n8c+fU2nGfAwLqGZFWZQuS3ToPe7t26124o9PHadQw6bkrvQjuSv9yD3/vYQFnVY78cuL5pGnag3M\nHEtk2XV8oTxFc8T9pghdI0KIKUBX4GdFUfa8Tx2ZTs8AQoXu59axetXfaGlp0blb4zfaxMcnoG+g\nB4COjg66ujrExsYDsHzpdl68iMJ7YJtPojeZHTv8qVixlNqBAxQuXIAqVcqwffvrtFx8fAIGBvop\ntOuqtS9ZsonnzyMYPLjLJ9WeTHR0LFv/DKBu/cqYmRkl6X2JQap7nY24JL0rlu7gxYtI+g/8Kcs0\naWm9/9d4/qytJL5KpGc/zc9OfMJL9A1eP+IGBnrExqmuxX9PEEcOXWT0Lz9/nGBI5ZyTcfyhKACP\nHoS/2yY0XF32Mo1mfQM94pI0B+47zanAC/Qb0+GjNb+L4cPm4eBYhJataqc7Fh+fgL5+mmckSeOy\npVt4/iKSAYPaZ6m+K8sXYViwMPlc3NMdS0xIACCboWGq8mw5DFESlVR2Wnp66n1tPX1eJaiu49HJ\n44SfP6t2+J+LzzRP/BKqfvG0OACX36cBIcQIYAjQR1GUte99ve9r+CkQQowVQihCiKJCiJ1CiEgh\nxH9CiNFCCK0UdpZCiEVCiHtCiDghxNW0fRTJbWk4xyohxK2kzzVQpbsB9iadW0kqRwhxSwixTgjR\nSQhxFYgH6iUdGyeECEqa1B8mhPAXQlRMe76s4GjgOezsC/LHJj8c7T3JqV8Vp2LNWbTgT7VNufIO\nLF+6jfDw56xa8RcREdGUKWPP48dPGTd6MbPmDkBP79O+j1y6dAMnJ7t05Y6Otly+/DrFV6FCKRYv\n3kR4+FOWL/+DiIgoypZ15PHjJ4wYMZv588d8cu3J7Nh2kIiIaNq0q6Mucy7vwPKl2wkPf87qFX8T\nERHND+p7vZSZc70/m96U3AwOZfbU35kyuxvZsmlOwpVxtuP3df48DH1CwN4gLp6/Sdny9sTFJTB8\nwBJGjG+PmblRlug7HagaF1S46JszLKePJNnYvbZxKmPPXxv9efzgCUf8g7h28SYlnYsRH5fAlKGL\n6TPqZ0zMskZzMoGHz/Lb2p3MmTdY4/Fy5Z1YtnQL4eHPWLliGxERUfxQpjiPHz9lzKiFzJk7JEuf\nkScXz3PPbzdOXv01Hreq5oKusTEXfWYR/eA+CVFRPAg8yL19e7Bp9jrbZ1LMgXt7fYkND+PxqRO8\nCLmBaTEHXsXHc2nBbIp16oauUfqXr++AHUBFIYRNckFSV22VpGNvRQjRB9W88hGKovhk5MRfajp9\nK7ASmAU0AMYBd4CVQggjVKlvA2Asqrl0tYCFQgg9RVHmZeA8QUAvYD7QB0gebZLyzckFKJ2k4RFw\nK6k8P6rJ+f8BOYC2wEEhRFlFUS5kQEOGCQ0NI/R+GCOGzmfshG7YFMnHls0BePedwauXL+nVpyVT\npvehaaOBFMhTBx0dbaZM600B6zx06/wLru7lcHUrl5USNfLkyXN1H2BKzMyMefr0hXp/5syh1KvX\nDQuLiujo6DBjxhCsrfPSqdMwPDwq4+5e+VPKTsX6db5Y5jKlZu0K6rIp071o1mgw1nnqo6OjzeRp\nXhSwzk33zpNxdXfG1e1TdaW9ncF9F1K3USV+rF7yjTYDh7eidZNxlCyi6tro1b8J5SoUY8akjZhb\nGNGmg0eWaHsYGs6Cqb9RoXppdbSdlqiIaKaPWIqNXQFc6r5+X+42uDVeLcfi4aTKEPzs1ZRS5Yqx\nePoGTC2MadK2ZpZoTiY+PoFePSfR37st9vaFNNpM/7U/jRv2I29ud3R0tJk6vT/W1nno2nkcbu7l\ncXOvoLFeZpCYkMCFOb9i49lSnSpPi56pGZVnLeTU2OEE/NxKVSgEdm07UqTF6yySXdsOnBg5iH0/\nNQXApnlrTB2cuL5uFbrGJhSoXS/LruN9SDEQ7VOzFPACtgshRqJa7GUCKr+1ONlICFEQCAbGK4oy\nPqmsFTAb8AXSBoMvFEV5ayT/pTrxGYqirEz67CeEcAVao3LsfYGCQAlFUa6nsDEBxgghFiqK8l7D\nIhVFeSGESL5BVxRFOabBzBQoqyjKgzR1/5f8WQihjeo/4BLQOUljlpGYqBAREc3i5SNp3KQGADVc\nnPnvv1CmT1tLrz4tcXQqwqVrf3Az5D6585hjZJSDo4Hn2bHtAEEX1hMW9oz+fWYQsO8kFpYmjB7b\nlaaerlkp+71xcrIjOHgvISF3yJPHEiMjQwIDT7Nly16uXNlFWNgTevUaj5/fUSwtTZkwoS/Nm9d5\nd8MfSej9MAL2naZnb090dF5/dRydbLh4baOGe32Q0xfWEhb2DO8+swjYdwoLSxNGje1MU0+XLNeb\nks0b9nP29A0Czy54q51VPnMCjs/hv5sPMDLOgZm5EbduPmD+7K385TeFmJh4xgxZzq6/jmFgoEf3\nPo3o3KP+R2mLjoyhf9uJ6GhrM36e5q/Oy5evGNp1Oo9Cn7Bq19RUA9RyW5nz+4G53L31gJzGOTAx\nM+LurQes9tnKyp1TiY2JY8ao5fjvOoa+gS7tejSmdZcGH6U5JTOmryYmJo6hwzu90cbRyZYr/24j\nJOQeefKYY2RkyJHAs2zbGsC5i5sJC3tG395T8d93AgtLE8aO60Ezz/Rp7w8h+I/1vIqPw7b1m9P1\ncc+ecXrCSLT19Skzcjy6RsaEnQ3i+oY1aGXLRpGWqq43fQtLqi5cSXTofbIZGqJrZEx06H2CN2+g\n8oz5JMbFcXmxDw+OHEJbT4/CzVpSuFGzTLmO90VDAjbLURQlKslPzQLWonqX2Af0UxQlMqU8QJvU\nWfDaSeW1k7aUHABqvO3cX6oT35lm/yLwQ9Ln2sBx4GbSUPxkdqNyoA7A+UzUciytAwcQQrgDI4CS\nqAYvJHPzfRtO6gLoClDAOvd7C0rui3VzTx1Nu7uXZ+/uY4SGhmFlZYGOjg5F7VRv3q9evaJf718Z\nOfp/WFlZ0LHdWCIjo7l8/U9OnriEZ+PBOJUogp19wXTnyyxMTY1SRdzJaIrQdXR0sLMrrNbes+c4\nxo3rjZVVLtq0GUBkZDQ3b+7j+PFzNGjQnZIl7bG3t0nXdmayYf1uEhMTU6XSU+pNfa9nMmJ0p6R7\nPZ7IyGguXf+dkycu07zx0KR7/c5llTOFqMgYRg9dgZd3U/T0dHj+TPWbkpiYSELCS54/iyR7Dn11\nil0IQSEbK3X9Ed5LaNPBA8eShZk0Zi3ngm5w4OQ8HtwPp6HHMOyKFaCaS6kP0hYbE0efNhO4+98D\nlu+YTO68FulsEhMTGdVrFscPnmPehjHYOaYfbCiEoEDh15qnDF1Mk7Ye2DsVZt4va7h89gabD/nw\nKDScTvWHYmNvTYVqH6Y5JbdvP2DK5JUsWjKSuLgE4uIS1Mfi4hJ49iyCnDmzo62tnfRMq75fr169\nok/vqYwa0w0rKwt+bjeSyMhort3YzonjF2na2BunErZvjOzfl5hHD7mxYS0l+w8mMSGexKT+a1BF\n6AmREegYZCfkj/XEPHyA65o/yJZTNavCvNQPKImJXFuznAK166FrbAKo7nWOvK8HxF5cMBvr2vUx\nKmLL1ZVLeX79GtUWryY2/DFHB3iR07oQFj+U/ajr+BpQFOU28NY3FkVRbpEmWaAoSgdUM6Q+iC+q\nTzwFT9LsxwH6SZ9zAdWAhDTbH0nHzTNZS2jaAiFEGWAXEAn8D6gIlAPOpdD5ThRFWaIoirOiKM4W\nFu8/lbC4Q8ad1UKfzQgtQfdengDs3XOMzl2bYGSUAzf38hR3KIz/vvRzyTMTR0dbLl26nq788uVg\nHBxs31hv3ry1aGlp4eXVFgBf38N0794KIyNDPDyq4OhYFD+/9HPJM5v1a30pUdKWkqXerBVgoc+f\naGlp0b2XKuXot+c4nbs2TrrX5SjuUIiALL7XKQkPf0H44+dMGrMWu7xt1Nu9u2Hs+DMQu7xt2PuP\nZj27dhzj4vmbDBmlSqkG7D1Di7auWFga41TKhhpuPxCwN+iDdCUkvGRgxylcPnsDn41jKOpQSKPd\nxAEL2LPtEFOWDnovx+u/6yjXLobQc6gqejyyL4gGrVwxszCmWAkbKrmUJnBf+rn8H8LNkLvExsbR\nof0oclu4qDeAWTPXktvChYsX0k/pmu+zCS0tQc9eLQDYs/soXbo2w8jIEHePijg42uC/78RH64sO\nvU9ifDxnp05kT7N66g0gZPNG9jSrx4tbIUTcDCG7VT61A0/GxL4YysuXRN2/p7H9B0cO8SL4Bnbt\nVYnJx6eOk8+jNnomJhgXKYplmXI8PnX8o68jI2TRPPEvli81En8b4aj6pt+Usr6W9G8sgBBCV1GU\n+BTHM+rkNeVmmgEvgaaKoqhfvYUQpsAzDfaZSsPG1Vi98i/89hynSbPXKfC9e46RL38urKxSRzOh\noWH8MmE52/+eibb26zRkdFSM+nNUVAyKkrVpqIYNXRk4cBohIXfU08Nu3bpLYGAQU6ZoXnQmNPQR\nY8f64Ou7LJX2qBTaIyOjslx70KmrXLl8iynTvd5qFxoaxqQJK9n2969v1Psp7nVKcuU2ZYvvxHTl\n3dr/SnGngvQb3JxiDukzMNHRcYwatIzx0/6HYc7Xc8qjo2LVn1XXknFNiYmJDO/+KycPn2fu+tGU\ndC6m0W7GqOVsXbeHCfP74Vq30jvbjYmOZfrwpQyc2JkcKTTHRL/WHB0VyweJ1kCp0vbs8VuUrrym\ne3d+alOHDh0bUcQ29UC90NAwJo5fwl8756X+PkanfKajM+UZMSpiS8Vpc9KVHxvcl3xuNSlQqx45\n8uZDz8yMp1cukhARkcqRP7uqWjBM3zx9huRVbCyXF87FoZsXOtmzpyh/fR0vYz/ts/498jU6cV+g\nN3Bb05qzKfgv6V8nVAPYSOo3rwxEpLCLS/rXIAMasgOvSOHgk/pDrMlAOv1DqV2nMtVrlKF3z2mE\nhT2nsE1etmz2x2/vCRYvG5HOfuiguTT1dKV8RSd1mat7OaZOXoWRsSGnTl4mJPgeNVyyNuXVpUsL\nfHx+o1Gjnkyc2BchBKNGzaFAgTx069ZSYx1v7ym0aFGHihVLq8s8PCozceJCjI0NOXHiAsHBd3B1\nzdqJAevX+aKjo03Ln94+SGroIB+aerpQvuLr2Sau7s5MnbwGI2NDTp+8Qkjwfaq7lMlUfX9tDQTg\n/JlgAPx3B2FuaYS5hTGVqzpRpVr6ebv6+rpY5jLReAxg5pRNFLHLR6NmP6rLqrmVYsWiXdja5edh\n6BMOBZynR583T3V8E5MHL2Lv9kA6e7fAILse509dVR/LndeC3HktWDl3M2sXbqNxGw+sbfKmsjE1\nN06VPk9m6YxNFLTNR63GVdVlFWuUZuOynRQqmp/HD55w4uA52vXMuGZNmJjkpHoNzQMXra2tNB4b\nPHAmzZp7UKHi6/vu5l6eyZOWY2RkyKmTlwgJvoeLy8cPPs1mmBPzUj9ouv454wAAIABJREFUPGaQ\nK7f6mHW9Rtzz38vx4QOw8WyFrpEx4efPEPLnRnJXqYpBrvTdfdfXryZH/gLkrf46kLAs48x/O7Zi\nWKAgseFhhJ8JSjW6Pct5/7XOvxm+Ric+C9WfbjskhJiFKvLOARQDqiqKkrzY/D/Ac2CpEGIMoAcM\nRpUCT8m/qKLqTkKIJ6ic+jVFUSJ4M75AP2CVEGIlYIfqT8dpzjllMkIINv05ldEjFvLL+GU8fRqB\nvX1BVq4ZS8vWqZ3M/oBTBOw7xdlLG1OVT5/Znz69pvFzm9GYmRuzdMVIjQubZCY5cmTH3381/ftP\npl27wSiKgptbJWbPHo6hYY509v7+R/HzO8K1a76pyufMGUH37mNo1cobc3MTVq+e8tZ0/MeSkPCS\nPzb54VGrArlyvbnbY3/AafbvO8WZS+tTlU+b2Ze+vX6lQ5uxmJkbsWTF8Ey/153bTEu1P6SfKjqs\nXNWJrbt/yXB716/dZeXiXewNTL0sq/eQFoQ9fEb/HvPQ19dl5IT21HDX7CTexuGkdPaymb+zbObv\nqY51G9SaHkN+4rCfymbbb3vZ9tveVDYNWrkywSf1dKmb1+/8v73zDLejrNrw/aSRIr0ICoIKAtKU\nABKQEEBFBBFEEKR3hEDoHQlBpFdR6aEYpUv56IQakEDoLTTpTaqBBEhC1vfjeSeZbM5JINn1nPfm\nOhc5s2dmrz1nz6x3dS459zr+MfyUqbbvuPdvee+dDxm8x2nM0rMHexy2NatUeRH1Zbn9tge4bfj9\nPP7UFVNtP/HkfRm469FsufnBzDX3HJw7dPAMhc1mlDmXXIp+J57Oc8PO56kzTmPi2HH0+vr8LLb5\n1nxno02/sP/Hr7zMy9f+ix+fPnXr1kV/txWfffABj514DF1mmYXFt9uJefuuVKdPYdd3s8aIa4Wa\nydUhaTDunta9nGEu6XxgQEQskn6fE49n2wBPefkQK/MrIuKU0nE/xkp/KeA1YAjwk/K50n474yL7\nb+HMwTUi4o5UTz4iIrZoQ9bdgb2B+XHi3UHAoQARMSDtM4Av2XZ1+b5Lxj0jz5vOFWouenWrdvpB\nfRg3cVoOnObl4wmVqSLNz5vjWvORuuQcX7Tym51fDx83/Z2ajBEDd+TDZ0dXzXZedvnF4po7pzX1\nc8b49mzrP1jHtqtfiaayxCNiMK79rty+TcXvHwB7pZ9pnW8ETjgr8/c29juTUi1fafsi0zj3n4HK\nmvRbK/a5g+bPi8hkMpkOQ2dzp7fmMjmTyWQymUxzWeKZTCaTycwMncwQz5Z4JpPJZDKtSrbEM5lM\nJtNh6Gwx8azEM5lMJtNh6GQ6PLvTM5lMJpNpVbIlnslkMpkOgYAuncwUz5Z4JpPJZDItSrbEM5lM\nJtNh6GSGeFbimUwmk+koBFLztBKvB9mdnslkMplMi5It8Uwmk8l0GDqbOz1b4plMJpPJtCjZEs9k\nMplMh0DKHdsymUwmk2lZOpkOz0q8WXj4odHv9u6+yss1Ov08wLs1OnetaEWZoTXlbkWZoTXlzjJP\nzcI1Om+nISvxJiEi5q3VuSWNiogVanX+WtCKMkNryt2KMkNryp1lrj2dLdGrs33eTCaTyWQ6DNkS\nz2QymUyHobMltmVLvHNwVqMFmAFaUWZoTblbUWZoTbmzzJmqoojO1aIuk8lkMh2TH/RdLG6796Sq\nn3funus/2Kx5AdmdnslkMpkOgQB1siKz7E7PZDKZTKZFyZZ4JpPJZDoMUueyTTvXp81kMplMpgOR\nlXimw6EmWopL6tpoGToyknpLWrnRcmSaCdXgp3lpmoddpnmQXGnZTMpwekjqWcgdEZMkzSKpZl3w\nvqRMiojP079vlLRtI+WpBpKaJgSXvp9nAHdJ+kmj5clMIS2uVq3/M0Q1+a+ZaZmHdKY+SOoF3CTp\n+xExqdHyfBkkzQZsB+yafu8G3AtsWij2BsjUNVL9pqR9gWWA/7bSwqgtImKipD6SBknq0UhPQ/p+\nXgs8AJwn6WeNkqUetNh35xTgbuCnLSZ3y5EvbqaSVYE1gB9Cyzw4xmOZB0v6A/AcMAa4IhrUCKFk\ngS8LfB84Gbi5VRZG02Fn/HnmKD5nvSl5XS4D/gS8AJwrac1GyFNrJHVLHqbukhaUtLSkuUqvN5u5\neBIwHLgQWLu+z5HsTs90YiLiVmAEsEf6vamVTnJZfwpsAjwLHAxMALaKiDca+XCTNBh4BFgTeCoi\nJjThw3ZGuAZ4FRjYwEVe+X3fBp4BegMXSVq9MSLVhuTVmShpVuAmrBwfA26RdDhAoxar7RERo4Hf\nA08CF1B3Rd55yBc1MxlJ3dM//wJ8V9JGjZTnyxARIal7eojNga3yrwGbSeqSXm/U9/xs4HbgW8Av\nJc3abA/b6aFE+ndxHV8AHgfWLe9XT5lKno4rgb8BSwP3AQsAwzpSjDwiPpfUG4eIBPwR2BB4EDhc\n0imNlK89IuJ5YCfgCeqoyKUuVf9pZppbukzNSe652QAiYkLafC8wFli7YYJ9CUrx2MKluznQD3ge\nexL2S1bMpJIiqomyqTxvUjSvJ5nuxp6CdSTNUov3rwWluH4XmOKVSduGAIsDO5a21YVSrsFhwOrA\n7sDPI2JdYEvgv8D5Hcy1viPQFdgN+GdEXI2t8QDebKRgBW3dW0mR70xdFXl2p2c6CSkB7H7gBkmH\npAzvnhHxBnAatmZ/1Fgp2ybFCD+X1Ac4SdKuwOsR8SSwAfAf/HDfFyZb7AsAe0qap8qylJPYlK5r\nEbN9C/gttl5PxhZ5SyjydH17AVdLOlbSoqXs9FewEllHUtd6ezuSwlgSewRGAeOSzMOAo4HZgL9L\nGlBPuWrIMsBHEfFUcq1vhu/RgyLiWEmzNzKxr3wPpN+7l15ugCLvPOQL2UmRNDewFTAYeAfYG99k\nJ0paAsfF3wJWS/s3Tb1zRYzwHuBHwKfA/5IL/X3g18CLwG6SjpbUD7gS+A3wfpVlKVy7hwGXAHfi\nJLv5YbIiXx94DT9415PUs1oy1Jil8bXdHrgRuFJSX2zt/hF/rh/WO3ciKYzewLwRMbFI+kqvXYaV\nxbzA9ZLWqqdsM0s7Cu4zYPb0+m+AYcDBEXFcWlhtA/yqnOxWLyrugT9IuhgYKWl/SYunv1WlIq9J\n1nptCsyyJZ5pMpIleBewD3AddkH+ALgVu6MfBbYFFgS2kdSnUVnIbZEsxJ443vwulvWiiBifHubd\nIuJdYCNgNDAQuAG7IwekfWb6u58WDMXD62JgB+AN4GlgF+ASSQsmmd8CfoUXFv+gSUMVlYu1iHgA\n2Bhn2A8D5sMLvLuAHwMvATvK5WZ1edqV/na3A9+QtEOSdULJUyDgIeAW7DVoCTQlC72HpEVLL40G\nvinpbOBi4EDg2PTaEvhv9FFawNZT3sp7YFtsFIwC9gdOk7RchSJ/BLgeJ3xmZpKsxDsZ6QH4c5xd\nvAkwKSI+iohXI2IXfGMNAr6Jb8bvA79LxzbTknQdbIkNAp5JD/ABko4C/iZprYj4L/6Mm+A68n7F\ng74almNxDkknAH2B30bEntjamANfuyslfTPt/xZ+2N4NPDWz719tSiGKnpL6SVo/hR5mTddySESs\njBcoT+Frvwj+zvROIYuqfkfa8gCV/nZX4O/xPpJ+l16bKGlOYE48B3vziHiumjLVinT9J0r6GnAp\ncKxSN7qI+DNO3NseuBw4LV3vvjiBsgtwaDpP3e7T0j1wPL4HNo2I3bESnwtYFjhZ0tIlRb4HNh5q\nsrjqbJZ4nifeiUjW61XAx0DXiNgwbS/it+WY1rzA3NgF/VJE/KL+Ek8hJYqV5dsMGIofHGOwYtkf\nW8Fz4pjoGhHxUMV5Jrv+qiTXksBxwLCIuFjSAdjNvCWwMI7P3osV/Ou1kKEaJItqUgpR3A4siq/h\nB8D5wLkR8VTFMUviBd6uwF8i4g9Vlqnsph2UZFoQ/91HRsTbKfTzf0BP3PRlNLAisBLQt4UUePn6\n34fDFacDN0TEuLTPXMBl+LM9DkzCLvaPgNXTArUu363y/Shpcdw574yIuCTdA0fh0NUSuI7/DmBQ\nRDyenjfdSom0VWP5vovHXfedWe3TMmuPNfI88UxT0AOYB/gZ8Khc8vRRhXIsbs73I+IduXnKMEkr\nRcT9jRC69IDrXrrxX8Sr/RHYGpsbW9uXYsvwUuxNmEqJ1+AB9xxwGzBc0jo4t2CHiLg4yb4esDJw\nh6Q1IuK1Jlbg3bGrdgx2i76a/r8lsLSkQeH63+KYpyUdAywPrFLx96mGTIUC/ye+hg/jBdo5wD8k\nnRQRo+Vysn2AAcBywMvAqq2iwGFyq+Du+Hv7X2Br4LW0fTage0S8B6wlaXfgO9j6fhiHkj4vLPla\ny1qxuFo4Ip6RdAlwd7oH9gW2j4ir0j4DgBWACyRtHRGP414OmSqQlXgnoFDMETFGzmA9F8dnN5d0\nYbHShynWeEnRfIQt94aFXooYIfCgpNsiYlBE3CfpSNxZ7kPgrsJSlPQRjk2PqaYchbKrkG2ipFOS\na3MAVuo3lnYZiy3ELkA5Y7dpKF3flYBewJERcXt6eZSk/+AY7PZpUfdZTCk3GytpOH5wfx0n71VF\nJgBJp+HExc3S33xXbKFuCXSTdHREvCRpL1xuNTvwafk73YxIWgF7Qh8obV4AWAhf/1fSfhthL9N3\nJI0Adkqu9crzda2HAoepuhFeD7yTFndnpG2DcKjl/0r3SxdcBvc5Vb4n26K5on61J8fEOzhyidBl\nkpYGSIkv22Pr8Sjg13IjibaOnQX4CU4Iq8rDeSaYByfE7C7pTwARcVNEHAOcGRFPyUNPlsIJP6/g\n2HNVSA/JQrEsKGkJuYe4kgLvimPgc0XE22m/eYBPcE312hHxYrXkqSZJ9rtxZv28wMi0fRaAiDgR\nx2G3AXqWFzLp+/VT/JAeW2W5+mEFvmdS4AcBp2I37fXYjX+QpG+GM9Q/j4j3W0CB98EL6XXaeHkx\n4HuSVpeT2C7Di9Rbcani/m2ds04u9K6lf6+D8yHOw4v8gkWAb0XEe2lxOC+WfyfgJxHxcq3l7Gxk\nJd6BkZPYfoUV8QWSvguTFfnGOAv9VNpX5F8D+gD9I6KhSjxcu34o7iZ3oKQ/ll6LFC/cDT9UegC/\niCpkocs10GX34Zn4gfoQbvV5oFxG83l678UknStpR+DPONv/iYj438zIUUuS7Mfh67YUzuonIj7T\nlJr2i3DIYsWKw+fGHel2jogPZkYOfTGJ7RE84OQeuaxqP2C7iLgSh05G465xf1Iq52sFImIssF5E\nDJHUS9JSyWp9BZd8HoErGPqm/TbGyvsxvJhtlNzFPbANfq6MwrkJEzXF/L0cmE/SZZK2w16T/jg0\nUId7oBaNXprbss/u9A5KSpA5CZgfu7B+CFwh6bcR8UxEfJBcdZel/Xon1/qnxTki4r3kKqtr/KpQ\nmqVYbREOeFnSiWm3gyVNiinJVL/E3bseBgamB8sMxwiTtdQrXKpWbBuGy6qOwXHLH2FvRj+5zGkE\nfgjvhx9y72ALvNFejKkohwVK1/YKSR/j78MOkp6JiPsj4rN02EL4ezSVoo6I1yStEBGfzKRM5YXS\n3sArEXG5pGPS3/KXePF0VXEIrl+fHQ/taSki4tWk+C7Enoyf4rDLsThRrxvw34h4PS1E58ehjv/U\nW9aKv82GeLH6Jk52/DTJV+TV3AaciL19A3Bf+7Uj4tV6y91ZyNnpHZBkVY/EN9o5uMfy74FNcaOT\njSPimbTvnDhz9I2IaMu91xDkTPqbcFnT8ELZpNcWAQ7BD4qDk0sdua72hcK9PaMuxrQA+g8e9LFj\nWkj8HFvWewE3hTOB58DX82TgkGIBJOkb2EJ9I5yM1DRoShlTd5wk1rOIv6bX18fJbaOwy/dqvFgZ\nDEzEWdBVbexSsaj4B06CGomzmd+Xa79H4Fj3gLTfIsAJ2EL9KCLeqaZMtaJ0/fsAswDfw5ndvYAt\ngAcrwhV9cGe60/DC5cd1cp0Le2YmlhT4/BHxVsqLGAy8jj1eRca50r3SE3//58UW+Lttv0v1Wb7v\nEjFi5NlVP2+f7v2bNjs9u9M7Jr/CmdlH4HGcL0TEvrj0aW7chKRwrX+Arcv1GiVsOyyKXYf/lLRa\nUsxFKdxLeF7xGOxKPS1tf77YbyYUeDecIfwcsHvpgToPrv1+IinwJXEr1SuAQ5NFsqLcGOeNiHi8\nCRV4udPdNdjyu0/SDZJWltQ7Iq7Bsdcf4FKue7Bn4Q0c05zUhtt7pigp8PNx+GF7HAd/Pyn4iThZ\ncDFJR0paG+cZrASMbSEFrphSB/4i7of+OA4NTMAhixVK+8+GPT3n4qSw/slDVdPuiek+2wwvkHqn\nbcNxyIWIGAIchuvAD5H0vbTALu69TyPi9Yh4pJ4KfApdavDTvDS3dJkZZQEcz74/3fQ9AMIZpJfi\nBgyXS/pe2v/jejwcpkXx3kUMOyKewOVNT+Pe3YUi75pefxLHCO8Bli/F5GZ2GMcCOMZ7bUSMkzRU\n0n7AN4DPw5nQi6X3vQXYNiI+kbQ5LnOaYybeu2YUCxs5Ee0u/AA+H3tqFsNu6i0l9YqIa3HOxBg8\nFe5PEbFRipH3qIUlKKk/DocMjIi7UyhnXtwxcHMc/74PNwq5GLcD/mWkJMJmJ1ngxUS93bHyviYi\nxoZ7GWyFPR0XSlopHTY3LvO7BHcaLBoV1doSF65BPwI4TtINeNjNn0v331E4DLc2bjH8vZm87zIz\nSFbiHYiSIitqo7cAiIjxhSLH3Z1ex80xTpc0X3Hz1cNN1x4lBXOhpHXTtvuxNfAEVuQDSq69vtiV\nvT8wlaU+k7yJY9k7JutjPRwnvhEn7PwNN2+5FdfCfixpPlx7PwtVztCuBpp6JOv3gf/hBLHDwzkF\ny2MleQTulU5E3IQnsC0B7Ctp2bR9fI3EnAOYFXhR0pySNsCLtCHYQt0BK42fJblWjYhHayRL1Sm5\n0LfD4YmbcWJk8XpZkV+Q8gxexJ3Z/lQssqMOZWTJM3IJvuY7Aavg78sDSY6iR/1hOHHtF8ChkpZs\nBkXe2Tq2ZSXegSjdQK8CT+K63gHptfFpFf1DnPX7T5xpvFQDRJ1Mcl8XC5B1cEvYQ5NlRkSMxO7c\nR7AiP1zSPjg+/TXgvkJBzewDpHB3Yg/AfPjhtT9OsnoMK5Fi1OVW4Rrp7+JkpLVxfP7DmZGhFiQX\n+CzYfX4cMC55MgoLcQweZDIWOLx03HW4nGsV4AxJy9RQzNG4EuIcnJF+Pg5VrIGztNfEpUsjI+L6\ncLVCq7E/bgXbH7cKniSpSylMVCjy8cCtSSlOTiqtUyy88IQFvgcC/102SZ6Rokd9WZGfgg2GvTX1\n9LJMHchKvMWRS1S2kbSbpJVSXPMF/MBYHjhK0g5ysttquLb2ORwf/xqOQTZK9nKM9h/YhTsJWyqn\nSloDJivyXXEo4FCcXPYxsE5JgVejF3qxCNgBu5LfAA5iSpzyLBwnXhK4VtJtWOn8BGfgPj2zMtSQ\n+XCy3mrAgnKtexGjLRT5pcBykhYoKZbrsPW4MLbga0JEPIsXQmNwqGL7iBgY7ro2Hn9n6zrco9pE\nxOE4QW0O3O9g4YiYVPYiJUW+M17IPFtP+dL3oXwfnY1zIwbhxcXRkr6e5Jw8bCYiBgMHAydEnStZ\nKpFUk59mJmentzBJ+d2LY2fzYzfwJcAfIuJDST/F5VDL4gXbx9iFtxpu2zgc2CsiLmmA+MDkZiH3\n41KUk/GAhA2BPbFHYf+Y0j2s6NM8Ds8OLyaWVdXFKGlhHG6YFSvtXniQxkhJs+MWoJvhazoKx8+b\nspFLGbnP+B64A9h+EXFienAXWf9/wkltK0VFUp6csFfzUIEqqgrkGfCH43j5Wq1igVd+jorX/oYV\n9bHAqeHBOFP1I/8y56kVkv4C9ImIbdLvfbB36iQc2jggIt5NVvfvaaLvf98Vlox7Rg6t+nl7devX\ntNnpuU68tTkBx3B3wArvOGADYHZJe0bELZJewAp+BWyJXZ+U38HYwrm3MaJPZj3crnM3YESyBI6R\n9AZwPHCSpD0ioui+9lxMyWbuUm0FDhClrlJyw4qhuH/85jhZ8CZJt1TD+q8F7T34w33GT8UZx8cl\n6+8SSa8Dy+DGKY/RhsVbDwWe3qeswLfGbvT18DCbVlHgRRlZ0c1uVmxVjw7PKvi9XIZ1QNr/1Ih4\nq61wUAMU+JzYKPippNMiYo8UNjofu9ZPArpLugp7TnbEE8kyDSIr8RYkrYzXxX3Nz0juZuQuYSfg\nErNT5EYt/8HK+960z4Zy96ufY8um0U0Y5sblW4+nxUWP8FzwC+VZ3H8ETpC0f0TcWVacdVKio7AV\nMhRbIVtKeiAqmqXUQY4vRYUC2RiX6j2F64+fCw+rODrtfhx2lb+C455jgU2qGaKYUeSWq7tj71H/\nIobf7JRCFLPi2vaFcNgKXC45NCLuiIhtJQVW5JMk/TXSlLtGkWT/QNK+2D2+RfoeDAwncF6AF/5n\n4mS2cXhS3AsNFPsLqJNFiTvXp+0AJOvpKFxmsz2uN0VSz3DXrL1wg441sRVbWfK0Alaa/SPikboJ\nTpttNcEWyjhg06SAypn0/4c7hM0O7Cc3+KgrSUEXinwstjqWr3i9KajIMbgD5w+shxcgp0j6BUC4\n0c8x+GG8BFaUu+Is/wnyNLJGexlG4iz0jVtIgXdNC6BuwAXAu7iF7co4rrwJzlFZHSAitsM5FQfR\ngD4N+mJL4i7pM7yGx4deCmwm6c8AEfFxRJyNc0K2BfpFxMN1FTrzBbIl3mKkh8SleK7yr3H8+OFw\ns5EeSQnuhZtD7IobkhxVWFYRcYikOaLOWdQVFuJvsev8edxN7j84tva0pBHpM3QBvo1Lu0ZhpbM4\n8FI95YbJ13wUvp4nUtF6tFkIl//0xuVvY3Ec/3lJ9+Is7znkVrU3Jtf6n/EzYDvche7x9BBv+JjI\ntIh4Zro7NhHp+vfE39NuwMmlfI6HJL2I6/G3kfRgUoo7yVPizm2AvIU36Vzgqoi4Vs6W7xpup3tk\n+hy7SPo0IvZLxz1DU/9tmjsRrdpkS7yF0JRGC/filfL1eIrTHmn7+EKR47Ks/bHyK8qMivKReivw\nSgtxW+CXyeL7H7ZW5sdlY7vIGbBr4fGXn0bEyXga2IB6yl0mzL+BNZvNfViQvDSDsGdjq6TA/4W7\n9x2EO5wdKU+gIjy69Xjg77iRx6B6x2A7Aum6F/+/DPfv/wHOqEdSt+SqvhGPbP0dbrADQEQU/eHr\nblTJJZIrAv+S9JOk2Iu2xa/jOv23gEGSqp8xVnU6X3Z6VuItgDxJaxas6IDJpSiHAzcAQyoU+SwR\n8VlEnBSlTmyNcpEmGfrguPwYvMD4a3LdKlxGtCr2HhyDk/Uuwd/PXeQOaeNw97aGEqUBMc1Gcu0/\niWervyZnGS8HbBgRp2IF8kNgr5QXUZR2DcELwsPaCL9kpkHJhd4Hh32OxyVyCwJrp3txIlOetaPS\nvxetPFfUaR54xXu+gD1MdwA3Sfppek4UJW+v4O5yTwGrqIWmxXUWshJvcuQ+y0OBfwOPSPqLUrvU\niHgQOBK30TxC0sC0/bPyORqQ4dqjjc0HYyW9U6TpWHLJ0+pyS9XncBOMdXDG62Y45jYB+APuLX1n\nfT5Ba9BWjkG49/nRkhbCeRFH4QcweBE0Hns5flLyzLyAW8YuW28vTSuTFqCfa8rAnG2xFb4f7jI4\nEFghKfLiHpwdJ6R+3NY5ayxv14rfC0VdTN+7C7hR0trFgkIe5jMODxxaLVI5XHOTR5FmmoSkwB/A\n7qyh2IodCswr6fhwG8QHJA3BN9lpkt6KiMsbKPMquE3ndoVCSA+PRYHnI+LFZO1tjj0JXYC5JB0U\nEccCd6cfJG0mt99cCw/feLmNt+yUlPIfegFb43v52Yi4OeVHLIZjs6+m34X7pZ+Fu/WNKkIsKVei\nKep8W4VSjkcXHMJ4ErgxIj7CQ2V2wsltQ4G/SboFu9D3w272m+ssb3mc6EDcXreLpCci4rSIGCHp\nIFwNcp3cFfEdfO/1BXaJhgwzyUyPrMSblGTNXoT7nG8WEe9Iuhj4EJeXFYrvgYgYJel4nOl9Vftn\nrQsLAi+VLbpkrTwDHCjpr3j8Yn+sxO/DpVCHyCUsb5cyvufDJWj9U/y2UyNpRWCpiDg/KfDZcRnT\n7HhAyzuSrouIHXC997PYdf4mrlXeHdfZFyWJdW8k0lGIKb3QN8Ex5espdViLiPskbYUXTSfi+3gU\nTszcJqb0Qq/LWNGSAr8cd2l8Bn8ntkg5ErsnmffDPRtOxgmcHwIbtJICzyVmmWZhMdxc4fikwC/B\nceNVcZ/i/lgp/gic7BYRBzQwQWZxSUtHxKURsbekPpJOkvTttMvZeG5yP5wxv3pEHJ2yd9/ELt8x\nJQVOiuP+OivwyT3m9wTOk7R92lw0+9kQL4yuAdaV9M/00D0dN3F5GLgSz4feoThnVuAzzWE4q3xV\n4KmkmMvP1PtxZ7aRQHec77FlWoB1r9f1L+4pSYfh8shNcZvgFXEZ4tqkpNGIeDgtApfD4Zh+0UKD\nZjoj2RJvXl7ASm+4pN1wP/HNIuLpZFk9hh/eC0naKiJGFwfWO0FGHozwL+DT5EZ/BM8o3xNYRNLA\ncFOZPVKIYGJy8XYDFsEPkdE4A704p1JG+Jh6fpZmJS3O9sUL77MlfYbDLDem3AiSO/R9YCe5qci2\nku7DdcqfAkOToql6q9rOQOV1i4gDU2hoJ9wL/dEoNWxJCW/34/tgGFb420p6OBpTxtcPuB2XpE5I\nC+yD8dyCYeUdI+LxBshXJZo7hl1tsiXepKQs6FvSar0/8CjOei1KxF7H1u27pFKWRhER7wDn4a5f\np0haLjzKclM8HOQMSd9K+36cFPgcuLTs/HTcDumhVyTbNE0TlWYhIt7ECuFK4EJgbxy3JFl272Nr\n7yxcwndhRIyKiNMj4pyo4zjLjkjhQpe0dGnbLjjuvTawc1rQlo9z8lknAAANo0lEQVSZlMIXm6dN\nV+NZBnVDrm6ZA8e2Xw13X1sC92gYDuwcEZ9IGixpm3rKVn1qMYi0uRcFWYk3MUmpdcW9rufBiUlI\nWi79fk5E/CJKZWT1ppThfAKe0LQAnkC2TERciq2UNXDS3ULpmG44Pnsg8B6wYnpAds3Ke9pExNs4\n6/kiPKRlzbR9QrIU/8eUbmxbSPojTJWJnF3oM0j6rp8BPJbyEwCIiO2xNXsoMLBQ5MU1T/uMxINn\nXsdx5lrKOdWzICI+Twv/Ubgn+io4l+JWvHgeK1e8LAd8sxHhuMyMk/9YTU5S0EOwFX6ePNCkP/AZ\n8FB5vwaJ2AX3fu6KY3+v4Vrk0yX9PiIuTs+ys3FDkYHhGuarcVLb8KjRNLKOSkS8JekArMT/IOm1\nZGkXY0X/J+kEPBTn7HRMXhzNJOl7OgxPALxD0hoRcX96bYv0PT8U3w9nRkU5VjgDfLWoYa+Biiz0\ndfF35I1wo6JLgFOx9X1TRGyS9psbL6i/B+zdyvehoOmbs1SbrMRbgHAZ2Vr4gfx9XIO6ST0zXNsi\nxa2LTmwP4D7uPfDiYk1cWjOwpMjPwsp994h4rHSemkwj68gkRb4HXkSdJYmSIu8eER9gqzFnoc8g\nKg2B0ZRSvBtTPsIxWJEPqFDkk3DVxWu00Uq1lgo8nb9Q4P/EHrD5gDclXRwR+6RQwB5At+RNWAZP\nWlsHV4HkUsMWIyvxFiEi7pa0AjAL8H5ytTfUei25+4fhpLRd8Zzv8ZIOxC7zskU+CQ9uGY1X/sV5\nGj1soyWJiLeVGvxgRT4pIs6rTJrKCnzGSJZ3T6BrcjkXivz29P0uFPlqRXJhRGwl6XlcI143ys+C\nlOC4Ap5H8Eb6/1byzITtJb0FbIm9ey/h0rhVo0UGzUyfzhUlzkq8hYiIj0mdnprIep0LN3K5NtzI\npYiRH5NigkcBf03W96WS3iN3XqsaJUU+CThH0jsRcW2j5eoIpAXqLUCv5Dr/qEKRH44Xpbcli/xh\ngIgYko6v2yK7pMCXB/4LnAJcnRYiz+FSxJ2T/NviCYfLA88Dk9KzpUPQ7Ilo1aZzLVk6EE1kvX6C\na2Dng8nWS7f076NxT+Yl8SzlRSNieDSolr2jkpLd9sRDcW5osDgtTZEUlkJFn+MqgEWAyyTNFlMP\nEroRJ7TNCjwoaanyueq9yJZLUUfhuPeHpVyTomrhTFy18I/0+R6KiDEdSYF3RrISz8ws43EzkQGS\nfgyTS3G6yC1Be2F33WOk2efFPo0QtqMSEW9GxKF5gTTjJIVXDOv5i6Rfhedn74knwE1W5KXDZsGK\n/mQaP57zX7hqoTupjK2c7IgV+Rl4FPB5DZOyptSib3pzW/ZZiWdmivDY08G45O1wSaul7ZOAhfCw\nhz3wbOuGlcJ1JvIC6aujqcfl3oMrLFZJL1+Nv8M/Aq6QtICkXpIWwd/xqyNin0YvoCLiDeAArMz3\nk7RD2l5W5CcCRwBHN0rOjoqkhSRdLul/ksZIulKpP8aXOLanpOMlvSnpE0n/ltT/yxybV+yZmSYi\nnpK0EXAF8HdJI3ATkp/hUrjHUhLc5B7OmUwzkRaYvXD51bs4Gezl9NpHkv4BTASOw6WUz+I57Z/h\ndreTqzUaIP5kUtXCIKAr7VQtSDqyI5ccNqLETFJv4Db8fdgat8z+I3C7pGUjYux0TnEunomxH56I\ntxseDdsv3AGzXbISz1SFiLhZ0kq4TnZ57GZ/Avhdo0vhMpkvyfrAnLgBynMAklbFk7zG43HA6+HR\nuD3x6M7dmu37Pb2qhY6swE1DHMw74v4Bi0fE8wCSHsPdNHcGTmrvQLl51++A7SJiaNp2J56MNwR/\nL9slK/FM1Qj3dd8Gx+R60SSlcJnMl2R+/L39UNJ38aChg7FltDhuU7pGRPymfFAzfr9LinwirlqY\nEBEXNVquDsz6wH2FAgdI1Tr3AL9iGko8HTsBN+Mpjp0oT608UJ5H/1l7B+eYeKaqRMSEiBgXEe+V\nXOhN9YDLZNrhdjz69lbsIh+IW6WugIfI9MUTyybTzN/vVLWwN068e7DB4tSNBvVOXwp7Hit5Ejfo\nmt6xL0bEuDaO7YFLeNslW+KZmtLxXXeZjkJEPCZpALANfiDfFRGPp2TMuXH2+X8rjmnq73dEvClp\n+2Zx9deaBx988iZp8XlqcOqekkaVfj8rIs4q/T4Xnr9eyfs4RDMtpnVs8Xq7ZCWeyWQyifCgkpHF\n75K6457iB+LuZi03W7uzKHCAiPh5o2WoN1mJZzKZTBvIg0F+j8eM9gbWKpq9NFGzpUxz8AFtW9zt\nWdmVxy7czrEwxSJvkxwTz2QymbbpC/wCeAH4UaneOivwTCVP4th2Jd8HnvoSx347lalVHjset8Zt\nl6zEM5lMpm1uwd3Nto0p8+6bMokt03CuAVaW9J1iQ2oGtGp6bVpciyt6Ni4d2w1/926eVmY6gJo8\nLyOTyWQaTnahZ6ZFatX7KJ4lcShu9nIk7qu/bNGfXtLC2LMzpBiUk7ZfjMM2++H21L/HPQlWiYiH\npvXe2RLPZDKZ6ZAVeGZapI5sa+JOfhfh8cwvAmtWDJgR7qZXqXu3BYbiLm/X4Xa+P5+eAodsiWcy\nmUwm07JkSzyTyWQymRYlK/FMJpPJZFqUrMQzmUwmk2lRshLPZNpA0jaSovTzkaRHJQ2sx8xoSYMl\nRcW2kDT4K55nT0m/rqpwPu9Lks6fzj4DkswDZvD8f59R+do43x2S7qjW+TKZZiF3bMtkps3GwGvA\nbOnffwbmw+Mo602/JMtXYU9gBHBl9cXJZDKNJivxTGbaPFIaL3hzGlE5iHaUuCQB3SNifLUFiYj7\nqn3OTCbT2mR3eibz1RgFzCZpPpji9pW0naTRuE3iuum13pKOlfSipPHp/4dImuq+k/RDSXdL+lTS\n65IOgy/OP2zLnS5pOUn/kvSepE8kPSPpoEI23JN581JY4PyKY6+R9EE69h5Jq7XxvoPS5/xU0qi2\n9vmySPqZpOslvSlpnKQnJO2TJoW1tf+Okp5P7/2QpDXa2Gd1ScNTyGOspJskLT2jMmYyrUS2xDOZ\nr8Z3gM+BcgOHNYAfAEfgUZUvpbj5Tbj/8ZHA43gm9WF4sME+AJLmAW4D3gK2Bj7DXZu+NT1BJK0E\n3IF7K++FXe2LAcumXTYErsedpAanbe+kY5cH7gYeBnYExuHZ2bdKWiUiHkz7bQ+cApwPXIJnG/8T\nd6KaEb6TZP4rMBbP6h4MzIsnhZUZgPuXH4KvywHADZKWi4hnknzrAlfjBhlbpOMOAO6WtGxEvDqD\ncmYyrUFE5J/8k38qfvBM6QAWx4vdOYGdsQK/qrTfS1gBzl9x/Jbp+P4V2w/B1vp86fej0u8Llfbp\nA7xLGldd2h7A4NLvdwGvAr2n8TleAv7exvbhwNNAj9K2rmnbVen3Lun8N1Yc+9sky/nTuYYD0n4D\n2nld6doegic5damQu/K6zIonOl1U2vY8MLzivLOl63dKadsdwB2N/l7ln/xT7Z/sTs9kps1oYAJW\nHn/F7RS3q9jnvoh4q2Lbz4GXgXsldSt+gJvxsIOV03790vGTLcZwC8drpyVUmni0KjAsIsZ9lQ8k\nqRewOnAZMKkkm4Bbgf5p1wXTz6UVp7gCmKFBIJIWkHSmpJexkp6AW03OgRMGy1Rel4+wxd0vnWsx\n4LvAsIprPA74d+lzZDIdluxOz2SmzYbYTf0R8HJEfNrGPm+2sW0+HI+e0M55507/XwB4oo3X356O\nXHNiS/mrZquD3fldsWv/sLZ2SHH7BdqSJTzR672v+qbpnNcA38Au9NF4YMQG2BrvWXFIW9fgbeCb\n6d+F0j83/VTyyleVMZNpNbISz2SmzRMxJTu9PdoaQPAeHoCwSTvHvJT+/ybw9TZeb2tbmQ+ASUxR\naF+FD9OxfwEubGuHiJgkqVicTCVLsnbn/uJR0+W7OAa+ZURMrgGX9Mt29m/vurye/l0sJA7CHoRK\nql4hkMk0G1mJZzK14UZgI+DjiBg9jf3+DewnaaHCdZzGGran2ACIiHGSRgBbSBoSEZ+0s+tnQK+K\nY8dKuhtYDngo2p/Q9RqOiW8CnFfavhEz9uzonf4/2TshqTuweTv7r1xxXWbFmf/XpdefwYuhpSLi\nmBmQJ5NpebISz2RqwzA8XnC4pBNxhngPbI2uD2yQYtknA7viGvTBTMlOb08pl9kXuBP4d3qP13D2\n9w8iYve0z1PAapLWwxnw70bES8DeODHuJknnYo/APMDyQNeIODBZ40cA50gaClyMs9MPBMbMwDV5\nGucJHCXpc6zM95rG/m8z9XU5ACf9HQnO+pO0G3C1pB44dv8uttZXAV6JiJNmQM5MpmXIiW2ZTA2I\niAnA2sDZwE641GsYLiO7l+TqjYh3gbWw8rkAu7hvZGrLt733eAAnt72KO8ldjxcA5Tj5QdhivRR4\ngFRqFp5TvCJ2SZ+GE+5OBZbByr14j3Nx17c1cSnXtsBm2J3/lQg3wNkALyYuTJ/1LqA9K/pO4ETg\nT7i8rSewTkQ8Wzrn9TiBrQ9wDi7rOw6YH3s5MpkOTZ4nnslkMplMi5It8Uwmk8lkWpSsxDOZTCaT\naVGyEs9kMplMpkXJSjyTyWQymRYlK/FMJpPJZFqUrMQzmUwmk2lRshLPZDKZTKZFyUo8k8lkMpkW\n5f8BpWWWSNCQ7q0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21cb1f89a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, cmap=plt.cm.Blues):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cm = (cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]).round(2)\n",
    "    fig = plt.figure(figsize=(7,7))\n",
    "    matplotlib.rcParams.update({'font.size': 16})\n",
    "    ax  = fig.add_subplot(111)\n",
    "    matrix = ax.imshow(cm, interpolation='nearest', cmap=cmap, vmin=0, vmax=1)\n",
    "    fig.colorbar(matrix) \n",
    "    thresh = 0.5\n",
    "    for i in range(7):\n",
    "        for j in range(7):  \n",
    "            ax.text(j,i, str(int(cm[i,j]*100)) + \"%\",va='center', ha='center', color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    ax.set_title('Confusion Matrix')\n",
    "    ticks = np.arange(len(labels))\n",
    "    ax.set_xticks(ticks)\n",
    "    ax.set_xticklabels(labels, rotation=45)\n",
    "    ax.set_yticks(ticks)\n",
    "    ax.set_yticklabels(labels)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "plot_confusion_matrix(y_true, y_pred, cmap=plt.cm.YlGnBu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def class_precision(y_true, y_pred, emotion):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    i = [i for i, label in enumerate(labels) if label == emotion][0]\n",
    "    col = [cm[j,i] for j in range(7)]\n",
    "    return float(col[i])/sum(col)\n",
    "\n",
    "def class_recall(y_true, y_pred, emotion):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    i = [i for i, label in enumerate(labels) if label == emotion][0]\n",
    "    row = [cm[i,j] for j in range(7)]\n",
    "    return float(row[i])/sum(row)\n",
    "\n",
    "def class_accuracy(y_true, y_pred, emotion):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    i = [i for i, label in enumerate(labels) if label == emotion][0]\n",
    "    tp = cm[i,i]\n",
    "    fn = sum([cm[i,j] for j in range(7) if j != i])\n",
    "    fp = sum([cm[j,i] for j in range(7) if j != i])\n",
    "    tn = sum([cm[i,j] for j in range(7) for i in range(0,6)]) -(tp+fp+fn)\n",
    "    return float(tp + tn)/sum([tp, fn, fp, tn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angry\n",
      "   acc = 0.8245584524810765\n",
      "  prec = 0.42833052276559863\n",
      "recall = 0.2651356993736952\n",
      "\n",
      "disgust\n",
      "   acc = 0.983515559293524\n",
      "  prec = 0.6511627906976745\n",
      "recall = 0.25225225225225223\n",
      "\n",
      "fear\n",
      "   acc = 0.7885618166526492\n",
      "  prec = 0.35006435006435005\n",
      "recall = 0.265625\n",
      "\n",
      "happy\n",
      "   acc = 0.8052144659377628\n",
      "  prec = 0.6561866125760649\n",
      "recall = 0.7294250281848929\n",
      "\n",
      "sad\n",
      "   acc = 0.719259882253995\n",
      "  prec = 0.3608179419525066\n",
      "recall = 0.43865276663993585\n",
      "\n",
      "surprise\n",
      "   acc = 0.8978973927670311\n",
      "  prec = 0.6266968325791855\n",
      "recall = 0.6666666666666666\n",
      "\n",
      "neutral\n",
      "   acc = 0.7571068124474348\n",
      "  prec = 0.42426417803302224\n",
      "recall = 0.4793187347931874\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for emotion in labels:\n",
    "    print(emotion)\n",
    "    print('   acc = {}'.format(class_accuracy(y_true, y_pred, emotion)))\n",
    "    print('  prec = {}'.format(class_precision(y_true, y_pred, emotion)))\n",
    "    print('recall = {}\\n'.format(class_recall(y_true, y_pred, emotion)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      angry       0.43      0.27      0.33       958\n",
      "    disgust       0.65      0.25      0.36       111\n",
      "       fear       0.35      0.27      0.30      1024\n",
      "      happy       0.66      0.73      0.69      1774\n",
      "        sad       0.36      0.44      0.40      1247\n",
      "   surprise       0.63      0.67      0.65       831\n",
      "    neutral       0.42      0.48      0.45      1233\n",
      "\n",
      "avg / total       0.49      0.49      0.48      7178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true, y_pred, target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
